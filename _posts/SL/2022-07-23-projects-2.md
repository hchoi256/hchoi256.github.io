---
layout: single
title: "Deep Learning - CIFAR-10 Classification"
categories: SL
tag: [CNN, Classification, CIFAR-10]
toc: true
toc_sticky: true
toc_label: "쭌스log"
#author_profile: false
header:
    teaser: /assets/images/posts/dl-thumbnail.jpg
sidebar:
    nav: "docs"
---

# Code
**[Notice]** [download here](https://github.com/hchoi256/machine-learning-development)
{: .notice--danger}

# Learning Goals
1. 합성곱 신경망 모델 설계하여 케라스로 이미지 분류 <span style="color: yellow">Building the CNN and Image classification using keras</span>
2. Adam 옵티마이저로 신경망 가중치 최적화 <span style="color: yellow">Optimizing weights using 'Adam'</span>
3. 드롭아웃을 통한 과적합 개선<span style="color: yellow"> Drop-out</span>
4. 모델 평가 진행 (*confusion matrix*) <span style="color: yellow">Model evaluation</span>
5. *Image Augmentation*으로 신경망 일반화 성능 개선 <span style="color: yellow">Improving generalization error through image augmentation</span>
6. 훈련 신경망 가중치 조작 방법 <span style="color: yellow">How to adjust weights</span>

# Background knowledge

## CIFAR-10
![image](https://user-images.githubusercontent.com/39285147/180509114-3b492055-56eb-42c6-85b8-80fb8e077546.png)


10가지 클래스로 나누어져 있는 **6만 개의** **컬러(RGB 채널)** 이미지로 구성된다 (airplanes, cars, birds, cats, etc.). <span style="color: yellow">Ten classes; each includes 60,000 color images </span>
- 이미지 해상도가 **32x32** 픽셀로 매우 낮다. <span style="color: yellow">Image resolution = 32x32</span>
- 각 클래스마다 6천개의 이미지가 존재한다 (클래스 별 매우 균등한 이미지 분포). <span style="color: yellow">Uniform image distribution by class</span>

이번 프로젝트에서 주어진 입력 이미지가 10개의 클래스 중 어디에 속하는지 분류 모델을 학습시켜보자. <span style="color: yellow">Training the model to put new image into certain class</span>

## [Convolutional Neural Network (CNN)](https://github.com/hchoi256/ai-boot-camp/blob/main/ai/deep-learning/cnn.md)
![image](https://user-images.githubusercontent.com/39285147/180512062-48c118e4-c9d4-4ea6-8281-958201289626.png)

CNN 관련 배경지식은 상기 링크를 통해 숙지해주세요! <span style="color: yellow">Please refer to the link above.</span>

![image](https://user-images.githubusercontent.com/39285147/180513584-f47d8136-4cc3-473b-b85f-437ddd376101.png)

3x3 'sharpen' 커널 필터를 적용하면 인풋 이미지의 3x3 픽셀 범위에 대해 합성곱마다 가운데 값에 가중치를 높게줘서 출력 이미지에서 가운데 픽셀을 뚜렷하게 강조한다 (= 명확하게 보이게 한다). <span style="color: yellow">Applying a 3x3 'sharpen' kernel filter, the value in the center of convolution matrix takes a significant weight, which sharpens the image</span>

## 성능지표: Key Performance Indicators (KPI)
![image](https://user-images.githubusercontent.com/39285147/180517136-7b390f93-0f67-4e21-9217-a482e74a1f41.png)

**Type I Error**: 암이 없는 환자에게 있다고 오진할 확률 <span style="color: yellow">Probability of misdiagnosing a patient without cancer</span>

**Type II Error**: 암이 있는 환자에게 없다고 오진할 확률 <span style="color: yellow">Probability of misdiagnosing a patient with cancer</span>

**Precision**: 암이 없는 환자에게 없다고 예측할 확률 <span style="color: yellow">Probability of misdiagnosing a patient without cancer</span>

**Recall**: 암이 있는 환자에게 있다고 예측할 확률 <span style="color: yellow">Probability of misdiagnosing a patient with cancer</span>

> ![image](https://user-images.githubusercontent.com/39285147/180517030-eedfd66d-7cd8-4109-9fb2-87f6a29d3c7c.png)

# Implementation

## Observing the dataset

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn

from keras.datasets import cifar10
(X_train, y_train) , (X_test, y_test) = cifar10.load_data()
X_train.shape
```

        (50000, 32, 32, 3)


- *# Images*: 50000개
- *Image resolution*: 32x32
- *RGB*: 3


## Data visualization

```python
i = 30009
plt.imshow(X_train[i])
print(y_train[i])
```

        1

![image](https://user-images.githubusercontent.com/39285147/180518417-37e04fc2-210e-40db-b111-e219b5d66a9b.png)        


클래스 리스트에서 인덱스가 1인 클래스, 즉 'Cars'에 속하는 이미지인 것을 확인할 수 있다. <span style="color: yellow">Index 1 represetns 'Cars'</span>

이제, 한 번에 여러 이미지를 배출하여 직관적으로 비교해보자.<span style="color: yellow"> Displaying multiple images at once for better intuition</span>

```python
W_grid = 4 # Grid width
L_grid = 4 # Grid height

fig, axes = plt.subplots(L_grid, W_grid, figsize = (25, 25))
axes = axes.ravel() # 4x4 matrix --> 16 elements 
n_training = len(X_train)

for i in np.arange(0, L_grid * W_grid):
    index = np.random.randint(0, n_training) # pick a random number
    axes[i].imshow(X_train[index])
    axes[i].set_title(y_train[index])
    axes[i].axis('off') # hide axis
    
plt.subplots_adjust(hspace = 0.4) # space out images
```

![image](https://user-images.githubusercontent.com/39285147/180518577-9f9298f7-ff70-4bf5-ba08-b353fa610a6a.png)

## Data Preprocessing

### Formatting the image(float32)
```python
X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

number_cat = 10 # number of classes
y_train

```

        array([[6],
            [9],
            [9],
            ...,
            [9],
            [1],
            [1]], dtype=uint8)

클래스 인덱스로 종속변수인 2차원 배열이 표현된 것을 확인해볼 수 있다. <span style="color: yellow">expressed as a 2-dimensional array</span>

각 숫자는 앞서 '데이터 시각화' 예제에서 보았던 클래스 인덱스 번호이다. <span style="color: yellow">Each number represents the index of classes</span>

이를 인덱스 번호가 아니라 'One-Hot Encoding' 방법을 활용하여 범주화 시켜서 신경망 학습 인자로 만들어보자. <span style="color: yellow">Performing categorization to the indexes using 'One-Hot Encoding'</span>

> 신경망의 학습 데이터는 'numpy 2차원 배열'이여야 한다. <span style="color: yellow">Training dataset must be numpy 2-dimensional array</span>

### Categorization (Categorical Data)

```python
import keras
y_train = keras.utils.to_categorical(y_train, number_cat) # one-hot encoding
y_test = keras.utils.to_categorical(y_test, number_cat)
```

        array([[0., 0., 0., ..., 0., 0., 0.],
            [0., 0., 0., ..., 0., 0., 1.],
            [0., 0., 0., ..., 0., 0., 1.],
            ...,
            [0., 0., 0., ..., 0., 0., 1.],
            [0., 1., 0., ..., 0., 0., 0.],
            [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)


### 정규화
독립변수들은 픽셀에 할당된 [0, 255] 사이의 수치이므로, [0, 1] 사이 값들로 *정규화*를 거칠 필요가 있다. <span style="color: yellow">Independent variables are in range [0, 255], so they need to be normalized</span>

```python
X_train = X_train/255
X_test = X_test/255
```

이렇게 255로 나누어주면 각 데이터들은 [0, 1] 사이 값을 가지게 된다. <span style="color: yellow">Dividing by 255 makes the data become a number in range [0, 1]</span>

## 모델 훈련하기

```python
from keras.models import Sequential 
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, Dropout
from keras.optimizers import Adam
from keras.callbacks import TensorBoard # TensorFlow Visualization Tool
```


```python
cnn_model = Sequential()
cnn_model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu', input_shape = Input_shape))
cnn_model.add(Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'))
cnn_model.add(MaxPooling2D(2,2))
cnn_model.add(Dropout(0.4))


cnn_model.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))
cnn_model.add(Conv2D(filters = 128, kernel_size = (3,3), activation = 'relu'))
cnn_model.add(MaxPooling2D(2,2))
cnn_model.add(Dropout(0.4))

cnn_model.add(Flatten())

cnn_model.add(Dense(units = 1024, activation = 'relu'))

cnn_model.add(Dense(units = 1024, activation = 'relu'))

cnn_model.add(Dense(units = 10, activation = 'softmax')) # 최종 출력 클래스 개수 10개 # final output class = 10

cnn_model.compile(loss = 'categorical_crossentropy', optimizer = keras.optimizers.rmsprop(lr = 0.001), metrics = ['accuracy'])

history = cnn_model.fit(X_train, y_train, batch_size = 32, epochs = 1, shuffle = True)
```

> ReLU: 회귀 작업 관련 함수로 연속적인 출력값을 생성한다  <span style="color: yellow">Continuous output</span>

> Softmax: 분류에 사용된다. <span style="color: yellow"> classification</span>

> CPU vs. GPU
>
> CPU는 직렬, GPU는 병령 처리에 각각 능하다. 따라서, 하나의 학습이 오래 지속될 필요가 있는 경우 GPU가 아닌 CPU를 사용하면 보다 능률적인 처리가 가능하다.<span style="color: yellow"> CPU <=> serialization, GPU <=> parellelism. Thus, if one training lasts for long, CPU is better than GPU</span>

> ANN 은닉층 *뉴런개수*와 CNN *필터개수*를 증가시키면, 모델 복잡도가 증가하여 학습 시간이 늘어난다. <span style="color: yellow">The more neurons in the hidden layer of an ANN and more filters in the CNN, the more complex the model and the longer it takes to train.</span>

## Evaluating the model

```python
evaluation = cnn_model.evaluate(X_test, y_test)

predicted_classes = cnn_model.predict_classes(X_test)

y_test = y_test.argmax(1) # one hot(binary) --> decimal

L = 7
W = 7
fig, axes = plt.subplots(L, W, figsize = (12, 12))
axes = axes.ravel()

for i in np.arange(0, L*W):
    axes[i].imshow(X_test[i])
    axes[i].set_title('Prediction = {}\n True = {}'.format(predicted_classes[i], y_test[i]))
    axes[i].axis('off')

plt.subplots_adjust(wspace = 1)    
```

![image](https://user-images.githubusercontent.com/39285147/180562014-e6d8d90f-7dc5-449f-a7cb-233e50bd6fa3.png)


이미지는 결과의 한 행을 보여준다.<span style="color: yellow"> Showing one row of the result</span>

해당 행에 대하여 세 번째와 마지막 열을 제외하고, 분류기가 모두 올바른 예측을 해낸 것읋 확인해볼 수 있다. <span style="color: yellow">Excluding the third and last column on the row, the classifier performs prediction successfully </span>

여기서는 정확도를 결과값으로 따로 보여주지 않았지만, 정확도는 'evaluation' 변수에 담겨있다. <span style="color: yellow">The accuracy is in 'evaluation'</span>

이제 혼동 행렬을 사용하여 보다 직관적으로 평가지표를 분석해보자. <span style="color: yellow">How can we analyze the model performance using confusion matrix?</span>

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns

cm = confusion_matrix(y_test, predicted_classes)
cm
plt.figure(figsize = (10, 10))
sns.heatmap(cm, annot = True) # 해당 데이터가 많거나 높은 경우 색을 사용해 시각화하는 그래프 color visualization in case that data 多
```

![image](https://user-images.githubusercontent.com/39285147/180563602-b9035fea-733c-4514-a223-63c1e99608a6.png)

대각선에 위치한 픽셀들은 'True Positive'과 'True Negative'로 모델이 실제값과 일치하는 데이터들 개수를 담고있다. <span style="color: yellow">'TP' and 'TN' on the diagonal include the number of correct predictions</span>

그 외 다른 모든 픽셀에 속한 수치들은 오분류('False Negative', 'False Positive')로 취급한다. <span style="color: yellow"> Other pixels ('FN', 'FP') are errors</span>

## Saving the model

```python
import os 
directory = os.path.join(os.getcwd(), 'saved_models') # getcwd: get current working directory

if not os.path.isdir(directory):
    os.makedirs(directory)
model_path = os.path.join(directory, 'keras_cifar10_trained_model.h5')
cnn_model.save(model_path)
```


## Image Augmentation

과적합 문제를 해소하고 정확도를 높이기 위해 기존 데이터에 변화를 적용하는 전처리 기법이다. <span style="color: yellow">Applying changes to existing data to solve overfitting problems and increase accuracy.</span>

기존 인풋 이미지에 뒤집기, 회전 등 다양한 변화를 주어 학습하는 데이터량을 증가시키고, 데이터 차원이 모델 복잡도를 웃돌게 만든다. <span style="color: yellow">By applying various changes (i.e., flipping, rotation, etc.) to the existing input image, it increases the amount of learning data and makes the data dimension exceed the model complexity.</span>

> *ImageDataGenerator* 클래스를 통해 이미지내 여러 변화를 끌어낸다. <span style="color: yellow">various changes to images</span>

이는 차후 과적합 방지에 효과가 있다. <span style="color: yellow">Avoiding overfitting</span>

### New dataset with image augmentation

```python
import keras
from keras.datasets import cifar10
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

n = 8 
X_train_sample = X_train[:n] # 8개의 샘플 이미지를 가져온다 Loading 8 samples
```

```python
from keras.preprocessing.image import ImageDataGenerator

# dataget_train = ImageDataGenerator(rotation_range = 90) # rotation
# dataget_train = ImageDataGenerator(vertical_flip=True) # flipping/inversion
# dataget_train = ImageDataGenerator(height_shift_range=0.5) # 이미지 평면 위치 이동 move image plane position
dataget_train = ImageDataGenerator(brightness_range=(1,3)) # brightness

dataget_train.fit(X_train_sample) # applying the image genearter
```

```python
from scipy.misc import toimage # array to image

fig = plt.figure(figsize = (20,2)) # 새로 생성될 이미지 사이즈 조정 adjusting the size of new image

# 훈련 샘플을 가져와 이미지 flow를 생성한다. Creating the image flow with the training dataset
# 변형된 이미지를 배치 단위로 불러올 수 있는 Generator(*flow()*)을 생성해 준다 (8개 요소 포함하는 리스트 형태로 한 번에 가져오게 된다) Loading the certain number of adjusted images
for x_batch in dataget_train.flow(X_train_sample, batch_size = n):
     for i in range(0,n):
            ax = fig.add_subplot(1, n, i+1)
            ax.imshow(toimage(x_batch[i]))
     fig.suptitle('Augmented images (rotated 90 degrees)')
     plt.show()
     break;
```

![image](https://user-images.githubusercontent.com/39285147/180567864-9bef861d-2973-4367-9344-436ae78ee7c9.png)

이미지 증감을 이용하여 기존 데이터에서 새로운 데이터로 개수를 부풀린 예시이다. <span style="color: yellow">This is an example of inflating the number from existing data to new data using image increase/decrease.</span>

결과에서 보이는 것처럼 기존 인풋 이미지의 '밝기'를 수정하여 새로운 데이터를 만들어냈다! <span style="color: yellow">New data was created by modifying the 'brightness' of the existing input image! </span>

### Training the model with image augmentation

```python
from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
                            rotation_range = 90,
                            width_shift_range = 0.1,
                            horizontal_flip = True,
                            vertical_flip = True
                             )

datagen.fit(X_train)

cnn_model.fit_generator(datagen.flow(X_train, y_train, batch_size = 32), epochs = 2) # 이미지 생성기로 만든 데이터를 학습에 이용할 때 fit_generator() 함수를 사용한다 fit_generator() when using data made by image generator

score = cnn_model.evaluate(X_test, y_test)
print('Test accuracy', score[1])

# save the model
directory = os.path.join(os.getcwd(), 'saved_models')

if not os.path.isdir(directory):
    os.makedirs(directory)
model_path = os.path.join(directory, 'keras_cifar10_trained_model_Augmentation.h5')
cnn_model.save(model_path)
```