---
layout: single
title: "ConvS2S, Self-Attention, Multi-head Attention"
categories: NLP
tag: [NLP, ConvS2S, Self-Attention, Multi-head Attention]
toc: true
toc_sticky: true
toc_label: "쭌스log"
#author_profile: false
header:
    teaser: /assets/images/posts/bert-thumbnail.png
sidebar:
    nav: "docs"
---

## Convolution Seq2Seq (ConvS2S)
![image](https://user-images.githubusercontent.com/39285147/187002178-642ad27b-b738-48c5-9eb0-1ddab54cc921.png)

### Encoder
![image](https://user-images.githubusercontent.com/39285147/186263776-3dfac63c-5ea1-4736-8e19-52dbbd40809a.png)

- *Residual Connection*: 입력 정보가 가중치 합(weight sum) 연산에 적용되고자 지름길 route를 만든다. 다음 레이어에 전이시켜 최종 출력에 영향을 줄 수 있도록 하기 위함.

> [ResNet](https://github.com/hchoi256/ai-terms/blob/main/README.md) 알아보기.

기존 RNN의 '직렬화'라는 한계점을 타파하고자 **RNN 구조를 제거**하고 몇 개의 단어 토큰으로 'Convolution'을 적용한 경우이다.

> RNN 확장 모델 LSTM으로도 무한히 많이 쌓이는 데이터 처리에 대한 RNN의 근본적인 한계점을 해결하지는 못한다.

![image](https://user-images.githubusercontent.com/39285147/186263248-1acb5a60-ae13-4df1-a1ba-cbe0d47fe9cc.png)

- Convolution Filter 개수: 순환 신경망의 레이어 간 연결선을 제거하여 **이전 출력을 기다릴 필요없이**, 상기 사진에서는 가령 3개의 단어 토큰 단위로 새로운 단어 벡터를 인풋으로 활용한다.
- 빨간색 평행사변형은 'go', 'to', 'the school' 세 단어가 하나의 새로운 벡터로 변환되는 모습을 보여준다.

![image](https://user-images.githubusercontent.com/39285147/187803235-9c85f564-987d-489d-a40c-901600767c9c.png)

이러한 아키텍쳐를 구현함으로써 질적으로도 뛰어날 뿐 아니라, 계산의 **병렬화**를 가능하게 하여 **훈련 시간의 단축**이라는 쾌거를 이루어낼 수 있었다.
- 기존 직렬화 방식은 'I' --> 'go' --> 'to' --> 'the school' 식으로 학습하면서 최종적으로 이전 단어 맥락을 전부 고려하는 context vector를 만든다.

![image](https://user-images.githubusercontent.com/39285147/187803537-dee60d19-98e6-4caa-979f-f3a9be6d62e2.png)

상기 사진에서, ①은 Attention Weight를 구할 때 사용되는 부분으로, Softmax 이후 Attention Weights가 도출되는 모습이다.

또한, ②은 ①에서 얻은 Attention Weights에 각 단어 토큰에 대한 지름길 route를 통하여 가중합을 구할 때 사용된다.

### Decoder
하나의 time step에서 디코딩을 할 때, 이전 단계의 decoder에서 얹어준 hidden state vector, 생성 단어 토큰, 그리고 인코더에서 계산된 attention weights를 입력으로써 활용한다.

![image](https://user-images.githubusercontent.com/39285147/187806286-f4f722e6-4e15-4811-8ff4-d6c7de7a2212.png)

- Decoder들의 hiddens state vector에 인코더처럼 합성곱 연산을 취한다 ![image](https://user-images.githubusercontent.com/39285147/187806394-b73d772a-50bb-4c75-a3e8-2b1c11866f39.png)
- *노란색 박스*: 가중치가 가장 높은 단어 토큰을 의미한다 ![image](https://user-images.githubusercontent.com/39285147/187806363-3583876e-8617-47d7-ad40-6814263c501f.png)
- 인코더에서 계산된 출력값 (*encoding vectors*) ![image](https://user-images.githubusercontent.com/39285147/187806450-19811752-ff33-478e-8505-7ab676c389cd.png)
- 현 time step 디코더 hidden state vector 가중치 ![image](https://user-images.githubusercontent.com/39285147/187806528-3e392bcf-7d38-48d2-92ab-2b643c8fc96e.png)
- 현 time step 단어 토큰을 대표하는 hidden state vector ![image](https://user-images.githubusercontent.com/39285147/187806336-ac45f014-9b1d-4026-968a-cea3e6a5b355.png)
- 인코더처럼 Concat하는 것이 아니라 Sum한다 ![image](https://user-images.githubusercontent.com/39285147/187806574-bbe103a9-4435-4e34-a57e-edd488431423.png)

****
# Self-attention 모델
![image](https://user-images.githubusercontent.com/39285147/185520452-e27a130d-510f-4d3a-a12d-adea5378a164.png)

RNN의 시계열 학습에서 벗어나 Attention 구조만으로 학습에 임한다.

Decoder 해석에 용이한 방향으로 가중치 업데이트를 하는 것이 아닌 **input 그 자체를 가장 잘 표현하기 위한 방향으로 학습하는 방식**으로 동작한다.

![image](https://user-images.githubusercontent.com/39285147/183540623-c662b029-b65d-493c-8501-6edbcf8139c8.png)

**인코더 내부에서 인코더 한 토큰을 재구성**하는 개념이다.
- **Query, Key, Value가 동일한 시퀀스**를 가진다.

![image](https://user-images.githubusercontent.com/39285147/183540697-a5e884be-56b5-4c34-9b87-95f8f4eacf7f.png)

- Score = Query와 Key 내적

최종적으로, softmax와 value를 곱한 값의 합계를 도출하여 해당 단어가 가진 전체적인 의미를 설명한다.

이러한 과정을 단어마다 각각 수행한 것이 바로 self-attention 모델로, 하기 도표를 통해 직관적으로 이해해보자.

![image](https://user-images.githubusercontent.com/39285147/183540713-da495ca0-9f6e-4584-a701-b6c402576c87.png)

****
# Multi-head Attention 모델
하나의 Attention 모델은 각 단어 토큰의 가중치만을 도출하기에, 다른 단어와 어떻게 연관되어있는지 잘 훈련이 안될수도 있다.

따라서 여러개의 어텐션, 즉 Multi-head Attention을 이용하여 이를 하나로 이어붙여서 연관성을 탐구한다.

여러 번의 Self-attention을 **병렬처리**로 수행하여 **빠른 속도**를 끌어낸 것이 바로 **multi-head attention**이다.


이제 [**Transformer**](https://hchoi256.github.io/nlp/bert-4/)에 대해 알아보자.

# Reference
[Deep Learning for NLP - KAIST 주재걸 교수님](https://www.youtube.com/watch?v=JqkfT1s60cI&list=PLep-kTP3NkcOjOS1a30UNW-tH2FSoGYfg&index=1)