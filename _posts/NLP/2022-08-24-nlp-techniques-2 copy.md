---
layout: single
title: "PART 2: ConvS2S, Self-Attention, Transformer"
categories: NLP
tag: [NLP, ConvS2S, Self-Attention, Transformer]
toc: true
toc_sticky: true
toc_label: "쭌스log"
#author_profile: false
header:
    teaser: /assets/images/posts/seq2seq.png
sidebar:
    nav: "docs"
---

이제 Trnasformer 기반 언어 모델인 [BERT](https://hchoi256.github.io/bert/bert-1/)에 대하여 알아볼 준비를 마쳤다.
