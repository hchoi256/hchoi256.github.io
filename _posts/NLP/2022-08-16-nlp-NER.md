---
layout: single
title: "NLP - Part 6: Name Entity Recognition (NER) 앱"
categories: NLP
tag: [NLP, NER]
toc: true
toc_sticky: true
toc_label: "GITHUB BLOG JJUNS"
#author_profile: false
header:
    teaser: /assets/images/posts/nlp-thumbnail.jpg
sidebar:
    nav: "docs"
---

# 사전 설정

```python
% pip install spacy spacy_streamlit
% python -m spacy download en_core_web_trf
```

1) 하나하나 직접 입력!
   -> 노동력이 필요
   -> 시간도 필요
   -> 실수가 있을 수 있다.
   -> 입력 도중에 값이 변할 수도 있다.

2) Copy & Paste 로 할 때 총 1640번의 반복작업을 해야한다.
    붙여넣기 하고 정리가 필요하다!

3) 최후의 수단 웹 크롤링(Web Crawling)을 하자!
   -> 반복을 내가 하기 싫다!
   -> 매일 정해진 시간에 하고 싶다
   -> 수집한 후에 데이터베이스든 엑셀파일이든 저장하고 싶다


웹 크롤링 (Web Crawling) :
  => 내가 수집하고자 하는 데이터가 있는 서버에 접속해서 해당 웹페이지의 소스코드를 가져오는 행위
  => 반복적인 일도 있고, 페이지 이동, 로그인 등등이 필요하다.
  => 컴퓨터는 시킨 일에 대해서 빠르게 반복적으로 잘 한다.
  => 해당 서버 모니터링 중 자주 빠르게 반복적으로 접근하는 IP를 차단
  
웹 스크래핑 (Web Scraping) :
  => 원하는 데이터가 있는 웹페이지에서 원하는 데이터를 추출하는 행위

각 웹사이트마다 
https://www.[웹사이트 주소]/robots.txt


```python
% pip install beautifulsoup4
```

