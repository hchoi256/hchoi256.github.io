---
layout: single
title: "[ë…¼ë¬¸ë¶„ì„] Teaching Assistant Knowledge Distillation"
categories: LightWeight
tag: [Model Compression, Light-weight, Knowledge Distillation]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/qntzn.png
sidebar:
    nav: "docs"
---

[ë…¼ë¬¸ë§í¬: XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks](https://arxiv.org/abs/1603.05279)

****
# í•œì¤„ìš”ì•½ âœ”
- XNOR Netì´ë€ **Weightê³¼ inputì— ëŒ€í•œ binarization ìˆ˜í–‰ì„ í†µí•´ Convolutions ì—°ì‚°ì„ binary operationsìœ¼ë¡œ ëŒ€ì²´**í•˜ì—¬ 58ë°° ë¹ ë¥¸ í•©ì„±ê³± ì—°ì‚° ì†ë„ì™€ 32ë°° memory saving íš¨ê³¼ë¥¼ ê±°ë‘” ë„¤íŠ¸ì›Œí¬ì´ë‹¤.
- ìµœì´ˆë¡œ ImageNet ë¶„ë¥˜ í‰ê°€ ì§„í–‰
- CPU ì‚¬ìš©
- Binarized Neural Network 2016ê³¼ ë¹„êµí•´ì„œ inputë„ binary í‘œí˜„í•œë‹¤ëŠ” ì ì—ì„œ ì°¨ì´

****
# Introduction ğŸ™Œ
![image](https://user-images.githubusercontent.com/39285147/218665627-4e7bdfd9-c7b4-42a2-ae73-a87442b56267.png)

BinaryNetì€ binarized weightsì™€ binarized activationsì„ í™œìš©í•œ `BinaryConnect`ë¥¼ ì¶œì‹œí•œë‹¤.

í•˜ì§€ë§Œ, `BinaryConnect`ëŠ” small datasetì— ëŒ€í•´ì„œë§Œ SOTA ì„±ëŠ¥ì„ ë‹¬ì„±í•˜ê³  large datasetì—ëŠ” ë‚®ì€ ì •í™•ì„±ì„ ë³´ì—¬ì¤¬ë‹¤.

í•´ë‹¹ ë…¼ë¬¸ì—ì„œ ì œì•ˆëœ XNOR NETì€ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡° ë° binarization method ìì²´ë¥¼ ë³€ê²½í•˜ì—¬ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.

****
# Definition âœ
            `Given` a pre-trained FP32 model
            `Returns` a (mixed-)binarized model
            `Preserving` the accuracy of the original model with higher inference speed

****
# Proposed Method ğŸ§¿
## XNOR ì—°ì‚°
![image](https://user-images.githubusercontent.com/39285147/218667767-97aa66a1-83a9-4266-8c2a-048f823de249.png)

Binary ê°’ë“¤ë¡œ í‘œí˜„ëœ í–‰ë ¬ ê°„ì˜ í•©ì„±ê³± ì—°ì‚°ì€ ê°„ë‹¨í•˜ê²Œ **XNOR ì—°ì‚°**ìœ¼ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤.

XNOR ì—°ì‚°ì—ëŠ” í–‰ë ¬ ê³±ì…ˆì´ ìˆ˜ë°˜ë˜ì§€ ì•Šì•„ì„œ Costê°€ í›¨ì”¬ ì ˆì•½ëœë‹¤.

## XNOR Net
XNOR-Netì€ inputê³¼ weightsì— ëŒ€í•˜ì—¬ binarizationì„ ìˆ˜í–‰í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ì´ë‹¤.

$$X^TW\approx \beta H^T \alpha B$$

$$(H=binarized input_X,\ B = binarized W,\ \alpha= scale factor for W,\ \beta=scale factor for X)$$

ìƒê¸° ì‹ì—ì„œ $$X^TW$$ëŠ” hidden nodesë¥¼ êµ¬í•˜ëŠ” ìˆœì „íŒŒ ê³¼ì •ì„ ë‚˜íƒ€ë‚¸ë‹¤.

$$\alpha^*,H^*,\beta^*,B^*=argmin_{\alpha,H,\beta,B}||X\odot W-\beta \alpha H \odot B||$$.

`argmin`ì„ ì·¨í•˜ì—¬ ì‹¤ì œê°’($$X\odot W$$)ê³¼ ì˜ˆì¸¡ê°’($$\beta \alpha H \odot B$$)ì˜ ì°¨ì´ê°€ ìµœì†Œê°€ ë˜ëŠ” í”¼ë¼ë¯¸í„°ë“¤ì„ êµ¬í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

> ì‹¤ì œ ê³„ì‚°ì€ $$||\cdot||$$ì„ ë¯¸ë¶„í•œ ê°’ì„ 0ì´ ë˜ê²Œ ë§Œë“œëŠ” í”¼ë¼ë¯¸í„°ë“¤ì„ êµ¬í•˜ë©´ ëœë‹¤.

![image](https://user-images.githubusercontent.com/39285147/218670838-6a159169-6fe1-4750-8771-549d877e60ef.png)

ê·¼ë° í•©ì„±ê³±ì€ ê²¹ì³ì§€ëŠ” ë¶€ë¶„ì—ì„œ ì¤‘ë³µ ì—°ì‚°ì´ ë§ì´ ë°œìƒí•˜ê¸° ë•Œë¬¸ì—, channel wise ì •ë³´ë“¤ì˜ í‰ê· ê°’ì„ scale factorsë¡œ í™œìš©í•œë‹¤.

$$\alpha^* \beta^*=(\frac{||X||_{l1}}{n})(\frac{||W||_{l1}}{n})$$.

$$H^*\odot B^*=sign(X) \odot sign(W)$$.

## Modified Block Order
![image](https://user-images.githubusercontent.com/39285147/218672068-70c43d4c-65d9-478e-8df0-863778af3e52.png)

Binary Activiation ì´í›„ binary input ë§Œë“¤ì–´ì§€ëŠ”ë°, ê·¸ ê°’ë“¤ì´ maxpoolì— ë“¤ì–´ê°€ë©´ outputì´ ëŒ€ë¶€ë¶„ 1ì´ ëœë‹¤.

í•˜ì—¬ block ìˆœì„œë¥¼ ë’¤í‹€ì–´ convolution ì´í›„ non-binary ê°’ì„ maxpoolì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ë©´ ì •ë³´ë¥¼ ë§ì´ ì•„ë‚„ ìˆ˜ ìˆë‹¤.

****
# Experiment ğŸ‘€
![image](https://user-images.githubusercontent.com/39285147/218671986-23680735-2957-4e5b-8468-04d680afa3d4.png)

****
# Conclusion âœ¨
![image](https://user-images.githubusercontent.com/39285147/218671945-067d603d-3adc-425f-ab01-27b1cd83c26e.png)

****
# Reference ğŸ’•