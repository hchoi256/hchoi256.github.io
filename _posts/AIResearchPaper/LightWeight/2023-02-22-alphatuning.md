---
layout: single
title: "[ë…¼ë¬¸ë¶„ì„] AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models"
categories: Others
tag: [Model Compression, AlphaTuning, Quantization, Pruning]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
author_profile: false
header:
    teaser: /assets/images/posts/qntzn.png
sidebar:
    nav: "docs"
---

[ë…¼ë¬¸ë§í¬](https://arxiv.org/pdf/2210.03858.pdf)

****
# í•œì¤„ìš”ì•½ âœ”

****
# Background ğŸ±
Self-supervised Learningì˜ ë“±ì¥ìœ¼ë¡œ, ë°ì´í„° í™•ë³´ê°€ ì‰¬ì›Œì§ì— ë”°ë¼ ì¦ê°€í•œ ë°ì´í„° ê°œìˆ˜ë§Œí¼ ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆ(parameter ê°œìˆ˜) ë˜í•œ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

í˜„ ì‹œì ì—ì„œ Transformerì˜ ë§‰ê°•í•œ powerì„ ë•íƒì— AI ì „ë°˜, íŠ¹íˆ NLP ë¶„ì•¼ì— ë§ì€ ë°œì „ì´ ì‡ë”°ë¥´ê³ , ê±°ëŒ€ ì–¸ì–´ëª¨ë¸ì— ëŒ€í•œ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ì˜€ë‹¤.

í•˜ì—¬ ë³¸ ë…¼ë¬¸ ë˜í•œ ì–¸ì–´ëª¨ë¸ ì••ì¶•ì„ targetìœ¼ë¡œ ì‚¼ëŠ”ë‹¤.

ëª¨ë¸ì••ì¶• ì™¸ì—, zero/few-shot learning ê¸°ë°˜ ê¸°í•™ìŠµ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì˜ ì „ì ì—ë„ ë¶ˆêµ¬í•˜ê³ , ê¸°í•™ìŠµ ëª¨ë¸ training ì´í›„ fine-tuningì´ë¼ëŠ” ìƒˆë¡œìš´ adaptation ê³¼ì •ì€ downstream task ì„±ëŠ¥ í–¥ìƒì— ìˆì–´ì„œ í•„ìˆ˜ì ì´ë‹¤.

> ê° downstream taskë§ˆë‹¤ ë…ë¦½ì ì¸ ê°ê°ì˜ adaptation ì„±ëŠ¥ ê²°ê³¼ë¥¼ ë³´ì¸ë‹¤.

í•˜ì—¬ ë‹¤ì–‘í•œ downstream taskì— ë²”ìš©ì ìœ¼ë¡œ ì¢‹ì€ ì„±ëŠ¥ì„ ëŒì–´ë‚¼ ìˆ˜ ìˆëŠ” parametersë§Œì„ fine-tuning ëŒ€ìƒìœ¼ë¡œ ì‚¼ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤ (`parameter-efficient adaptation techniques`).
- Adapter modules, low-rank adapatino, prefix-tuning, etc.

í•˜ì§€ë§Œ, ë³¸ ë…¼ë¬¸ì€ trainiable parameter ê°œìˆ˜ ìì²´ëŠ” ìƒê¸° ë°©ì‹ë“¤ë¡œ ì¤„ì¼ ìˆ˜ ìˆìœ¼ë‚˜, ê·¸ë“¤ì´ ê¸°í•™ìŠµ ëª¨ë¸ì— ë¹„í•´ fine-tuned modelì˜ inference ì„±ëŠ¥ì´ ê·¸ë‹¤ì§€ ì¢‹ì§€ ì•Šë‹¤ëŠ” ì ì„ ê°•ì¡°í•œë‹¤.

ë˜í•œ, í˜„ì¡´í•˜ëŠ” ëª¨ë¸ì••ì¶• ê¸°ìˆ ë“¤ì€ ë°˜ëŒ€ë¡œ parameter-efficient adapation ê¸°ë²•ì„ í™œìš©í•˜ì§€ ì•Šë‹¤ëŠ” ì ì„ ê°•ì¡°í•œë‹¤.

ê°€ë ¹, ê¸°ì¡´ ì••ì¶• ê¸°ë²•ì¸ QATì˜ ê²½ìš°, fine-tuningê³¼ ëª¨ë¸ì••ì¶•ì„ í•¨ê»˜ ì‚¬ìš©í•œ ì ‘ê·¼ë²•ì´ì§€ë§Œ, ê¸°í•™ìŠµ ëª¨ë¸ ë§Œí¼ì˜ memory storageë¥¼ í•„ìš”ë¡œ í•œë‹¤.

****
# Introduction ğŸ™Œ
ìµœê·¼ ì´ˆê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ì— ëŒ€í•œ ê´€ì‹¬ë„ê°€ ë‚˜ë‚ ì´ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ ì†ì—ì„œ, ì–´ë–»ê²Œ ëª¨ë¸ì˜ ì¶”ë¡  ì†ë„ë¥¼ ì •í™•ë„ë¥¼ í•´ì¹˜ì§€ ì•Šìœ¼ë©´ì„œ ë†’ì¼ ìˆ˜ ìˆëŠ” ì§€ì— ëŒ€í•œ ë§ì€ ì—°êµ¬ê°€ ì´ë¤„ì§€ê³  ìˆë‹¤.

ì´ëŸ¬í•œ ê´€ì‹¬ì—ë„ ë¶ˆêµ¬í•˜ê³ , í•´ë‹¹ ë¶„ì•¼ëŠ” ì•„ì§ ë°í˜€ì§€ì§€ ì•Šì€ ê²ƒë“¤ì´ ë„ˆë¬´ ë§ë‹¤.

í•˜ì—¬ ë³¸ ë…¼ë¬¸ì€ `model compression`ê³¼ `parameter-efficient adaptation` ê¸°ìˆ ì„ ê²°í•©í•œ ìƒˆë¡œìš´ ë°©ì‹ì¸ compression-aware parameter-efficient ê¸°ë²•ì¸ **AlphaTuning**ì„ ì œì‹œí•œë‹¤.

> `Parameter-efficient tuning`
>
>> ë” ì ì€ íŒŒë¼ë¯¸í„°ë§Œì„ í•™ìŠµí•˜ì—¬ downstream taskì— ëŒ€í•´ì„œ fine-tuningê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë‚´ëŠ” ê²ƒì´ë‹¤.

í•´ë‹¹ ê¸°ìˆ ì€ ê¸°í•™ìŠµ ëª¨ë¸ì— ëŒ€í•œ post-training quantizationê³¼ ì–‘ìí™”ëœ ëª‡ëª‡ì˜ parametersë“¤ì— ëŒ€í•´ì„œë§Œ target taskì— fine-tuningì‹œí‚¨ë‹¤.

AlphaTuningì€ binary-coding quantizationì„ ìˆ˜í–‰í•˜ë©°, adaptation ë‹¨ê³„ì—ì„œëŠ” binary ê°’ë“¤ì„ freezeí•˜ê³  scaling factorsë“¤ë§Œ fine-tuningì„ ì§„í–‰í•œë‹¤.

> `Binarization` ê°œë…ì´ ì–´ìƒ‰í•˜ë‹¤ë©´, [ì—¬ê¸°](https://hchoi256.github.io/aipaperlightweight/xnor-net/)ë¥¼ ì°¸ì¡°í•˜ê¸¸ ë°”ë€ë‹¤.

ë³¸ ë…¼ë¬¸ì´ ì œì‹œí•œ AlphaTuning ê¸°ë²•ì€ GPT-2ì™€ OPT ì ìš© ì‹œ, 4-bit quantization í™œìš© 10ë°° ì••ì¶• ë° 1000ë°°ì˜ parameter ê°œìˆ˜ ê°ì†Œ íš¨ê³¼ë¥¼ ë³´ì—¬ì¤€ë‹¤.

> GPTëŠ” ë‹¤ë“¤ ì•Œê³  ê³„ì‹¤í…Œê³ , OPTëŠ” Metaì—ì„œ ì„ ë³´ì¸ ì´ˆê±°ëŒ€ ì–¸ì–´ ëª¨ë¸ë¡œ ê°€ì¥ ìµœì‹  ë²„ì „ì˜ í•´ë‹¹ ëª¨ë¸ì€ 1750ì–µê°œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì´ìš©í•œë‹¤.

![image](https://user-images.githubusercontent.com/39285147/220860698-05776ad1-d788-422f-a4e0-5cf52b53fcef.png)

ëª¨ë¸ì••ì¶•ê³¼ parameter-efficient adaptationì„ ìˆ˜í–‰í•˜ëŠ” ì ‘ê·¼ë²•ì€ ë‘ ê°€ì§€ê°€ ìˆë‹¤.

ìƒê¸° ì´ë¯¸ì§€ì—ì„œ, ê¸°ì¡´ ì ‘ê·¼ë²•ì€ $$A \rightarrow C \rightarrow D$$ ìˆœì„œì— í•´ë‹¹í•˜ë©°, ë§ì€ trainable parameters ë° PTQ ì‹œ downstream tasks ì„±ëŠ¥ ê°ì†Œê°€ í•œê³„ë¡œ ê¼½íŒë‹¤.

í•˜ì—¬ ë³¸ ë…¼ë¬¸ì€ ìƒˆë¡œìš´ ì ‘ê·¼ë²• $$A\rightarrow B \rightarrow D$$ì„ ì œì‹œí•˜ê³ , í•´ë‹¹ ì ‘ê·¼ë²•ì„ **AlphaTuning**ì´ë¼ ëª…ì¹­í•œë‹¤.

AlphaTuningì€ (1)ì£¼ì–´ì§„ parametersì„ `binary values`ì™€ `scaling factors`ë¡œ factorizationì„ ìˆ˜í–‰í•œë‹¤.
- scaling factorsëŠ” quantization formatsì—ì„œ ì•„ì£¼ ì‘ì€ ë¶€ë¶„ë§Œì„ ì°¨ì§€í•œë‹¤.

ì´í›„, (2)binary valuesëŠ” freezeí•˜ê³ , ì‘ì€ ë©”ëª¨ë¦¬ ë¶€ë¶„ë§Œì„ ì°¨ì§€í•˜ëŠ” scaling factorsì— ëŒ€í•´ì„œë§Œ fine-tuningì„ ì§„í–‰í•˜ì—¬ ì¶”ë¡  ì†ë„ë¥¼ accelerateí•œë‹¤.

$$A \rightarrow B$$ ê³¼ì •ì€ QAT ëŒ€ì‹  PTQë¥¼ ìˆ˜í–‰í•œë‹¤; QATëŠ” ë°©ëŒ€í•œ ë°ì´í„°ì…‹ì— ëŒ€í•´ í›ˆë ¨ ì‹œ computational overheadê°€ ì—„ì²­ë‚˜ë‹¤.

<span style="color:blue"> QAT ê²½ìš° overhead ì¤„ì¼ ìˆ˜ë§Œ ìˆë‹¤ë©´, PTQë¥¼ ëŒ€ì²´í•´ë„ ì¢‹ì„ê¹Œ?</span>

****
# Related Work ğŸ˜‰
## Large-Scale Language Models and Quantization
ê¸°í•™ìŠµ Transformer ì–¸ì–´ëª¨ë¸ì€ ê¸°ì¡´ì˜ NLP ë””ìì¸ ë° ë°°í¬ ë°©ì‹ì„ ì „ë©´ì ìœ¼ë¡œ ë³€í™”ì‹œì¼°ë‹¤.

ìµœê·¼ì—, ì´ˆê±°ëŒ€ ì–¸ì–´ëª¨ë¸ì— ëŒ€í•œ í™•ì¥ëœ ì ‘ê·¼ì„±ì€ ìƒˆë¡œìš´ ìì—°ì–´ ì²˜ë¦¬ì˜ ì‹œëŒ€ë¥¼ ì—´ì—ˆê³ , few-shot learningê³¼ parameter-efficient adapation ê°™ì€ ê¸°ìˆ ì˜ ì¬ë°œê²¬ì„ ëŒì–´ë‚¸ë‹¤.

Quantizationì€ ê·¼ë³¸ì ì¸ ì´ˆê±°ëŒ€ ì–¸ì–´ëª¨ë¸ì— ëŒ€í•œ ê³µê°„ ë° ê³„ì‚° ì‹œê°„ íš¨ìœ¨ í•´ê²°ì±…ìœ¼ë¡œ ì†ê¼½íˆê³  ìˆì§€ë§Œ, ê¸°ì¡´ ë°©ë²•ë“¤ì€ ì–‘ìí™”ëœ ìƒíƒœì—ì„œ ì œí•œëœ ì˜ì—­ê³¼ task adapationabilityë¥¼ ì œê³µí•˜ëŠ” í•œê³„ë¥¼ ì§€ë‹ˆê³  ìˆì—ˆë‹¤.

## Parameter-Efficient Adaptation of LMs
ì´ˆê±°ëŒ€ ëª¨ë¸ë“¤ì´ íŒì„ ì¹˜ëŠ” í˜„ ì‹œì ì—ì„œ ì–¸ì–´ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ downstream taskì— adaptingí•˜ëŠ” ê²ƒì€ ì´ ì‚¬íšŒì˜ ìµœê³  ê´€ì‹¬ì‚¬ì´ë‹¤.

í•œ ê°€ì§€ ì „ë„ìœ ë§í•œ ì ‘ê·¼ë°©ì‹ì€ (1)`in-context learning (ICL)`ë¼ëŠ” ê²ƒì¸ë°, ì´ê²ƒì€ ì£¼ì–´ì§„ prompt ëŒ€í•œ íŒ¨í„´ë“¤ë¡œ ë¶€í„° ë°°ìš°ê³  ì˜ˆì¸¡í•˜ëŠ” ì–¸ì–´ëª¨ë¸ì´ë‹¤.

í•´ë‹¹ ê¸°ë²•ì€ ì´ˆê±°ëŒ€ ì–¸ì–´ëª¨ë¸ë“¤ì— ëŒ€í•˜ì—¬ parameter-tuning ì—†ì´ í•©ë¦¬ì ì¸ few-shot ì„±ëŠ¥ì„ ëŒë‚´ê³ , ìˆ˜ë§ì€ í™•ì¥ ì—°êµ¬ë“¤ì´ íƒ„ìƒí•´ì™”ë‹¤.

ë˜ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œëŠ” (2)parameter-efficient LM adapationì„ ìœ„í•´ ì™¸ë¶€ í˜¹ì€ ë¶€ë¶„ì ìœ¼ë¡œ ë‚´ë¶€ parameters (i.e., continuous prompt embeddings)ë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì¸ë°, ì´ê²ƒì€ íŠ¹ì • prompt prefixesê°€ ë” ë‚˜ì€ íŠ¹ì • LM í–‰ë™ ë°©ì‹ì— ê´€ì—¬í•  ìˆ˜ ìˆë‹¤ëŠ” ì•„ì´ë””ì–´ì—ì„œ ì°©ì•ˆí•œë‹¤.

> `Continuous/soft prompts`
>
>> Additional learnable parameters injected into the model

ê³¼ê±° ì—°êµ¬ë“¤ì€ **discrete** prompt token spaceë¥¼ ì¡°ì‚¬í–ˆì§€ë§Œ, ì´í›„ **continuous** work embedding spaceë¥¼ ìµœì í™”í•˜ëŠ” ê²ƒì´ ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤¬ë‹¤.

> Prompt tuningê³¼ ê´€ë ¨í•œ ë” ìì„¸í•œ ë‚´ìš©ì€ [P-tuning](https://velog.io/@seopbo/GPT-Understands-Too) ê¸°ë²•ì„ ì°¹ì¡°í•˜ê¸° ë°”ë€ë‹¤.
>
>> `P-tuning`ì€ ê¸°í•™ìŠµ ì–¸ì–´ëª¨ë¸ì˜ ëª¨ë“  weightë¥¼ fine-tuningí•˜ì§€ ì•Šê³ , `continuous prompt embeddings`ë§Œ tuningí•˜ëŠ” ë°©ë²•ì´ë‹¤.

(3)ë˜ ë‹¤ë¥¸ ì—°êµ¬ë¡œëŠ” ìƒˆë¡œìš´ parametersë“¤ì„ Transformer blocksì´ë‚˜ ë¶€ë¶„ì ìœ¼ë¡œ ê¸°ì¡´ parametersì„ í›ˆë ¨ì‹œí‚¤ê¸°ë„ í•˜ë©°, (4)ë§ˆì§€ë§‰ìœ¼ë¡œëŠ” parameter-efficient fine-tuning ë°©ì‹ê³¼ ê´€ë ¨ëœ ëª¨ë“  ê¸°ì¡´ ì ‘ê·¼ ë°©ì‹ë“¤ì„ í†µí•©í•˜ê¸°ë„ í–ˆë‹¤.

****
# Problem Definition âœ
                Given a large pre-trained language model

                Return a quantized model

                Such that it outperforms the performance of the original model in terms of inference time while retaining accuracy.

****
# Major Takeaways ğŸ˜ƒ
- First successful compression-aware parameter-efficient adaptation method
- Only scaling factors (0.1% of the model size) are enough for successful adaptations
- High scores even under 4-bit quantization throughout various LMs and downstream tasks

****
# Challenges and Main IdeağŸ’£
**C1)** Accelerating a large LM using binarization is accompanied by a non-trivial reduction in accuracy.

**C2)** How can we wisely remove many redundant parameters in the adaptation phase?

**C3)** What is the ace in the hole for the combination of model compression and parameter-efficient techniques without sacrificing memory storage?

**Idea)** Freezes all binarized parameters while just fine-tuning its scaling factor.

****
# Proposed Method ğŸ§¿
## Quantization for AlphaTuning
### BCQ Format

### Transformer Quantization

## AlphaTuning: Efficient Fine-Tuning of Quantized Models
### AlphaTuning Principles

### Training Algorithm

## AlphaTuning for GPT-2
### Adaptation Details

### Comparison with Fine-Tuning and LoRA

### Comparison with $$A \rightarrow C \rightarrow D in Figure 1.

### Hyper-Parameter Selection

****
# Experiment ğŸ‘€
## GPT-2 Models on DART and E2E
## OPT Models on MNLI and SAMSum

****
# Open Reivew ğŸ’—

****
# Discussion ğŸŸ
## Memory during Adaptation

## Embedding Layers

## Inference Speed


****
# Conclusion âœ¨

****
# Reference
[P-tuning](https://velog.io/@seopbo/GPT-Understands-Too)