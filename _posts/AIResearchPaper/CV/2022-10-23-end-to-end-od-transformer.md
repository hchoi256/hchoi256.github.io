---
layout: single
title: "[ë…¼ë¬¸ ë¶„ì„] End-to-End Object Detection with Transformers (ECCV 2020)"
categories: AIPaperCV
tag: [Computer Vision, Object Detection, Transformer]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/od.png
sidebar:
    nav: "docs"
---

[**ë…¼ë¬¸**](https://link.springer.com/content/pdf/10.1007/978-3-030-58452-8_13.pdf)

****
# ë°°ê²½ ğŸ™Œ
**Object detection**ì€ Classificationê³¼ Localizationì„ í•©ì¹œ ê²ƒìœ¼ë¡œ, ì‚¬ì§„ì† ê°ì²´ì— ëŒ€í•´ í´ë˜ìŠ¤ ë¶„ë¥˜ì™€ bounding box ìœ„ì¹˜ë¥¼ í‘œí˜„í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤.

ì´ì „ ê°ì²´íƒì§€ ë°©ë²•ë“¤ì€ ì‚¬ì§„ì† ê°ì²´ê°€ ì¡´ì¬í•  ê²ƒ ê°™ì€ í›„ë³´ì˜ì—­ì„ ì°¨ì¶œí•˜ê¸° ìœ„í•´ *ê°„ì ‘ì ì¸ ë°©ë²•*ìœ¼ë¡œ ê°ì²´ íƒì§€ë¥¼ êµ¬í˜„í–ˆë‹¤.
- Two-stage (ì†ë„ ëŠë¦¼, ì •í™•ì„± ì¢‹ìŒ):
    - **RCNN, Fast RCNN**: Selective Search
    - **Faster RCNN**: Sliding window, Anchor boxes, RPN
- One-stage (ì†ë„ ë¹ ë¦„, ì •í™•ì„± ë‚˜ì¨):
    - **YOLO**: grid division

> **Non-Maximum Suppression**
>> ![image](https://user-images.githubusercontent.com/39285147/197414699-970639a6-076d-4b2b-b1de-763931c9082e.png)
>>
>> object detectorê°€ ì˜ˆì¸¡í•œ bounding box ì¤‘ì—ì„œ ì •í™•í•œ bounding boxë¥¼ ì„ íƒí•˜ë„ë¡ í•˜ëŠ” ê¸°ë²•
>>
>> ê°ì²´ë³„ ê°€ì¥ ë†’ì€ ì˜ˆì¸¡ í™•ë¥ ì„ ë³´ì¸ bounding boxë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µë˜ëŠ” ë‹¤ë¥¸ boxesë¥¼ ì œê±°í•˜ëŠ” ê¸°ë²•. 

ì´ëŸ¬í•œ ê°„ì ‘ì ì¸ ë°©ë²•ë“¤ì€ *í›„ì²˜ë¦¬*(ì˜¤ì°¨ ì˜ˆì¸¡ ë° ì œê±°)ì— ë§‰ëŒ€í•˜ê²Œ ì˜í–¥ì„ ë°›ëŠ”ë‹¤.

ë•Œë¬¸ì— ê¸°ì¡´ ëª¨ë¸ë“¤ì€ ì—¬ëŸ¬ ê°€ì§€ ë³µì¡í•œ ì˜ˆì¸¡ ë¬¸ì œì— ëŒ€í•œ ê°ì²´ íƒì§€ ë¬¸ì œì—ì„œ í•œê³„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.

ì´ëŸ¬í•œ ê°„ì ‘ì ì¸ pipeline(ê³¼ì •)ì—ì„œ ì •í™•í•œ ê²°ê³¼ë¥¼ ë‚¼ ìˆ˜ ì—†ì–´ NMSê°™ì€ ì¶”ê°€ì ì¸ í›„ì²˜ë¦¬ì˜ í˜ì„ ë¹Œë¦¬ëŠ” surrogate tasksë¥¼ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ê²ƒì´ **direct set prediction ë°©ë²•**ì´ë‹¤.

> **Surrogate**: outputì´ ì •í™•íˆ ì¸¡ì •ë  ìˆ˜ ì—†ì„ ë•Œ, ëŒ€ì‹  output ê¸°ì¤€ì„ ì œê³µí•œë‹¤.

ìš°ë¦¬ê°€ í”íˆ ì•„ëŠ” ì§‘í•©(set)ì€ í•˜ë‚˜ì˜ ì§‘í•© ì•ˆì— ì¤‘ë³µë˜ëŠ” ìš”ì†Œê°€ ì—†ê³  ìˆœì„œì˜ ì œì•½ì´ ì—†ëŠ” ê²ƒì´ íŠ¹ì§•ì´ë‹¤.

Direct set predictionì€ ì´ëŸ¬í•œ ì§‘í•©ì˜ íŠ¹ì„±ì„ ì´ìš©í•˜ì—¬, í•˜ë‚˜ì˜ ê°ì²´ì— ëŒ€í•´ ë‹¨ í•˜ë‚˜ì˜ bounding boxë§Œ ë§¤ì¹­ë˜ëŠ” ê²ƒì„ ë„ì™€ ì¤‘ë³µë˜ëŠ” boxì˜ ìƒì„±ì„ íšŒí”¼í•˜ì—¬ NMS ê°™ì€ í›„ì²˜ë¦¬ì˜ ì˜ì¡´ì„±ì—ì„œ ë²—ì–´ë‚œë‹¤.
- ìˆœì„œ ì œì•½ ì—†ìŒ: ê° ê°ì²´ë³„ ë³‘ë ¬ì„± ë³´ì¥
- ì¤‘ë³µ íšŒí”¼: ê°ì²´ë³„ ë…ë¦½ì ì¸ í•˜ë‚˜ì˜ bounding box ê°€ì§.

ì´ë²ˆ ë…¼ë¬¸ ì£¼ì œì¸ **DETR(DEtection TRansformer)**ì€ direct set prediction(bipartite matching loss) ë°©ë²•ê³¼ Transformer(non-autoregressive)ì„ ê²°í•©í•œ ë°©ë²•ì´ë‹¤.

****
# INTRODUCTION ğŸ‘€
 ![image](https://user-images.githubusercontent.com/39285147/197411640-e6c3de0f-b4f3-4665-ae05-6a0b45c90bf3.png)

## ë°°ê²½ì§€ì‹
### Bipartite matching(ì´ë¶„ë§¤ì¹­)
[*Bipartite Graph*]

![image](https://user-images.githubusercontent.com/39285147/197421855-3281f5d4-8b83-4983-b407-6f84649dbccc.png)

ì´ë¶„ ê·¸ë˜í”„ì—ì„œ A ê·¸ë£¹ì˜ ì •ì ì—ì„œ B ê·¸ë£¹ì˜ ì •ì ìœ¼ë¡œ ê°„ì„ ì„ ì—°ê²° í•  ë•Œ, **A ê·¸ë˜í”„ í•˜ë‚˜ì˜ ì •ì ì´ B ê·¸ë˜í”„ í•˜ë‚˜ì˜ ì •ì ë§Œ** ê°€ì§€ë„ë¡ êµ¬ì„±ëœ ê²ƒì´ ì´ë¶„ ë§¤ì¹­

ìƒê¸° ì´ë¶„ ê·¸ë˜í”„ì—ì„œ, ì¢Œì¸¡ì€ ì´ë¶„ ê·¸ë˜í”„ì´ì§€ë§Œ ì´ë¶„ ë§¤ì¹­ì€ ì•„ë‹ˆê³  ìš°ì¸¡ì€ ë‘˜ë‹¤ ë§ë‹¤.

- ì¤‘ë³µ íšŒí”¼
    - Transformer í•™ìŠµ ì‹œ, ground truthì™€ ë””ì½”ë”ì˜ ì¸í’‹ì¸ object queryê°€ ê°ê°ì˜ ê°ì²´ì™€ ëŒ€ì‘ë˜ëŠ” ë…ë¦½ì  ì˜ˆì¸¡ì„ ê°€ëŠ¥ì¼€ í•œë‹¤.
    - object query: ë””ì½”ë” ì¸í’‹ìœ¼ë¡œ ì¸ì½”ë” ì¶œë ¥ìœ¼ë¡œë¶€í„° ì •ë³´ë¥¼ ë°›ì•„ ì‚¬ì§„ì† ê° ê°ì²´ì— ëŒ€í•œ í´ë˜ìŠ¤ì™€ box ìœ„ì¹˜ ì •ë³´ë¥¼ í•™ìŠµí•œë‹¤.
        - ë””ì½”ë” ì¸í’‹ì¸ object qeuryì˜ ê°œìˆ˜($$N$$)ëŠ” ì‚¬ì „ì— ì§€ì •ë˜ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œì¨ ì‚¬ì§„ì†ì— ì¡´ì¬í•  ê²ƒìœ¼ë¡œ ìƒê°ë˜ëŠ” ì´ ê°ì²´ ê°œìˆ˜ë³´ë‹¤ í¬ê²Œ ì¡ëŠ”ë‹¤(ë…¼ë¬¸ì—ì„œëŠ” 100ê°œì˜ object queryë¥¼ ì‚¬ìš©).
- ìˆœì„œ ì œì•½ ì—†ìŒ
    - uniquely assigns a prediction to a ground truth object
    - ê°ì²´ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ìˆœì—´ ë¶ˆë³€(invariant) --> ê°ì²´ë³„ parallellism ë³´ì¥
        - ê°œë³„ì ìœ¼ë¡œ GT(ground truth) objectì™€ ì˜ˆì¸¡ objectì— ëŒ€í•œ lossë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ ì˜ˆì¸¡ëœ objectì˜ ìˆœì„œì— ìƒê´€ì´ ì—†ì–´ ë³‘ë ¬í™”ê°€ ê°€ëŠ¥

> **Gound-truth**
>> ![image](https://user-images.githubusercontent.com/39285147/197421710-7405f615-8cfb-40b7-bd86-3ee8f7346a96.png)
>>
>> ë°ì´í„°ì˜ ì›ë³¸ í˜¹ì€ ì‹¤ì œ ê°’ í‘œí˜„

> ì°¸ê³ ë¡œ ê¸°ì¡´ RNN ëª¨ë¸ì€ autoregressive decoding ê¸°ë°˜ì´ë¼ object ìˆœì„œê°€ ì¡´ì¬í•´ì„œ ê°ì²´ë³„ parallellismì´ ë³´ì¥ë˜ì§€ ì•ŠëŠ”ë‹¤.

### Set loss function
- ì´ë¶„ë§¤ì¹­(bipartite matching)ì„ ì˜ˆì¸¡ê°’ê³¼ GTê°’ì— ëŒ€í•´ ìˆ˜í–‰í•œë‹¤.
    - ì˜ˆì¸¡ê°’ê³¼ GTëŠ” ëª¨ë‘ (class, box ìœ„ì¹˜) í˜•ì‹ì„ ê°–ëŠ”ë‹¤.
        - box ìœ„ì¹˜ëŠ” (x,y,w,h) í˜•ì‹ìœ¼ë¡œ ì œê³µëœë‹¤; xì™€ yëŠ” boxì˜ ì¤‘ì•™ì´ê³ , wì™€ hëŠ” í•´ë‹¹ boxì˜ ê°ê° ë„ˆë¹„ì™€ ë†’ì´ì´ë‹¤.
    - DETR ëª¨ë¸ì˜ ëª©ì í•¨ìˆ˜(Hungarian algorithm)ë¡œ ì‚¬ìš©ëœë‹¤.

> [Hungarian algorithm](https://gazelle-and-cs.tistory.com/29)
>
>> ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” ì´ë¶„ ê·¸ë˜í”„(weighted bitarted graph)ì—ì„œ maximum weight matchingì„ ì°¾ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜

> **COCO**: one of the most popular object detection datasets.

****
# DETR Model âœ’
- bipartite matching loss + transformers with (non-autoregressive) parallel decoding
- **í•˜ë‚˜ì˜ CNNë¥¼ Transformer ì•„í‚¤í…ì³ì™€ ë³‘í•©** --> **ì§ì ‘ ì˜ˆì¸¡** ê°€ëŠ¥
- extra-long training schedule
- auxiliary decoding losses in the transformer

> **ìê¸°íšŒê·€(AR; Autoregressive)**: ê³¼ê±°ì˜ ì›€ì§ì„ì— ê¸°ë°˜ ë¯¸ë˜ ì˜ˆì¸¡.

## Set Prediction
**Indirect Set Prediction**
- multilabel classification (postprocessing)
    - ì‚¬ì§„ì† ê°ì²´ê°€ ì• ë§¤í•˜ê²Œ ê²¹ì³ìˆëŠ” ì˜ì—­ì˜ near-identical boxesë“¤ì€ ë¶„ë¥˜ ë¬¸ì œ í•´ê²°ì´ ì–´ë µë‹¤.

**Direct Set Prediction**
- postprocessing-free
    - *global inference schemes* model interactions between all predicted elements to avoid redundancy.
- Non-autoregressive sequence models (i.e., recurrent neural networks)
    - bipartite matching loss            
    - permutation-invariance

## Object Detection Set Prediction Loss
![image](https://user-images.githubusercontent.com/39285147/197422840-8c8770b5-895b-4c82-b967-da083a62c4df.png)

- bipartite matching loss + transformers (non-autoregressive) parallel decoding
- loss = ìµœì  bipartite matching(ì˜ˆì¸¡ê°’ ~ GT)
    - Hungarian algorithm: ìµœì  bipartite matchingì„ íƒìƒ‰í•œë‹¤.

### Hungarian algorithm
![image](https://user-images.githubusercontent.com/39285147/197422872-acf77efd-3103-4008-921c-f62aa22a13fc.png)
- $$\mathbb{1}_{\{c_i \neq \emptyset \}}$$: í´ë˜ìŠ¤ $$c_i$$ê°€ ì¡´ì¬í•˜ë©´ 1, ì•„ë‹ˆë©´ 0.
- $$\hat{p}_{\hat{\sigma}(i)}(c_i)$$: í´ë˜ìŠ¤ $$c_i$$ì„ ì˜ˆì¸¡í•  í™•ë¥ .
- $$\mathcal{L}_{box}(b_i,\hat{b}_{\hat{\sigma}(i)})$$: bounding box ì†ì‹¤ê°’.
    - $$b_i$$: i ë²ˆì§¸ GT ì •ë‹µê°’ì˜ bounding box (x,y,w,h).
    - $$\hat{b}_{\hat{\sigma}(i)}$$:  ië²ˆì§¸ object query ì˜ˆì¸¡ê°’ì˜ bounding box (x,y,w,h).

#### Bounding box loss $$\mathcal{L}_{box}$$.
![image](https://user-images.githubusercontent.com/39285147/197422932-1866e001-8086-4f89-a231-4582d8e304d2.png)
- $$L1$$: l1 normalization.
- $$\lambda$$: í•˜ì´í¼ íŒŒë¼ë¯¸í„°

> **IoU**
>> ![image](https://user-images.githubusercontent.com/39285147/197422984-634e754a-c7db-47fd-9eaa-2523296a2057.png)

## DETR Architecture
![image](https://user-images.githubusercontent.com/39285147/197422990-0d50e9ab-0866-40d2-9940-ff3ffb91fdde.png)

## 1) Backbone
- feature extraction
    - ê° ê°ì²´ì— ëŒ€í•œ íŠ¹ì§•ì´ ì•„ë‹Œ ì´ë¯¸ì§€ ì „ì²´ì— ëŒ€í•œ íŠ¹ì§• ì¶”ì¶œ.

## 2) Transformer Encoder
- Encoderì—ì„œëŠ” ì´ë¯¸ì§€ íŠ¹ì§•ë“¤ ê°„ì˜ ìƒí˜¸ ì—°ê´€ì„±ê³¼ ìœ„ì¹˜ ì •ë³´ì— ëŒ€í•œ ë¬¸ë§¥ ì •ë³´ ì´í•´í•œë‹¤.
- CNN ì¶œë ¥ì„ flattení•˜ì—¬ 1ì°¨ì›ì˜ Transformer ì¸ì½”ë” ì¸í’‹ í˜•ì‹ìœ¼ë¡œ ë§ì¶°ì¤€ë‹¤.
- ê¸°ì¡´ transformer encoderì— **positional encoding** ì¶”ê°€
    - ë•ë¶„ì— autoregressiveì™€ ë‹¤ë¥´ê²Œ ì¸í’‹ ìˆœì„œ ìƒê´€ ì•ˆ ì¨ë„ë¨

## 3) Transformer Decoder
**ê¸°ì¡´ Transformer Decoder**
- autoregressive (output sequenceë¥¼ ***í•˜ë‚˜í•˜ë‚˜*** ë„£ì–´ì£¼ëŠ” ë°©ì‹) 
- pairwise interactions between elements in a sequence
- duplicate predictions ì œê±° ê°€ëŠ¥

**ìƒˆë¡œìš´ Transformer Decoder**
- **í•œë²ˆì—** $$N$$ê°œì˜ obejctë¥¼ ë³‘ë ¬ ì˜ˆì¸¡.
    - 1) Input embedding
        - *object query(positional encoding)* í†µí•´ í‘œí˜„ (ì´ˆê¸° ëœë¤ê°’).
    - 2) Nê°œì˜ object queryëŠ” ë””ì½”ë”ì— ì˜í•´ output embeddingìœ¼ë¡œ ë³€í™˜
    - 3) Nê°œì˜ ë§ˆì§€ë§‰ ì˜ˆì¸¡ê°’ë“¤ ì‚°ì¶œ
    - 4) self/encoder-decoderê°„ ì–´í…ì…˜ì„ í†µí•´ ê° object ê°„ì˜ global ê´€ê³„ í•™ìŠµ
        - self-attention: ê°ê°ì˜ object queryê°€ ì„œë¡œ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµë˜ë„ë¡ í•¨.
        - Encoder-Decoder Attention: ê°ê°ì˜ object queryê°€ ì‚¬ì§„ì† ê°ê°ì˜ ê°ì²´ ì •ë³´ë¥¼ í•™ìŠµí•œë‹¤. 

## 4) Prediction FFN
- FFN = linear layer1(ë°•ìŠ¤ìœ„ì¹˜íšŒê·€) --> í™œì„±í™” í•¨ìˆ˜ --> linear layer2(í´ë˜ìŠ¤ ì˜ˆì¸¡).
- ìµœì¢… detection ì˜ˆì¸¡; ë°”ìš´ë”© ë°•ìŠ¤ì™€ í´ë˜ìŠ¤ ì˜ˆì¸¡ì„ ë™ì‹œì— ìˆ˜í–‰
- Procedure
    - 1) **box ìœ„ì¹˜ ì˜ˆì¸¡**: FFN --> ìƒëŒ€ì ì¸ ì¤‘ì•™ê°’ ì˜ˆì¸¡
    - 2) **í´ë˜ìŠ¤ ì˜ˆì¸¡**: linear layer --> softmaxë¡œ class ì˜ˆì¸¡
        - ì‹¤ì œ object ì™¸ class = âˆ…

> FFN(Feed-Forward Network)ì€ ì¼ë°˜ì ìœ¼ë¡œ ì‹ ê²½ë§ êµ¬ì¡°ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê°œë…ìœ¼ë¡œ, ë‘ ê°œì˜ ì„ í˜• ë³€í™˜(Linear Transformation) ë ˆì´ì–´ì™€ í™œì„±í™” í•¨ìˆ˜(Activation Function)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. FFNì€ ì…ë ¥ê°’ì„ ë°›ì•„ì„œ ë¹„ì„ í˜• ë³€í™˜ì„ ìˆ˜í–‰í•˜ê³  ì¶œë ¥ê°’ì„ ìƒì„±í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. FFNì€ ì£¼ë¡œ íŠ¹ì„± ì¶”ì¶œì´ë‚˜ ë¹„ì„ í˜• ë§¤í•‘ì„ ìœ„í•´ ì‚¬ìš©ë˜ë©°, ì—¬ëŸ¬ ê°œì˜ íˆë“  ë ˆì´ì–´ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> Linear LayerëŠ” FFNì˜ í•œ ì¢…ë¥˜ë¡œ, ì„ í˜• ë³€í™˜(Linear Transformation)ë§Œ ìˆ˜í–‰í•˜ëŠ” ë ˆì´ì–´ì…ë‹ˆë‹¤. Linear LayerëŠ” ì…ë ¥ ë²¡í„°ì™€ ê°€ì¤‘ì¹˜ í–‰ë ¬ ê°„ì˜ í–‰ë ¬ ê³±ì…ˆ ì—°ì‚°ì„ ìˆ˜í–‰í•œ í›„, í¸í–¥(bias)ì„ ë”í•˜ê³  í™œì„±í™” í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤. Linear LayerëŠ” ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì„ í˜• ë³€í™˜ì„ ìˆ˜í–‰í•˜ëŠ” ë‹¨ìˆœí•œ ë ˆì´ì–´ì…ë‹ˆë‹¤.

## Auxiliary decoding losses
- ì•Œë§ì€ ê°œìˆ˜ì˜ object ì˜ˆì¸¡ ê°€ëŠ¥
- ê° decoder layerì— ëŒ€í•´ prediction FFN & Hungarian loss ì¶”ê°€
    - ëª¨ë“  prediction FFNì€ ê°™ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©
- ë‹¤ë¥¸ decoder layerì˜ input ì •ê·œí™”ë¥¼ ìœ„í•´ layer norm ì¶”ê°€

****
# Experiments âœ
## ì„±ëŠ¥ ë¹„êµ: Faster R-CNN and RetinaNet
![image](https://user-images.githubusercontent.com/39285147/197423492-347a9b5f-f3d1-4555-b6b4-d3bb0679dc22.png)

$$AP: Average Precision$$

$$AP_50: IoU > 50(correct)$$

- DETRì€ ì†ë„ê°€ ëŠë¦°ëŒ€ì‹  ì •í™•ë„ê°€ ë†’ì€ Two-stage ë°©ë²•ì¸ Faster RCNNê³¼ë„ ì‹¬ì§€ì–´ ë¹„ìŠ·í•œ ì„±ëŠ¥ì„ ë‚¸ë‹¤.

****
# ìš”ì•½ âœ”
## DETR ì¥ì 
- DETR ì •í™•ë„ SOTA R-CNN ëª¨ë¸ ëŠ¥ê°€
- ìœ ì—°í•œ Transformer ì•„í‚¤í…ì³ --> Panoptic segmentation ì„±ëŠ¥ â†‘
- êµ¬í˜„ì´ ì‰½ë‹¤
- í° object íƒì§€ ì„±ëŠ¥ â†‘
    - global information performed by the self-attention
    - enabled by the non-local computations of the transformer
- ì»¤ìŠ¤í…€ layers í•„ìš” ì—†ìŒ --> better reproduction
    - ë•Œë¬¸ì— DETRì€ ResNet, Transformer í”„ë ˆì„ ì›Œí¬ì—ì„œë„ ì¬ì‚¬ìš© ê°€ëŠ¥ 

## DETR í•œê³„
- Training ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼
- ìµœì í™” ë¬¸ì œ
- ì‘ì€ object íƒì§€ ì„±ëŠ¥ â†“

****
# Reference ğŸ‘“
[**GitHub Repository**](https://github.com/hchoi256/carla-research-project)

[*UW Madison CARLA Research Team*](https://cavh.cee.wisc.edu/carla-simulation-project/)

[*CARLA Simulator*](https://carla.readthedocs.io/en/latest/)

[End to End Object Detection with Transformers](https://velog.io/@long8v/End-to-End-Object-Detection-with-Transformers)

[*Hungarian Algorithm*](https://gazelle-and-cs.tistory.com/29)