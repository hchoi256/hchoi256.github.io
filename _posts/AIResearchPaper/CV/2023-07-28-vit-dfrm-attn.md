---
layout: single
title: "[ë…¼ë¬¸ ë¶„ì„] Vision Transformer With Deformable Attention (CVPR 2022)"
categories: AIPaperCV
tag: [Computer Vision, ViT, Transformer, Deformable Attention]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/vit.png
sidebar:
    nav: "docs"
---

[ë…¼ë¬¸ë§í¬](https://arxiv.org/abs/2201.00520)

<!-- <span style="color:blue"> ???? </span> -->

****
# í•œì¤„ìš”ì•½ âœ”
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/eb28ad9a-8050-4057-8c5c-4ff82da474fd)

- Backboneìœ¼ë¡œ Swin Transformer êµ¬ì¡°ë¥¼ ë”°ë¥´ë©°, ë§ˆì§€ë§‰ 2ê°œì˜ Stageì—ì„œ Deformable Attention Moduleì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
- Deformable Convolutionì˜ Offset ê°œë…ì„ ViTì˜ Self-Attentionì— ì ìš©í•œ Deformable Attention Moduleì„ ì œì•ˆ.
- ê¸°ì¡´ Swin Transformer(ICCV'21) ë° Deformable DETR(CoRL'21)ê³¼ ë‹¬ë¦¬ **Query Agnostic**í•œ í˜•íƒœë¡œ Patch ê°œìˆ˜ë³´ë‹¤ ì ì€ Reference Pointsë¥¼ í†µí•´ Attention ì—°ì‚°.
    - Query Agnostic: ëª¨ë“  Queryê°€ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ ê³ ì •ëœ ê°œìˆ˜ì˜ Reference Pointsë¥¼ ê³µìœ í•˜ì—¬ Offsetì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. 

****
# Preliminaries ğŸ±
## Swin Transformer
[ì—¬ê¸°](https://hchoi256.github.io/aipapercv/swin-transformer/)

## Deformable Convolution
[ì—¬ê¸°](https://hchoi256.github.io/aipapercv/od-deformable-detr/#deformable-convolution)

## Deformable DETR
[ì—¬ê¸°](https://hchoi256.github.io/aipapercv/od-deformable-detr/)

## DeepViT
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/39c66335-4b4a-422c-97be-96b446f61445)

DeepViT(arXiv`21) ë…¼ë¬¸ì—ì„œ ê¸°ì¡´ ViT êµ¬ì¡°ëŠ” CNNê³¼ ë‹¬ë¦¬ ê¹Šì´ê°€ ê¹Šì–´ì ¸ë„ ì„±ëŠ¥ í–¥ìƒì´ ì–´ë µë‹¤ëŠ” ì ì„ ì§€ì í–ˆìŠµë‹ˆë‹¤.

ìƒê¸° ì´ë¯¸ì§€ì—ì„œ<span style="color:red"> ë¹¨ê°„ì </span>ì€ ê°ê¸° ë‹¤ë¥¸ Queryì˜ ìœ„ì¹˜ì´ë©°, ê¶ê·¹ì ìœ¼ë¡œ ê¹Šì´ê°€ ê¹Šì–´ì§€ë©´ ë‹¤ë¥¸ Queryì— ëŒ€í•œ Self-Attention Mapì´ ê±°ì§„ ë™ì¼í•˜ê²Œ ìƒì„±ë˜ëŠ” ëª¨ìŠµì…ë‹ˆë‹¤.

ì´ê²ƒì€ Layerê°€ ê¹Šì–´ì ¸ë„ ê±°ì§„ ìœ ì‚¬í•œ Self-Attention Mapì´ í•™ìŠµë˜ëŠ” ë¬¸ì œì (**Attention Collapse**)ì„ ìœ ë°œí•©ë‹ˆë‹¤.

![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/de2ef356-afd9-4780-9f32-7e74be5d62de)

í•˜ì—¬ ë³¸ ë…¼ë¬¸ì€ **Re-Attention êµ¬ì¡°**ë¥¼ ì œì•ˆí•˜ì—¬ Learnable Matrixë¡œ Self-Attention Mapì„ ì„ì–´ì£¼ì–´ ê¹Šì´ê°€ ë” ê¹Šì–´ì ¸ë„ ë‹¤ë¥¸ Self-Attention Mapì´ ìƒì„±í•©ë‹ˆë‹¤.

Learnable MatrixëŠ” í•™ìŠµ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°ë¡œ, ì—¬ëŸ¬ Queryë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. 

ì´ë¡œ ì¸í•´ ê¹Šì´ê°€ ê¹Šì–´ì ¸ë„ ë‹¤ì–‘í•œ Self-Attention Mapì´ ìƒì„±ë˜ì–´ ë‹¤ì–‘í•œ íŠ¹ì§•ì„ í•™ìŠµí•˜ê³  ì…ë ¥ ë°ì´í„°(Query)ì˜ ë‹¤ì–‘í•œ ê´€ì ì„ ê³ ë ¤í•˜ì—¬ íŠ¹ì§•ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ëŠ” **query-dependent**í•œ íŠ¹ì§• ì¶”ì¶œì„ ê°œì„ í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ”ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.

ê°€ë ¹, ìƒê¸° ì´ë¯¸ì§€ì—ì„œ Block 23 ê¹Šì´ì—ì„œ Self-Attention Mapì€ **Uniform**í•´ì§€ê¸° ì‹œì‘í•˜ì§€ë§Œ, Re-Attentionì—ì„œëŠ” Block 30 ê¹Šì´ ì •ë„ì—ì„œ Uniformí•´ì§€ê¸° ì‹œì‘í•©ë‹ˆë‹¤.

í•˜ë‚˜ DeepViT ë˜í•œ ì–´ëŠ ì •ë„ ê¹Šì´ì—ì„œëŠ” ë‹¤ì‹œê¸ˆ Attention Collapse í˜„ìƒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

****
# Challenges and Main IdeağŸ’£
**C1)** <span style="color:orange"> CNN ê¸°ë°˜ì˜ ê°ì²´íƒì§€ ëª¨ë¸ì€ ê³ ì •ëœ í¬ê¸°ì˜ Kernelë¥¼ ì‚¬ìš©í•œ í•©ì„±ê³± ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ í° ê°ì²´íƒì§€ ì„±ëŠ¥ì´ ì €ì¡°í•©ë‹ˆë‹¤. </span>

**Idea 1)** <span style="color:lightgreen"> Deformable Attention Moduleì„ í†µí•´ ê°ì²´ì— íŠ¹í™”ëœ ìˆ˜ìš© ì˜ì—­ì„ í˜•ì„±í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤. </span>

**C2)** <span style="color:orange"> DeepViTì—ì„œ ì–¸ê¸‰ëœ Global Attention ê´€ì ì—ì„œ ê²°êµ­ ëª¨ë‘ ë™ì¼í•œ Self-Attention Mapìœ¼ë¡œ ìˆ˜ë ´í•˜ê¸° ë•Œë¬¸ì—, ê¸°ì¡´ì˜ Deformable ê°ì²´íƒì§€ ê¸°ë²•ë“¤ì´ ê° Queryë§ˆë‹¤ ë…ë¦½ì ì¸ Reference Pointsë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì€ ì—°ì‚° ì¸¡ë©´ì—ì„œ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤. </span>

**Idea 2)** <span style="color:lightgreen"> ëª¨ë“  Queryê°€ ë™ì¼í•œ Reference Pointsë¥¼ í†µí•´ Attention ì—°ì‚°ì„ í•˜ë„ë¡ í•©ë‹ˆë‹¤. </span>


**C3)** <span style="color:orange"> Deformable DETRì˜ ê²½ìš° Deformable Attentionì„ í†µí•´ small sets of key sampling pointsë§Œì„ ì´ìš©í•˜ì—¬ Attention ì—°ì‚°ì„ í•˜ì§€ë§Œ, Multi-Scale Feature Mapsë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° Exponential ì—°ì‚°ëŸ‰ ì¦ê°€ê°€ ë¬¸ì œê°€ ë©ë‹ˆë‹¤. </span>

**Idea 2)** <span style="color:lightgreen"> ë³¸ ë…¼ë¬¸ì€ Swin Transformerì„ Backboneìœ¼ë¡œ ì·¨í•˜ì—¬ Multi-Scale Feature Mapì— ëŒ€í•œ ì—°ì‚°ëŸ‰ì„ ì„ í˜• ë³µì¡ë„ë¡œ ì¤„ì…ë‹ˆë‹¤. </span>

****
# Proposed Method ğŸ§¿
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/e7cb5c40-5f93-4084-9143-5317aed44d65)

![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/985e10e3-5a9c-4be2-a34d-dfeb19b96628)

DMHA ëª¨ë“ˆì€ Offset ê³„ì‚°ì„ ìœ„í•´ ìƒê¸° ì—°ì‚° ë³µì¡ë„ì—ì„œ Offset Network ë¶€ë¶„ë§Œ ì¶”ê°€ëœ ëª¨ìŠµì´ë©°, í•´ë‹¹ ê³¼ì •ì˜ ì—°ì‚°ëŸ‰ì€ $$6%$$ ë°–ì— ì¦ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## Deformable Attention Module
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/11f29c0a-cfa4-46bb-9c8b-53b4d36f251c)

- $$x$$: Input Feature Map.
- $$q$$: Query.
- $$\tilde{k}, \tilde{v}$$: deformed key and value.
- $$\phi$$: sampling function.
- $$W_q,W_k,W_v$$: Query, Key, Value ê°€ì¤‘ì¹˜ í–‰ë ¬.
- Reference Points: í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ Patch ê°œìˆ˜ë³´ë‹¤ ì ë„ë¡ Input Feature Map ìƒì— Uniformí•˜ê²Œ ìƒì„±ë©ë‹ˆë‹¤.
- $$\theta_{offset}$$: offset network.

## ë™ì‘ ê³¼ì •
1) Input Feature Map $$x \in (B,C, H, W)$$ì„ ë§ˆì¹˜ MSHAì²˜ëŸ¼ Channel-Wiseí•˜ê²Œ Group $$G$$ ë‹¨ìœ„ë¡œ $$x \in (B,G \times C, H, W) \rightarrow (B \times G, C, H,W)$$ ë¶„í• í•˜ì—¬ **Deformed Pointsì˜ ë‹¤ì–‘ì„±ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤**.

- Headì˜ ê°œìˆ˜ $$M$$ì€ $$G$$ì˜ ë°°ìˆ˜ë¡œ ì„¤ì •ë˜ì–´ ê° Groupì´ ë‹¤ìˆ˜ì˜ attention headë¥¼ í†µí•´ ì—°ì‚°ë  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. 
- ê° Groupë§ˆë‹¤ shared subnetworkë¥¼ í†µí•´ offsetsë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

2) $$x \in (B \times G, C, H,W)$$ì— ëŒ€í•´ **Reference Points $$p \in (B \times G, H_G,W_G,2)$$ë¥¼ Uniform Grid $$((H,W) \rightarrow (H_G,W_G))$$ë¡œ ìƒì„±í•˜ê³  ê° ì¢Œí‘œë¥¼ $$[-1,1]$$ ë²”ìœ„ë¡œ Normalization í•©ë‹ˆë‹¤**.

- $$H_G={H \over r}, W_G={W \over r}$$.
    - $$r$$: a factor.
- Reference Points: $$\{(0,0),...,(H_G-1,W_G-1)\}$$ ì¢Œí‘œë“¤ì„ $$[-1,+1]$$ ë²”ìœ„ë¡œ Normalizationì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    - Normalization ì´í›„, $$(-1,-1)$$ ì¢Œí‘œëŠ” top-left cornerì´ ë˜ê²Œ ë©ë‹ˆë‹¤.
    - ê° Reference Point ë§ˆë‹¤ $$2$$ê°œì˜ $$x$$ì¶•ê³¼ $$y$$ì¶• Sampling Offsetì„ ê°€ì§‘ë‹ˆë‹¤.

3) Input Feature Mapì„ $$W_q$$ê³¼ ê³±í•˜ì—¬ **ì¿¼ë¦¬ $$q$$ë¥¼ êµ¬í•©ë‹ˆë‹¤**.

<span style="color:yellow"> $$q=xW_q$$ </span>

4) í•´ë‹¹ ì¿¼ë¦¬ $$q$$ë¥¼ Offset Network $$\theta_{offset}$$ì— ë„£ì–´ì„œ Reference Pointsì— ëŒ€í•œ **Offset Vectorë¥¼ êµ¬í•©ë‹ˆë‹¤**.

<span style="color:yellow">$$\bigtriangleup \textbf{p}=\theta_{offset}(q)$$ </span>

5) í•´ë‹¹ Offset Vectorê³¼ Reference Pointsë“¤ì„ ë”í•˜ì—¬ **Deformed Points(Sampling Points)ë¥¼ êµ¬í•©ë‹ˆë‹¤**.

<span style="color:yellow">$$\tilde{x}=\phi(x;p+\bigtriangleup p)$$ </span>

6) í•´ë‹¹ Deformed Pointsë“¤ì€ ì‹¤ìˆ˜ê°’ì„ ê°–ê³  ìˆê¸° ë•Œë¬¸ì— **Bilinear Interpolationì„ í†µí•´ ì•Œë§ì€ Sampled Featuresë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤**.

<span style="color:yellow">$$\phi(z;(p_x,p_y))=\Sigma_{r_x,r_y}g(p_x,r_x) \cdot g(p_y,r_y) \cdot z[r_y,r_x,:]$$ </span>

<span style="color:yellow"> $$g(a,b)=max(0,1-\left\vert a-b \right\vert)$$ </span>

- $$r_x,r_y$$: indexes on $$z \in \mathbb{R}^{H \times W \times C}$$.

7) í•´ë‹¹ Sampled Featuresë“¤ì„ ê°ê° $$W_k,W_v$$ì™€ ê³±í•˜ì—¬ Deformed Key $$\tilde{k}$$ì™€ Deformed Value $$\tilde{v}$$ë¥¼ êµ¬í•©ë‹ˆë‹¤.

<span style="color:yellow">$$\tilde{k}=\tilde{x}W_k,\tilde{v}=\tilde{x}W_v$$ </span>

8) Deformed Pointsë¡œ ë¶€í„° Swin Transformerì—ì„œ ì œì‹œëœ **Relative Position Bias Offsetsì„ ë™ì¼í•œ ë°©ë²•ìœ¼ë¡œ êµ¬í•˜ê³ , ìµœì¢… Attention ì¶œë ¥ì„ ê³„ì‚°í•©ë‹ˆë‹¤**.

<span style="color:yellow">$$z^m=\sigma({q^m (\tilde{k}^{m})^T \over \sqrt{d}}+\phi(\hat{B};R)W)\tilde{v}^m$$ </span>

- $$z^m$$: $$m$$ë²ˆì§¸ headì˜ Attention ê²°ê³¼.
- $$\phi(\hat{B};R) \in \mathbb{R}^{HW \times H_G W_G}$$: Relative Position Bias Offset.
    - $$G$$: Group.
    - $$\hat{B}$$: Relative Position Bias.

## Offset Network
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/43ce0b3d-86d8-4638-8063-416863e17e6e)

Offset NetworkëŠ” Query Featureë¥¼ ì…ë ¥ìœ¼ë¡œ ê° Reference Pointì— í•´ë‹¹í•˜ëŠ” Offset Valueë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

ë˜í•œ, Offset NetworkëŠ” **Depthwwise Separable Convolution, GELU, 1x1 Convolution**ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/7b46d1c5-7046-45cb-9ee3-78104de010f3)

ìƒê¸° ì´ë¯¸ì§€ëŠ” Depthwise Separable Convolutionì„ ì‹œê°í™”í•˜ë©°, ì´ëŠ” Channel ë‹¨ìœ„ë¡œ Convolutionì„ ìš°ì„  ì§„í–‰í•œ í›„, Pointwise Convolutionì„ ì§„í–‰í•©ë‹ˆë‹¤.

![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/89dca30d-bb7c-49ff-a800-a1f78164b92d)

ìƒê¸° ì´ë¯¸ì§€ì—ì„œ Standard Convolutionì— ë¹„í•´ ì—°ì‚° ë³µì¡ë„ê°€ $${1 \over N} + {1 \over D^2_k}$$ ë§Œí¼ ì¤„ì–´ë“  ëª¨ìŠµì…ë‹ˆë‹¤.

<span style="color:yellow">$$\bigtriangleup p \leftarrow s \cdot tanh(\bigtriangleup p)$$ </span>

ìƒê¸° ìˆ˜ì‹ì„ í†µí•´ Reference PointëŠ” $$x \times s$$ Regionì—ì„œ ì •ì˜ë˜ë„ë¡ í•˜ì—¬ Offsetì´ ë²”ìœ„ë¥¼ ì´ˆê³¼í•˜ì—¬ ë³€í˜•ì‹œí‚¤ì§€ ì•Šë„ë¡ ì œí•œí•©ë‹ˆë‹¤.

****
# Experiment ğŸ‘€
## SOTA Performance
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/8d37a810-f7e3-47d5-8d20-c6574eb92793)

![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/79a85476-3654-4742-9633-97a10c66e061)

## Ablation
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/030fbf3d-5b98-4a75-ae00-efb665f79047)

## Visualization
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/f141c1c6-d5d3-432e-8865-bcfadb6fc057)

ìƒê¸° ì´ë¯¸ì§€ëŠ” Swin Transformer ì‹œê°í™” ê²°ê³¼ì´ë©°, ë³´ì‹œëŠ” ê²ƒì²˜ëŸ¼ í•œì •ëœ ì˜ì—­ì—ì„œ ê°ì²´íƒì§€ë¥¼ í•˜ëŠ” ëª¨ìŠµì…ë‹ˆë‹¤.

![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/a605d796-6ad7-4880-a458-55041ac6b69e)

í•˜ë‚˜ ë³¸ ë…¼ë¬¸ì˜ DATëŠ” Reference Pointë¥¼ Deformableí•˜ê²Œ ë§Œë“¦ìœ¼ë¡œì¨ Recognition ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©´ì„œë„, Swin Transformerì˜ ì„ í˜• ì—°ì‚° ë³µì¡ë„ë¥¼ ìœ ì§€í•˜ì˜€ìŠµë‹ˆë‹¤.

****
# Open Reivew ğŸ’—
NA

****
# Discussion ğŸŸ
NA

****
# Major Takeaways ğŸ˜ƒ
- Query Agnostic

****
# Conclusion âœ¨
NA

****
# Reference
NA