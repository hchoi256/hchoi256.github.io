---
layout: single
title: "[논문 분석] AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE"
categories: AIPaperCV
tag: [Computer Vision, ViT, Vision Transformer]
toc: true
toc_sticky: true
toc_label: "쭌스log"
#author_profile: false
header:
    teaser: /assets/images/posts/vit.png
sidebar:
    nav: "docs"
---

[**논문**](https://arxiv.org/pdf/2010.11929.pdf)

****
# Summary 📌
- 이미지를 여러 개의 **patches(1차원 시퀀스)** 나누고, 인코더의 인풋으로 활용.
- 주로 대용량 데이터셋으로 학습 시 모델 성능이 우수하다.
    - Transformer는 공간 특징을 상대적으로 덜 반영하여 CNN에 비해 inductive biases가 낮다.
        - 낮은 inductive bias는 일반화 능력을 저하시켜, 적은 데이터셋으로 학습 시 모델 성능이 매우 저조하다.

> Inductive bias: 학습 시에는 만나보지 않았던 상황에 대하여 정확한 예측을 하기 위해 사용하는 추가적인 가정 (CV에서는 이미지 특성에 대한 locality와 같은 공간적 특성).

****
# Preliminaries ✏


****
# Introduction 🙌
그간 방대한 데이터셋 처리에도 saturating performance 문제에서 자유로운 Transformer는 NLP 영역에서 각광받아 왔다.
- Training: 방대한 데이터 corpus 학습
- Fine-tuning: downstream task에 대한 작은 데이터셋에서 fine-tuning.

하지만, CV 분야에서는 self-attention과 융합하고자 한 노력이 있었으나, h/w 가속기에 알맞은 비율로 scaling 되지 않는 등 여러 가지 문제가 발생했다.

하여 당시 CNN 네트워크가 여전히 SOTA를 달성하고 있었다.

****
# Problem Definition 🧿
- **Given** 2D image dataset $$\mathcal{D}$$.
- **Produce** a pre-trained Transformer model $$\mathcal{T}$$.
- **Such that** $$\mathcal{T}$$ competes with CNN-based models on $$\mathcal{D}$$.

****
# Methodology ✨
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/8204eabe-c472-4f9b-b289-f2c22c8f41b3)

## Backbone
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/9161b45e-9732-419d-be71-18d90452661d)

$$Patch + Position\ Embedding + Learnable\ [class]\ Embedding$$

- **Patch**: 인풋 이미지($$x$$)를 하이퍼 파라미터로 지정된 patch 크기 이미지 분할.
- **Position Embedding**: 해당 이미지의 class label을 나타내는 학습 가능한 embedding 추가. 
- **Learnable [class] Embedding**: 각 patch에 대응되는 Position Embedding 추가.

## Transformer Encoder
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/9abafa08-c6cf-4751-a6c5-11720ee4d309)

- Backbone의 patch들을 인코더 인풋으로 활용하기 위해 1차원 sequence로 flatten.
    - 이때 각 patch의 위치 정보 유지.


****
# Experiment 🗂

****
# Conclusion 🌷

****
# Reference 🧿