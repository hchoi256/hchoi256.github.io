---
layout: single
title: "[ë…¼ë¬¸ ë¶„ì„] AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE"
categories: AIPaperCV
tag: [Computer Vision, ViT, Vision Transformer]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/vit.png
sidebar:
    nav: "docs"
---

[**ë…¼ë¬¸**](https://arxiv.org/pdf/2010.11929.pdf)

****
# Summary ğŸ“Œ
- ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ê°œì˜ **patches(1ì°¨ì› ì‹œí€€ìŠ¤)** ë‚˜ëˆ„ê³ , ì¸ì½”ë”ì˜ ì¸í’‹ìœ¼ë¡œ í™œìš©.
- Transformerì˜ êµ¬ì¡°ì ì¸ íŠ¹ì§•ìœ¼ë¡œ ë” ë§ì€ ë°ì´í„° ë° íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤Œ.
- ì£¼ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ ì‹œ ëª¨ë¸ ì„±ëŠ¥ì´ ìš°ìˆ˜í•˜ë‹¤.
    - TransformerëŠ” ê³µê°„ íŠ¹ì§•ì„ ìƒëŒ€ì ìœ¼ë¡œ ëœ ë°˜ì˜í•˜ì—¬ CNNì— ë¹„í•´ inductive biasesê°€ ë‚®ë‹¤.
        - ë‚®ì€ inductive biasëŠ” ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì €í•˜ì‹œì¼œ, ì ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ ì‹œ ëª¨ë¸ ì„±ëŠ¥ì´ ë§¤ìš° ì €ì¡°í•˜ë‹¤.

> Inductive bias: í•™ìŠµ ì‹œì—ëŠ” ë§Œë‚˜ë³´ì§€ ì•Šì•˜ë˜ ìƒí™©ì— ëŒ€í•˜ì—¬ ì •í™•í•œ ì˜ˆì¸¡ì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì¶”ê°€ì ì¸ ê°€ì • (CVì—ì„œëŠ” ì´ë¯¸ì§€ íŠ¹ì„±ì— ëŒ€í•œ localityì™€ ê°™ì€ ê³µê°„ì  íŠ¹ì„±).

****
# Preliminaries âœ


****
# Introduction ğŸ™Œ
ê·¸ê°„ ë°©ëŒ€í•œ ë°ì´í„°ì…‹ ì²˜ë¦¬ì—ë„ saturating performance ë¬¸ì œì—ì„œ ììœ ë¡œìš´ TransformerëŠ” NLP ì˜ì—­ì—ì„œ ê°ê´‘ë°›ì•„ ì™”ë‹¤.
- Training: ë°©ëŒ€í•œ ë°ì´í„° corpus í•™ìŠµ
- Fine-tuning: downstream taskì— ëŒ€í•œ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ fine-tuning.

í•˜ì§€ë§Œ, CV ë¶„ì•¼ì—ì„œëŠ” self-attentionê³¼ ìœµí•©í•˜ê³ ì í•œ ë…¸ë ¥ì´ ìˆì—ˆìœ¼ë‚˜, h/w ê°€ì†ê¸°ì— ì•Œë§ì€ ë¹„ìœ¨ë¡œ scaling ë˜ì§€ ì•ŠëŠ” ë“± ì—¬ëŸ¬ ê°€ì§€ ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤.

í•˜ì—¬ ë‹¹ì‹œ CNN ë„¤íŠ¸ì›Œí¬ê°€ ì—¬ì „íˆ SOTAë¥¼ ë‹¬ì„±í•˜ê³  ìˆì—ˆë‹¤.

****
# Problem Definition ğŸ§¿
- **Given** 2D image dataset $$\mathcal{D}$$.
- **Produce** a pre-trained Transformer model $$\mathcal{T}$$.
- **Such that** $$\mathcal{T}$$ competes with CNN-based models on $$\mathcal{D}$$.

****
# Methodology âœ¨
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/8204eabe-c472-4f9b-b289-f2c22c8f41b3)

## Backbone
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/3e9bec0d-d004-45c8-b1bd-2aef9fd2ca4b)

![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/52f6540c-a22f-4a36-b8ae-ae1fc862f0dc)

- **Patch**: ì¸í’‹ ì´ë¯¸ì§€($$x$$)ë¥¼ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ ì§€ì •ëœ patch í¬ê¸° ì´ë¯¸ì§€ ë¶„í• .
    - $$x^i_pE$$.
    - $$H \times W \times C \rightarrow N \times(P \times P \times C); P:\ patch\ size,\ C:\ channel,\ N:\ patch\ or\ sequence\ ê°œìˆ˜,\ D:\ embedding\ dimension$$.
- **Position Embedding**: ê° patchì— ëŒ€ì‘ë˜ëŠ” Position Embedding ì¶”ê°€.
    - $$E_{pos}$$.
- **Learnable [class] Embedding**: í•´ë‹¹ ì´ë¯¸ì§€ì˜ class labelì„ ë‚˜íƒ€ë‚´ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ embedding ì¶”ê°€. 
    - $$x_{class}$$.

## Transformer Encoder
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/fb6105a2-3c24-47fe-86db-291256c670e9)

![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/885bd53b-e9e4-49d8-beef-29fe5d502c6a)

ìƒê¸° Transformer Encoder êµ¬ì¡°ì™€ ìˆ˜ì‹ì„ ë¹„êµí•´ë³´ë©´ ì§ê´€ì ìœ¼ë¡œ ì´í•´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì •ë¦¬í•˜ë©´ Transformer Encoder ì¸í’‹ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” sequenceë§Œ ì•Œë§ê²Œ ì¬ì •ì˜í•˜ê³ , ë‚˜ë¨¸ì§€ Transformer Encoderì˜ ë™ì‘ ì›ë¦¬ëŠ” ë™ì¼í•©ë‹ˆë‹¤.

## Notes
- ViTë¥¼ ë°©ëŒ€í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ê³ , ì‘ì€ downstream taskë¡œ fine-tuningí•œë‹¤.
    - fine-tuningí•  ë•Œ, pre-trained prediction head(MLP)ë¥¼ ì œê±°í•˜ê³  0ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ìƒˆë¡œìš´ $$d \times K$$ ì°¨ì›ì˜ FFNìœ¼ë¡œ ëŒ€ì²´í•œë‹¤; where $$K$$: ìš°ë¦¬ê°€ í’€ë ¤ëŠ” taskì˜ class.
        - **ì‚¬ì „ í•™ìŠµëœ ì˜ˆì¸¡ í—¤ë“œì™€ íŒŒì¸íŠœë‹ ì‘ì—…ì˜ ì°¨ì´**: ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì‚¬ì „ í•™ìŠµë˜ì–´ ìˆìœ¼ë©°, ì˜ˆì¸¡ í—¤ë“œëŠ” í•´ë‹¹ ë°ì´í„°ì…‹ì˜ ì‘ì—…ì— ë§ê²Œ ì¡°ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ íŒŒì¸íŠœë‹ ì‘ì—…ì€ ë³´ë‹¤ ì‘ì€ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ëª¨ë¸ì„ ì¡°ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ, ì´ˆê¸° ì˜ˆì¸¡ í—¤ë“œë¥¼ ìƒˆë¡œìš´ ì‘ì—…ì— ë” ì í•©í•œ í˜•íƒœë¡œ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒì´ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ViTëŠ” Fine-tuningì‹œ Pre-trainingì—ì„œ ì‚¬ìš©í•œ ì´ë¯¸ì§€ë³´ë‹¤ ë†’ì€ í•´ìƒë„ë¥¼ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ì˜¤ë¥¸ë‹¤.
    - $$N \times (P \times P \times C)$$ì—ì„œ $$N$$ì´ ì¦ê°€í•˜ì—¬ ê³µê°„ì ì¸ contextë¥¼ ë” ì˜ ì´í•´í•©ë‹ˆë‹¤.
    - $$N$$ ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡, Position embeddingì˜ ì˜ë¯¸ê°€ ëª¨í˜¸í•´ì§€ê¸° ë•Œë¬¸ì—, 2ì°¨ì› position embedding ì‚¬ìš©ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆë‹¤.

****
# Experiment ğŸ—‚
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/0f7a4101-3ce0-478e-a7f6-9638259a4c6a)

ì„±ëŠ¥ì€ í•™ìŠµ ë°ì´í„°ê°€ ë§ì„ ê²½ìš° ê²½ìŸëª¨ë¸ì— ë¹„í•´ ì••ë„ì ìœ¼ë¡œ ì¢‹ìœ¼ë‚˜, ì ì€ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ë©´ ì„±ëŠ¥ì´ ì•ˆ ì¢‹ë‹¤.

![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/2607118f-5b88-497f-8731-bdb7f47f0e2f)

ìœ„ì²˜ëŸ¼ ë§ì€ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ í•™ìŠµí•˜ë©´, ViTì˜ embedding filterê°€ ê¸°ì¡´ ë°©ì‹ì¸ CNN filterì™€ ë™ì¼í•œ ëª¨ìŠµì´ë‹¤.

****
# Reference ğŸ§¿
[ViT](https://arxiv.org/pdf/2010.11929.pdf)
