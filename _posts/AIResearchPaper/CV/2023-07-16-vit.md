---
layout: single
title: "[ë…¼ë¬¸ ë¶„ì„] AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE"
categories: AIPaperCV
tag: [Computer Vision, ViT, Vision Transformer]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/vit.png
sidebar:
    nav: "docs"
---

[**ë…¼ë¬¸**](https://arxiv.org/pdf/2010.11929.pdf)

****
# Summary ğŸ“Œ
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/8204eabe-c472-4f9b-b289-f2c22c8f41b3)

- ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ê°œì˜ **flattened patches**ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ì´ë¥¼ Transformer ì¸ì½”ë”ì˜ ì¸í’‹ìœ¼ë¡œ í™œìš©í•©ë‹ˆë‹¤.
- ê¸°ì¡´ CNN ê¸°ë°˜ SOTA ëª¨ë¸ë³´ë‹¤ ë” ì„±ëŠ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤.
- **íŒŒë¼ë¯¸í„° í•œê³„ ì—†ìŒ**: Transformerì˜ êµ¬ì¡°ì ì¸ íŠ¹ì§•ìœ¼ë¡œ ë” ë§ì€ ë°ì´í„° ë° íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
    - <span style="color:orange"> TransformerëŠ” ê³µê°„ íŠ¹ì§•ì„ ìƒëŒ€ì ìœ¼ë¡œ ëœ ë°˜ì˜í•˜ì—¬ CNNì— ë¹„í•´ inductive biasesê°€ ë‚®ìœ¼ë©°, ì´ëŠ” ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì €í•˜ì‹œì¼œ ì ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ ì‹œ ëª¨ë¸ ì„±ëŠ¥ì´ ë§¤ìš° ì €ì¡°í•©ë‹ˆë‹¤. </span>
    - <span style="color:lightgreen"> í•˜ì—¬ ViTëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì•½í•œ inductive biasë¥¼ ë³´ì™„í•˜ê³  ëª¨ë¸ ì„±ëŠ¥ì„ ëŒì–´ë‚´ì—ˆìŠµë‹ˆë‹¤. </span>

> Inductive bias: í•™ìŠµ ì‹œì—ëŠ” ë§Œë‚˜ë³´ì§€ ì•Šì•˜ë˜ ìƒí™©ì— ëŒ€í•˜ì—¬ ì •í™•í•œ ì˜ˆì¸¡ì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì¶”ê°€ì ì¸ ê°€ì • (CNNì—ì„œëŠ” ë¹„ìŠ·í•œ íŠ¹ì§•ì„ ê°€ì§„ í”½ì…€ë“¤ì€ ì£¼ë³€ì— ë°€ì§‘í•´ìˆë‹¤ëŠ” ê°€ì •).

****
# Introduction ğŸ™Œ
ë³¸ ë…¼ë¬¸ ì´ì „, ë°©ëŒ€í•œ ë°ì´í„°ì…‹ ì²˜ë¦¬ì—ë„ saturating performance ë¬¸ì œì—ì„œ ììœ ë¡œìš´ TransformerëŠ” NLP ì˜ì—­ì—ì„œ ê°ê´‘ë°›ì•„ ì™”ìŠµë‹ˆë‹¤.

> **Training**: ë°©ëŒ€í•œ ë°ì´í„° corpusë¥¼ í•™ìŠµí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.
>
> **Fine-tuning**: downstream taskì— ëŒ€í•œ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ fine-tuningí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

í•˜ë‚˜ CV ë¶„ì•¼ì—ì„œ ì—­ì‹œ í…ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ì´ë¯¸ì§€ì˜ íŠ¹ì§•ë“¤ì„ self-attentionê³¼ ìœµí•©í•˜ê³ ì í•œ ë…¸ë ¥ì´ ìˆì—ˆìœ¼ë‚˜, í•˜ë“œì›¨ì–´ ê°€ì†ê¸°ì— ì•Œë§ì€ ë¹„ìœ¨ë¡œ scaling ë˜ì§€ ì•ŠëŠ” ë“± ì—¬ëŸ¬ ê°€ì§€ ë¬¸ì œê°€ ë°œìƒí•˜ê³¤ í–ˆìŠµë‹ˆë‹¤.

ë³¸ ë…¼ë¬¸ì˜ **ViT**ëŠ” ë¹„ì „ ë¶„ì•¼ì—ì„œ Transformerë¥¼ ê²°í•©í•œ ì‹œì´ˆë¡œì¨ í° ì˜ë¯¸ë¥¼ í’ˆê³  ìˆìœ¼ë©°, ì´ë¥¼ ê¸°ì ìœ¼ë¡œ ë¹„ì „ ë¶„ì•¼ì—ì„œ ì—­ì‹œ Transformer ê¸°ë°˜ ë¹„ì „ ëª¨ë¸ë“¤ì´ ê¸‰ì¦í•˜ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤.

****
# Problem Definition ğŸ§¿
- **Given** a 2D image dataset $$\mathcal{D}$$.
- **Produce** a pre-trained Transformer model $$\mathcal{T}$$.
- **Such that** $$\mathcal{T}$$ produces comparable performance over existing models on $$\mathcal{D}$$.

****
# Methodology âœ¨
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/8204eabe-c472-4f9b-b289-f2c22c8f41b3)

## Backbone
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/3e9bec0d-d004-45c8-b1bd-2aef9fd2ca4b)

![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/52f6540c-a22f-4a36-b8ae-ae1fc862f0dc)

- **Patch**: ì¸í’‹ ì´ë¯¸ì§€($$x;\ H \times W \times C$$)ë¥¼ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ ì§€ì •ëœ patch í¬ê¸°$$(N \times(P \times P \times C) \times D)$$ì˜ ì´ë¯¸ì§€ë“¤ë¡œ ë¶„í• .
    - $$x^i_pE$$: ê° íŒ¨ì¹˜ ì„ë² ë”©.
    - $$P$$: patch size.
    - $$C$$: channel size.
    - $$N$$: patch or sequence ê°œìˆ˜.
    - $$D$$: embedding dimension.
- **Position Embedding($$E_{pos}$$)**: ê° patchì— ëŒ€ì‘ë˜ëŠ” Position Embedding ì¶”ê°€.
- **Learnable [class] Embedding $$(x_{class})$$.**: ì…ë ¥ ì „ì²´ ì´ë¯¸ì§€ì˜ class labelì„ í•™ìŠµí•˜ëŠ” embedding. 

í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ ì§€ì •í•œ í¬ê¸°ì˜ patchë§Œí¼ ì „ì²´ ì´ë¯¸ì§€ë¥¼ flattení•˜ì—¬ ë¶„í• í•˜ê³ , ì´ë¥¼ Transformer Encoderì˜ ì¸í’‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ linear projectionì„ í†µê³¼ì‹œì¼œ ê° patchê°€ ëª¨ë¸ì˜ ì„ë² ë”© ì°¨ì›ì˜ ë²¡í„°$$(N,P,P,C,D)$$ë¡œ í‘œí˜„ë˜ë„ë¡ í•˜ëŠ” ëª¨ìŠµì…ë‹ˆë‹¤.

ì´ì™€ ë”ë¶ˆì–´, ê° patchë“¤ì´ ëª¨ì—¬ ì´ë£¨ëŠ” ì „ì²´ ì´ë¯¸ì§€ì˜ classë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´, í† í° ë²ˆí˜¸ $$0$$ì— extra learnable class embeddingì„ ì¶”ê°€ì ìœ¼ë¡œ concatì‹œí‚¨ í›„ Encoderì˜ ì¸í’‹ìœ¼ë¡œ ë„£ì–´ì¤ë‹ˆë‹¤.

## Transformer Encoder
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/885bd53b-e9e4-49d8-beef-29fe5d502c6a)

![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/fb6105a2-3c24-47fe-86db-291256c670e9)

ìƒê¸° Transformer Encoder êµ¬ì¡°ì™€ ìˆ˜ì‹ì„ ë¹„êµí•´ë³´ë©´ ì§ê´€ì ìœ¼ë¡œ ì´í•´ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì—¬ê¸°ì„œ, Transformer Encoder ì¸í’‹ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ì…ë ¥ ì‹œí€€ìŠ¤ë§Œ ì•ì„  ì„¹ì…˜ì—ì„œ ì„¤ëª…í•œ ê²ƒì²˜ëŸ¼ ì¬ì •ì˜í•˜ê³ ,ë‚˜ë¨¸ì§€ ë™ì‘ ì›ë¦¬ëŠ” ê¸°ì¡´ Transformer ì¸ì½”ë”ì™€ ë™ì¼í•©ë‹ˆë‹¤.

## Observations
ViTë¥¼ ë°©ëŒ€í•œ ë°ì´í„°ì…‹ìœ¼ë¡œ trainingí•˜ê³ , ì´í›„ ì‘ì€ downstream taskë¡œ fine-tuningí•©ë‹ˆë‹¤.

ì´ ë•Œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì‚¬ì „ í•™ìŠµë˜ì–´ ìˆìœ¼ë©°, MLP(prediction head)ëŠ” í•´ë‹¹ ë°ì´í„°ì…‹ì˜ ì‘ì—…ì— ë§ê²Œ ì¡°ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

í•˜ë‚˜ íŒŒì¸íŠœë‹ ì‘ì—…ì€ ë³´ë‹¤ ì‘ì€ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ëª¨ë¸ì„ ì¡°ì •í•˜ëŠ” ê³¼ì •ì´ê¸° ë•Œë¬¸ì—, ì´ˆê¸° MLP or FFN(prediction head)ë¥¼ ìƒˆë¡œìš´ ì‘ì—…ì— ë” ì í•©í•œ í˜•íƒœë¡œ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒì´ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í•˜ì—¬ Fine-tuningí•  ë•Œ, ê¸°ì¡´ pre-trained prediction head(MLP)ë¥¼ ì œê±°í•˜ê³ , **ì´ë¥¼ $$0$$ìœ¼ë¡œ ì´ˆê¸°í™”ëœ ìƒˆë¡œìš´ ì°¨ì›ì˜ FFN$$(D \times K)$$ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤**.
- $$K$$: downstream taskì—ì„œì˜ class ê°œìˆ˜ì…ë‹ˆë‹¤.

ë˜í•œ, ViTëŠ” Fine-tuningì‹œ Pre-trainingì—ì„œ ì‚¬ìš©í•œ ì´ë¯¸ì§€ë³´ë‹¤ ë†’ì€ í•´ìƒë„ì˜ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ ì„±ëŠ¥ì´ ë” í–¥ìƒë©ë‹ˆë‹¤.
    - $$N \times (P \times P \times C)$$ì—ì„œ $$N$$ì´ ì¦ê°€í•˜ì—¬ ê³µê°„ì ì¸ contextë¥¼ ë” ì˜ ì´í•´í•œë‹¤.

<span style="color:orange"> í•˜ë‚˜ $$N$$ ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡, Position embeddingì˜ ì˜ë¯¸ê°€ ëª¨í˜¸í•´ì§€ê¸° ë•Œë¬¸ì— </span>, ì´ ê²½ìš°ì—ëŠ” <span style="color:lightgreen"> 2ì°¨ì› position embedding ì‚¬ìš©</span>ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

****
# Experiment ğŸ—‚
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/0f7a4101-3ce0-478e-a7f6-9638259a4c6a)

ì„±ëŠ¥ì€ í•™ìŠµ ë°ì´í„°ê°€ ë§ì„ ê²½ìš° ê²½ìŸëª¨ë¸ì— ë¹„í•´ ì••ë„ì ìœ¼ë¡œ ì¢‹ìœ¼ë‚˜, ì ì€ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ë©´ ì„±ëŠ¥ì´ ì•ˆ ì¢‹ì€ ëª¨ìŠµì…ë‹ˆë‹¤.

![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/2607118f-5b88-497f-8731-bdb7f47f0e2f)

ìœ„ì²˜ëŸ¼ ë§ì€ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ í•™ìŠµí•˜ë©´, ViTì˜ embedding filterê°€ ê¸°ì¡´ ë°©ì‹ì¸ CNN filterì™€ ë™ì¼í•œ ëª¨ìŠµì…ë‹ˆë‹¤.

****
# Reference ğŸ§¿
[ViT](https://arxiv.org/pdf/2010.11929.pdf)
