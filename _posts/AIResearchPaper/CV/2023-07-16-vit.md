---
layout: single
title: "[ë…¼ë¬¸ ë¶„ì„] AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE"
categories: AIPaperCV
tag: [Computer Vision, ViT, Vision Transformer]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/vit.png
sidebar:
    nav: "docs"
---

[**ë…¼ë¬¸**](https://arxiv.org/pdf/2010.11929.pdf)

****
# Summary ğŸ“Œ
- ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ê°œì˜ **patches(1ì°¨ì› ì‹œí€€ìŠ¤)** ë‚˜ëˆ„ê³ , ì¸ì½”ë”ì˜ ì¸í’‹ìœ¼ë¡œ í™œìš©.
- ì£¼ë¡œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ ì‹œ ëª¨ë¸ ì„±ëŠ¥ì´ ìš°ìˆ˜í•˜ë‹¤.
    - TransformerëŠ” ê³µê°„ íŠ¹ì§•ì„ ìƒëŒ€ì ìœ¼ë¡œ ëœ ë°˜ì˜í•˜ì—¬ CNNì— ë¹„í•´ inductive biasesê°€ ë‚®ë‹¤.
        - ë‚®ì€ inductive biasëŠ” ì¼ë°˜í™” ëŠ¥ë ¥ì„ ì €í•˜ì‹œì¼œ, ì ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ ì‹œ ëª¨ë¸ ì„±ëŠ¥ì´ ë§¤ìš° ì €ì¡°í•˜ë‹¤.

> Inductive bias: í•™ìŠµ ì‹œì—ëŠ” ë§Œë‚˜ë³´ì§€ ì•Šì•˜ë˜ ìƒí™©ì— ëŒ€í•˜ì—¬ ì •í™•í•œ ì˜ˆì¸¡ì„ í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ì¶”ê°€ì ì¸ ê°€ì • (CVì—ì„œëŠ” ì´ë¯¸ì§€ íŠ¹ì„±ì— ëŒ€í•œ localityì™€ ê°™ì€ ê³µê°„ì  íŠ¹ì„±).

****
# Preliminaries âœ


****
# Introduction ğŸ™Œ
ê·¸ê°„ ë°©ëŒ€í•œ ë°ì´í„°ì…‹ ì²˜ë¦¬ì—ë„ saturating performance ë¬¸ì œì—ì„œ ììœ ë¡œìš´ TransformerëŠ” NLP ì˜ì—­ì—ì„œ ê°ê´‘ë°›ì•„ ì™”ë‹¤.
- Training: ë°©ëŒ€í•œ ë°ì´í„° corpus í•™ìŠµ
- Fine-tuning: downstream taskì— ëŒ€í•œ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ fine-tuning.

í•˜ì§€ë§Œ, CV ë¶„ì•¼ì—ì„œëŠ” self-attentionê³¼ ìœµí•©í•˜ê³ ì í•œ ë…¸ë ¥ì´ ìˆì—ˆìœ¼ë‚˜, h/w ê°€ì†ê¸°ì— ì•Œë§ì€ ë¹„ìœ¨ë¡œ scaling ë˜ì§€ ì•ŠëŠ” ë“± ì—¬ëŸ¬ ê°€ì§€ ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤.

í•˜ì—¬ ë‹¹ì‹œ CNN ë„¤íŠ¸ì›Œí¬ê°€ ì—¬ì „íˆ SOTAë¥¼ ë‹¬ì„±í•˜ê³  ìˆì—ˆë‹¤.

****
# Problem Definition ğŸ§¿
- **Given** 2D image dataset $$\mathcal{D}$$.
- **Produce** a pre-trained Transformer model $$\mathcal{T}$$.
- **Such that** $$\mathcal{T}$$ competes with CNN-based models on $$\mathcal{D}$$.

****
# Methodology âœ¨
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/8204eabe-c472-4f9b-b289-f2c22c8f41b3)

## Backbone
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/9161b45e-9732-419d-be71-18d90452661d)

$$Patch + Position\ Embedding + Learnable\ [class]\ Embedding$$

- **Patch**: ì¸í’‹ ì´ë¯¸ì§€($$x$$)ë¥¼ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¡œ ì§€ì •ëœ patch í¬ê¸° ì´ë¯¸ì§€ ë¶„í• .
- **Position Embedding**: í•´ë‹¹ ì´ë¯¸ì§€ì˜ class labelì„ ë‚˜íƒ€ë‚´ëŠ” í•™ìŠµ ê°€ëŠ¥í•œ embedding ì¶”ê°€. 
- **Learnable [class] Embedding**: ê° patchì— ëŒ€ì‘ë˜ëŠ” Position Embedding ì¶”ê°€.

## Transformer Encoder
![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/9abafa08-c6cf-4751-a6c5-11720ee4d309)

- Backboneì˜ patchë“¤ì„ ì¸ì½”ë” ì¸í’‹ìœ¼ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ 1ì°¨ì› sequenceë¡œ flatten.
    - ì´ë•Œ ê° patchì˜ ìœ„ì¹˜ ì •ë³´ ìœ ì§€.


****
# Experiment ğŸ—‚

****
# Conclusion ğŸŒ·

****
# Reference ğŸ§¿