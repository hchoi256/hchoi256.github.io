---
layout: single
title: "[ë…¼ë¬¸ ë¶„ì„] Sparse DETR (ICLR 2022)"
categories: AIPaperCV
tag: [Computer Vision, Object Detection, DETR, Transformer]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/od.png
sidebar:
    nav: "docs"
---

<!-- <span style="color:blue"> ???? </span> -->

[**ë…¼ë¬¸**](https://arxiv.org/abs/2111.14330)

****
# í•œì¤„ìš”ì•½ âœ”

****
# Background ğŸ±

****
# Introduction ğŸ™Œ

****
# Related Work ğŸ˜‰

****
# Problem Definition âœ
                Given a large pre-trained language model

                Return a quantized model

                Such that it outperforms the performance of the original model in terms of inference time while retaining accuracy.

****
# Challenges and Main IdeağŸ’£
**C1)**

**C2)**

**C3)**

**Idea)**

****
# Proposed Method ğŸ§¿

****
# Experiment ğŸ‘€

****
# Open Reivew ğŸ’—

****
# Discussion ğŸŸ

****
# Major Takeaways ğŸ˜ƒ

****
# Conclusion âœ¨
## Strength
## Weakness

****
# Reference