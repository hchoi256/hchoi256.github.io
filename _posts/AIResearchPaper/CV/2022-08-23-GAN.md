---
layout: single
title: "[논문 분석] Generative Adversarial Nets, GAN (NIPS 2014)"
categories: AIPaperCV
tag: [GAN, Generative Models]
toc: true
toc_sticky: true
toc_label: "쭌스log"
#author_profile: false
header:
    teaser: /assets/images/posts/gan.png
sidebar:
    nav: "docs"
---

[**논문**](https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)

****
# 들어가면서
이 논문을 읽기 전, 나는 GAN이라는 기술의 정의와 막연한 쓰임 정도만 알고 있었다.

**GAN**은 **생성자와 구분자가 서로 적대적으로 대치**를 거듭하며 모델의 성능 향상을 도모하는 방법이다.

도둑과 경찰의 예시에서, 도둑은 위조 지폐를 진짜처럼 만들어내는 '생성자', 경찰은 위조 지폐를 위조라고 판별하는 구분자 역할을 이행한다.

도둑은 경찰의 눈을 속이기 위해 더 진짜같은 위조 지폐를 만들고자 할 것이고, 경찰은 그런 도둑의 꾀에 넘어가지 않기 위해 더욱 면밀하게 검사를 반복할 것이다.

이러한 일련의 과정 속에서, 모델의 성능은 괄목할만한 성장을 거듭하게 될 것이라는 것이 GAN의 핵심 이론이다.

> 이것은 1대1 턴제 게임 구현에 유용하게 사용되는 [minimax 알고리즘](https://hchoi256.github.io/others/ml-teeko-minimax/)과 매우 유사하게 동작한다.

****
# 배경
**[간단히] 기존 생성 모델의 한계:**
1. 기존의 확률 기반 모델(예: 마르코프 체인)은 실제 데이터와 유사한 새로운 데이터를 생성하기 위해 확률 분포를 모델링하는 과정에서 연산 복잡도가 높았습니다. 특히 고차원 데이터의 경우, 확률 분포를 완벽하게 모델링하는 것은 매우 어려운 문제였습니다.
2. 기존의 확률 모델은 매개변수가 역전파를 통해 업데이트됨에 따라 생성하고자 하는 새로운 데이터의 확률 분포가 굉장히 가변적으로 변할 수 있었습니다. 이는 매개변수의 업데이트에 따른 우도 기울기를 정확하게 추정하는 것이 어려워진다는 의미였습니다. 이로 인해 모델의 학습이 불안정해지고, 적절한 매개변수 우도 기울기를 찾아 업데이트하는 것이 어려워지는 문제가 있었습니다.

2015년 기준으로 분류 모델은 큰 발전을 이루었지만, 심층 생성 모델(Deep Generative Models)은 매개변수에 따라 가변적인 확률 분포를 처리하는 것에 어려움을 겪었습니다.

이는 매개변수 값이 변함에 따라 확률 분포의 우도 기울기(likelihood gradient)를 예측하기 어렵게 만들었고, 결과적으로 많은 기울기 근사값을 도출하게 되었습니다.

이전에 GAN이 등장하기 전의 생성 모델들은 실제와 유사한 이미지 $$A$$를 생성하려면 $$A$$의 확률 분포를 생성해야 했습니다. 이를 위해 **MCMC(Markov Chain Monte Carlo)**와 같은 방법을 사용하여 이전 상태를 고려하여 다음 값을 생성하는 복잡한 수식 연산 과정이 필요했습니다.

간단히 말하자면, 예를 들어 이미지 $$A$$의 $$(0, 0)$$ 좌표에 색상 정보(데이터)가 있다면 주변 픽셀의 분포를 고려하여 어떤 값이 나와야 하는지를 계산하여 확률 분포를 근사화하려는 시도를 했다는 것입니다.

이러한 방식은 작은 모델을 생성하는 데에는 탁월했을 수 있지만, 만약 사진이나 그림과 같은 큰 크기의 데이터를 생성해야 한다면 너무 많은 연산을 요구할 것입니다.

그래서 GAN이 등장하게 되었는데, 이는 MCMC 방법과 같은 확률 연산을 근사화하지 않고, 두 개의 딥러닝 네트워크를 만들어 서로가 서로를 견제하는 형태의 구조를 가지게 되었습니다.

~~이러한 배경에 착안하여, 뒤죽박죽인 데이터 분포에 존재하는 까다로운 우도 기울기를 명시적으로 다루는 것이 아닌, 원하는 이상적인 분포에서만 데이터를 생성하자는 '생성 모델'이라는 것이 주목받기 시작했다.~~

~~하여 'Generative Stochastic Networks (GSN)'라는 *Marcov 모형* 에 기반한 생성 모델이 탄생하였고, 이후 GSN에서 Marcov 확률 모형의 개념을 제거하고 우리가 아는 요즘의 생성 모델 형태로 진화하게 되었다.~~

여기서 생성 모델이란 실존하지 않으나 현실에 있을 법한 데이터를 생성할 수 있는 모델이다.

****
# INTRODUCTION
GAN이 등장하기 앞서, 딥러닝은 깊고 풍부한 모델을 만드는 것에 초점이 맞춰져 있었고, 당시 최대 성과는 Dropout과 역전파에 기반한 분류 모델을 고안해낸 것이었다.

반면, 생성 모델은 [배경](#배경)에서 언급한 바와 같이 역전파 과정에 포함되는 MLE 계산 과정의 까다로운 확률 연산때문에 연구 진척도가 매우 더딘 상태였다.

이러한 확률 모형의 한계를 타파하고자 등장한 것이 바로 **GAN**이다.

![image](https://user-images.githubusercontent.com/39285147/186082398-965b03e9-8a6c-49b1-80a8-a9b244b7c8d6.png)

앞서 언급했던 것처럼, GAN에는 두 가지 요소가 존재한다; **G(Generator)**와 **D(Discriminator)**.

G는 D가 실수할 확률을 최대로 만들어야 하고, D는 그런 G의 시도를 무력화해야 하며, 이러한 반복은 D가 G를 막는 것이 불가능해질 때까지 지속된다.
- G: 가짜 이미지를 진짜로 분류하도록 학습한다 (= 기존 데이터 분포를 잘 **근사**하도록 학습한다).
- D: 진짜 이미지는 진짜로, 가짜는 가짜로 잘 분류하도록 학습한다. 

> 목적함수에서 D와 G는 서로에게 **간접적으로** 영향을 주면서 각자 학습을 이어간다 --> 충분한 capacity 有 --> 학습 성능 ↑

G와 D 모두 Multilayer 퍼셉트론을 가지고, 역전파를 통해 학습이 진행된다 (*Markov 체인과 같은 확률론적 모형이 필요가 없다!*).

G는 **순전파 과정**에서 Multilayer 퍼셉트론에 **무작위 noise**를 방출하여 새로운 데이터를 생성한다.
- 학습 데이터 분포를 생성 모델이 잘 학습한 후(= 인풋 이미지와 유사하게 모델링 가능), 약간의 noise를 덧대면 높은 퀄리티의 현실에 존재하지 않는 다양한 얼굴 사진을 만들어낼 수 있을 것이다.

![image](https://github.com/hchoi256/ai-boot-camp/assets/39285147/d437b94b-870f-4d32-bda1-6958f36d5cff)
- 위 그림에서 가장 높은 확률로 어떤 특징을 잘 예측할 수 있는 극대점으로 부터 약간의 noise를 덧대어 빨간색으로 표시된 부분의 데이터라는 전혀 본적없는 새로운 얼굴 사진이 생성된다.

만약 생성 모델이 학습 데이터(인간의 얼굴 이미지에 존재하는 여러 특성)를 *잘 학습했다면*, 그러한 학습 데이터 분포와 유사한 새로운 이미지를 잘 생성할 것이다.

여기서, '잘 학습했다면'이란 이미지 내에서 각 얼굴 특성(i.e., 코, 입술)을 잘 나타내는 픽셀들에 대한 가중치가 확률론적으로 각각 높게 잘 부여된 것을 의미한다 (= 통계적으로 평균적인 특징을 가지는 데이터를 쉽게 생성할 수 있다).

이후, 생성된 output은 **qualitative**과 **quantitative** 방법을 통해 평가가 치뤄진다.

****
# GAN 수식
![image](https://user-images.githubusercontent.com/39285147/186083524-71a8c435-1fc1-4aa4-ae8b-fe045edb09a8.png)

- *V(D, G)*: 목적 함수(objective function); 높을수록 판별자(D)가 잘 판별해낸다.
    - G는 목적함수를 낮추고, D는 높이는 것을 목표한다.
- *D*: [0, 1] 1에 가까울 수록 입력값이 Real하다.
- ![image](https://user-images.githubusercontent.com/39285147/186129691-47747b42-6f0b-485e-bab9-5ba92e27752b.png): 원본 데이터 분포($$p_{data}(x)$$)에서 샘플 하나 추출.
- ![image](https://user-images.githubusercontent.com/39285147/186129740-cc47506a-c2c1-4a2e-9661-8b747c3d33a8.png): noise 분포($$p_{z}(z)$$)에서 채취된 noise를 덧대어 생성한(G) 이미지가 얼마나 진짜같은지(D) 나타내는 척도의 기댓값.

![image](https://user-images.githubusercontent.com/39285147/186082398-965b03e9-8a6c-49b1-80a8-a9b244b7c8d6.png)

- 파란 점선: 판별자(D) 예측 결과.

궁극적으로, 생성된 이미지가 원본 이미지와 차이가 없어져 D(G(z))은 $$1 \over 2$$로 수렴하고, 생성 분포(G)는 기존 데이터 분포에 잘 근사할 것이다.
- 여기서, 1/2이란 0 fake도 아니고 1 real도 아닌 중간지점, 즉 D에 의해 **구별 불가능한** 상태의 G(z)를 의미한다.

## GAN 학습 순서
GAN에서는 생성자(G, Generator)와 판별자(D, Discriminator)라고 불리는 두 개의 네트워크를 번갈아가며 학습시킨다 (학습 순서는 바뀌어도 괜찮다).

1. 판별자(D)의 학습:
- 먼저, 실제 데이터와 생성자(G)에 의해 생성된 가짜 데이터를 판별자에 입력한다. 판별자는 실제 데이터와 가짜 데이터를 구분하기 위한 이진 분류를 수행한다. 이때, 판별자의 가중치와 편향을 업데이트하여 실제 데이터와 가짜 데이터를 잘 구별할 수 있도록 학습한다. 이 단계에서 생성자의 가중치는 고정된 상태로 유지된다.

2. 생성자(G)의 학습:
- 판별자(D)가 학습된 후에는 생성자(G)의 차례이다. 생성자에 무작위한 잠재 벡터를 입력으로 주고, 생성된 가짜 데이터를 판별자에 입력한다. 이때, 생성자는 생성한 가짜 데이터를 실제 데이터처럼 보이도록 조정하기 위해 자신의 가중치와 편향을 업데이트한다. 이 단계에서 판별자의 가중치는 고정된 상태로 유지된다.

## GAN 역전파
목적함수는 **Convex 형태**이기 때문에 역전파 과정에서 빠르게 global optimum에 도달할 수 있다.

![image](https://user-images.githubusercontent.com/39285147/186086993-484a2175-c93e-4ee0-bca4-9e2f8c7e5e83.png)

[*Discriminator*]

![image](https://user-images.githubusercontent.com/39285147/186087209-a04c0c88-ba6a-4595-bb18-b438ea03dad9.png)

- 실제 데이터 $$logD(x^i)$$는 1이 되게끔, 가짜 데이터 $$log(1-D(G(z^i)))$$는 0이 되게끔 학습한다; **목적함수 증가**.

[*Geneator*]

![image](https://user-images.githubusercontent.com/39285147/186087706-c092c4ec-513f-497d-9425-dcf1c7790cd5.png)

- 가짜 데이터가 실제 데이터를 닮도록 학습한다; **목적함수 감소**.

****
# GAN 증명 - Global Optimality
순간마다 G와 D가 각각 어떤 순간에 global optima에 도달하는지 조사한다.

## 전제 1: 고정된 G에 대한 최적의 D
![image](https://user-images.githubusercontent.com/39285147/186091468-e663efd8-7984-4b24-b03f-de5c63fea426.png)

- 첫째줄: 연속확률분포 공식
- 둘째줄: dz --> dx 치환 (가짜데이터(z)를 도메인으로 활용한다).

> 연속확률분포 공식
>
> ![image](https://user-images.githubusercontent.com/39285147/186091811-f8ff7cbb-8648-4fae-9edb-d3f889a3825f.png)

이후, 목적함수에 미분을 취해서 최대값을 갖는 지점에 대한 x값은 하기와 같다.

![image](https://user-images.githubusercontent.com/39285147/186091383-7d3632f3-c3a0-4928-a30c-c5107ee8b980.png)
![image](https://user-images.githubusercontent.com/39285147/186094774-0e0ed29d-1eff-454c-b669-bbe8048d0005.png)

- *C(G)*: Convergence(G)로 G가 수렴하는 형태, 즉 최적의 D를 말한다.

해당 논문에서는 ![image](https://user-images.githubusercontent.com/39285147/186129883-ad5957e3-7c26-4bfa-aeaf-8d8624c5804c.png)의 최댓값 지점의 x값은 ![image](https://user-images.githubusercontent.com/39285147/186129991-1d273c1f-eec4-45cc-bf04-023dfe1f0a17.png)이라는 점을 이용해서 상기와 같은 D 최적값을 도출한다.

## 전제 2: G의 global optimum = D의 global optimum
![image](https://user-images.githubusercontent.com/39285147/186094703-76f64fd2-1bc7-495c-bec5-4c8cdc2de830.png)

앞선 과정에서 우리는 **최적의 D**를 구했다.

하여 우리는 이제 그 값을 활용해서 **최적의 G** 또한 도출할 수 있다.

하기는 *최적의 D*를 활용해서 $$C(G)$$를 재정의한 모습이다.

![image](https://user-images.githubusercontent.com/39285147/186095528-3704426a-d5c9-43e2-9e39-31ffe45b2232.png)

> [**KL Divergence**](https://github.com/hchoi256/ai-terms/blob/main/entropy.md): 서로 다른 두 확률 분포 사이의 다름의 정도를 나타낸다.

> For ![image](https://user-images.githubusercontent.com/39285147/186096029-c6fae746-0d03-4a57-97e9-eb69c8f79cf1.png), ![image](https://user-images.githubusercontent.com/39285147/186095367-c4f7fbe9-1da1-44ce-8e3c-5c8e59f2ae58.png)

KL Divergence는 단순히 서로 다른 두 확률 분포 간의 차이를 나타낼 뿐, **Distance Metric**으로써 활용할 수 없기 때문에 **JSD**를 통해 수식을 재정의한다.
- Distance Metric은 거리값이기 때문에 음수값이 없어서 그 최소값이 0을 갖는게 특징이다.

> JSD: 서로 다른 두 확률 분포 사이의 거리를 나타낸다.
>
> $$ D_{JS}(p||q)=\frac{1}{2}D_{KL}(p||\frac{p+q}{2})+\frac{1}{2}D_{KL}(q||\frac{p+q}{2}) $$

![image](https://user-images.githubusercontent.com/39285147/186096637-ca65d8ef-14e3-4d4c-8e3c-541e6468525c.png)

원본 분포($$p_{data}$$)와 생성 분포($$p_g$$)가 동일할 때, 그 사이의 거리는 0이 되는 모습이다.

하여 **JSD 값 역시 0으로 수렴**하고 목적함수의 값이 최적의 global optimum이 **-log(4)**이 되게된다.

이러한 지점이 바로 해당 논문에서 가르키는 global optimum이며, 이로써 global optimum이 존재함을 증명했다.

또한, global optimum에서의 최적의 $$G*$$ 값 또한 구할 수 있었다.

****
# GAN 알고리즘
![image](https://user-images.githubusercontent.com/39285147/186098063-6c0711ab-39aa-4c17-8003-41947d9f915c.png)

**Pseudocode**를 보면서 이해하는 것이 직관적일 것이다.

![image](https://user-images.githubusercontent.com/39285147/186104665-02aabb4b-dea6-4b43-b5e4-8185b785d94d.png)

여기서, 생성자는 상기 알고리즘 부분에서만 업데이트가 발생하는 모습인데, 이는 판별자 부분은 생성자(G)가 없어서 G에 대하여 미분을 하면 상수 취급을 받아 0이 된다. 

그 외 상기 모형에 자세한 설명이 나와있으니, 추가적인 설명은 생략한다.

****
# GAN 한계와 해결
## Gradient Vanishing
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/391b11a8-3521-457a-8276-f9d6dee933d5)

상기 이미지에서 기존 Generator의 목적함수 $$log(1-D(G(z)))$$는 $$D(G(z))$$가 작으면 Gradient Vanishing 문제가 발생하여 G 생성자의 학습이 어느 순간 더디게 발생한다.

하여 이 문제점을 타파하고자 Generator의 목적함수를 $$-log(D(G(z)))$$로 사용하면 그림에서 파란색 선처럼 Gradient Vanishing 현상을 해결 가능하다.

****
# 결과
![image](https://user-images.githubusercontent.com/39285147/186098600-7d47b963-9c81-47e1-9f87-bf558aa210f5.png)

테스트를 위해 사용된 이미지들은 선별된 데이터들이 아닌 무작위로 뽑힌 것들이다.

노란색 박스가 기존 이미지이고, 그 옆으로 나란히 GAN이 생성한 이미지들이 나열되있다.

이를 통해, 해당 논문에서는 생성된 이미지들은 따로 모델이 사전에 외워두거나 학습한 것들이 아니라 GAN 생성모델이 새로이 생성해낸 이미지들 임을 다시 한 번 강조한다.

![image](https://user-images.githubusercontent.com/39285147/186099701-d202ab48-1942-4095-a5bf-c5b3dd6b09f1.png)

또한, 상기 이미지처럼 생성모델이 noise을 덧대면서 *latent vector* 이미지 형태를 변형하여 아에 다른 숫자를 만들어내는 것도 가능한 모습을 확인할 수 있다.

> Latent vector: 생성모델의 최종 출력이 아닌 학습 도중 중간에 잠정적으로 발생되는 벡터들이다.

![image](https://user-images.githubusercontent.com/39285147/186106133-d553b4d6-1538-4311-ba6c-bee37169704d.png)

상기 실험은 MNIST, TFD 데이터셋에 대해 성능 평가를 한 모습이다.

결과적으로, GAN은 다른 생성모델에 비해 더 **또렷한** 이미지 생성 능력을 보여주었고, 이후 CycleGAN, StarGAN 등 다양한 확장 버전이 등장하게 되었다.

다음 시간에는 이러한 GAN 기술을 확장하여, 사진에서 사람 얼굴 표정 등을 바꾸는 **image-to-image translation** 작업을 처리하는 [CycleGAN](https://hchoi256.github.io/aipapercv/CycleGAN/)에 대하여 살펴보자.