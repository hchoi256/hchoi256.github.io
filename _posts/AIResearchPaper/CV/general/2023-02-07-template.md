---
layout: single
title: "[ë…¼ë¬¸ë¶„ì„] "
categories: AIPaperCV
tag: [Computer Vision, CLIP, Contrastive Learning]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
author_profile: false
header:
    teaser: /assets/images/posts/ai-thumbnail.png
sidebar:
    nav: "docs"
---

<span style="color:sky"> [ë…¼ë¬¸ë§í¬](https://arxiv.org/abs/2103.00020)  </span>

****
# í•œì¤„ìš”ì•½ âœ”
- Contrastive Languageâ€“Image Pre-training (CLIP)ì€ Image-Languageë¥¼ ì„œë¡œ Contrastive learningí•˜ëŠ” ë°©ë²•ë¡ ì´ë‹¤.
    - í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì™€ ê·¸ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë§¤ì¹­ì‹œí‚¤ëŠ” ë¬¸ì œë¥¼ í‘¸ëŠ” ëª¨ë¸.

****
# Preliminaries ğŸ±
## Image Captioning
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/443420a2-9832-4d92-a101-4b4258eda4a9)

- Traditional Image Captioning with a focus on raw image pixels generates language descriptions for images.

## Zero-Shot Prediction
- Zero-Shot Predictionì€ íŠ¹ì • downstream taskì˜ datasetì„ ì¼ì ˆ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê¸°í•™ìŠµ ëª¨ë¸ë¡œ ì¶”ë¡ í•˜ëŠ” ê²ƒ.

****
# Challenges and Main IdeağŸ’£
NA

****
# Problem Definition â¤ï¸
Given a dataset $\mathcal{D}$ with pairs of an image and a text.

Return a pre-trained model $\mathcal{S}$.

Such that $\mathcal{S}$ achieves the SOTA performance in various tasks.

****
# Proposed Method ğŸ§¿
## Training Dataset
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/13e14dbd-8327-49c0-ad48-1539165fcd94)

- ì¸í„°ë„·ì— ì¡´ì¬í•˜ëŠ” ì•½ 4ì–µ ê°œì˜ (image ,text) ë°ì´í„° ìŒ (ImageNetì€ 1ì²œ 4ë°±ë§Œì¥ì˜ ë°ì´í„°ê°€ ì¡´ì¬í•œë‹¤).
    - ê°€ë ¹, ìƒê¸° ì´ë¯¸ì§€ì—ì„œ `(<ê°•ì•„ì§€ ì´ë¯¸ì§€>, â€œpepper the aussie pupâ€)` .

## Training
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/92fc8bec-0954-4968-a7ce-be95e4b129d2)

### Contrastive Pre-training
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/7105af50-3ad0-4cd3-b467-c4bd14f25eee)

- Zero-shot í•™ìŠµì´ë¼ì„œ Pre-training ì´í›„ ì¶”ê°€ì ì¸ fine-tuning ê³¼ì •ì´ ì—†ë‹¤.
- cosine similarity ì—°ì‚°ìœ¼ë¡œ (ì´ë¯¸ì§€, í…ìŠ¤íŠ¸) ë§¤ì¹­ì„ í•™ìŠµí•œë‹¤.

### Image Encoder
ì´ë¯¸ì§€ ë²¡í„°í™”.
- ì´ë¯¸ì§€ $X_{i,j}$ë¥¼ Image Encoderì— í†µê³¼ì‹œì¼œ ë²¡í„°ê°’ $X^v_{i,j}$ìœ¼ë¡œ í‘œí˜„í•œë‹¤.
    - $X_{i,j}$: $j$ë²ˆì§¸ Batchì˜ $i$ë²ˆì§¸ ì…ë ¥ ì´ë¯¸ì§€.
    - $N$: batch size.
- $X^v_{i,j}$ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^O_{image}$ë¥¼ ê³±í•˜ì—¬ $X^{vw}_{i,j}$ë¥¼ ì–»ëŠ”ë‹¤.
- $X^{vw}_{i,j}$ì— L2-normalizationì„ ì ìš©í•˜ì—¬ $I_{i,j}$ ì„ë² ë”©ì„ ì–»ëŠ”ë‹¤.

### Text Encoder
í…ìŠ¤íŠ¸ ë²¡í„°í™”.
- í…ìŠ¤íŠ¸ $Y_{i,j}$ë¥¼ Text Encoderì— í†µê³¼ì‹œì¼œ ë²¡í„°ê°’ $Y^v_{i,j}$ìœ¼ë¡œ í‘œí˜„í•œë‹¤.
    - $Y_{i,j}$: $j$ë²ˆì§¸ Batchì˜ $i$ë²ˆì§¸ ì…ë ¥ Text.
    - ë¬¸ì¥ì˜ ëì¸ `[EOS]` í† í°ì„ í•´ë‹¹ textë¥¼ í‘œí˜„í•˜ëŠ” ë²¡í„°ë¡œ í•™ìŠµì‹œì¼œ $T$ ê³„ì‚°.
- $Y^v_{i,j}$ì— ê°€ì¤‘ì¹˜ í–‰ë ¬ $W^O_{text}$ë¥¼ ê³±í•˜ì—¬ $Y^{vw}_{i,j}$ë¥¼ ì–»ëŠ”ë‹¤.
- $Y^{vw}_{i,j}$ì— L2-normalizationì„ ì ìš©í•˜ì—¬ $T_{i,j}$ ì„ë² ë”©ì„ ì–»ëŠ”ë‹¤.

### Cosine Similarity
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/4eb53bf5-c078-4dde-886a-92910a4f9337)

- ì´ì „ ë‹¨ê³„ì—ì„œ ì´ë¯¸ L2 ì •ê·œí™”ë¥¼ ê±°ì³¤ê¸° ë•Œë¬¸ì— ë‹¨ìˆœ ë‚´ì ìœ¼ë¡œ cosine similarity ê³„ì‚° ê°€ëŠ¥.

### Loss Function
$\mathcal{L}=\frac{<ImageLoss>+<TextLoss>}{2}$

ê°€ë ¹, $ImageLoss$ëŠ” í•˜ê¸° ì´ë¯¸ì§€ì—ì„œ ì´ˆë¡ìƒ‰ ì ì„  ë°©í–¥ìœ¼ë¡œ $1$ë²ˆì§¸ batchì— ëŒ€í•´ ê³„ì‚°í•œë‹¤.

![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/7d28447f-2791-4eaf-9e98-c1558f7fce0d)

## Create Classifier from Label Text
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/5299d9e3-6392-4a66-8d35-ce5af3555fc9)

- Downstream taskì˜ datasetì— ì¡´ì¬í•˜ëŠ” labelì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.
    - i.e., plane, car, dog ,etc.
- ê° labelì„ â€œa photo of a (object)â€ phraseì—ì„œ (object)ì˜ íŒŒë¼ë¯¸í„° ê°’ìœ¼ë¡œ í™œìš©í•˜ì—¬ text $\mathcal{T}$ë¥¼ ìƒì„±.
- $\mathcal{T}$ë¥¼ Text Encoderì— í†µê³¼ì‹œì¼œì„œ Text Vector $\bar{\mathcal{T}}$ë„ì¶œ.

## Zero-shot Prediction
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/2f9421fe-9b17-4694-8308-9528a720feea)

- Downstream taskì˜ ì¸í’‹ ì´ë¯¸ì§€ë¥¼ Image Encoderì— í†µê³¼ì‹œì¼œì„œ ì´ë¯¸ì§€ ë²¡í„° $I_i$ íšë“.
    - Image Encoderì€ pre-training ë‹¨ê³„ì—ì„œ í•™ìŠµë¨.
- $I_i$ê³¼ ì´ì „ì— êµ¬í•œ Text Vector $\bar{\mathcal{T}}$ ê°„ì˜ cosine similarity ê³„ì‚°.

****
# Experiment ğŸ‘€
ì‹¤í—˜ ë‚´ìš©ì´ ë§ì•„ì„œ ì£¼ìš”í•œ ê²°ê³¼ë§Œ ë³´ê³  ë‚˜ë¨¸ì§€ëŠ” ê°ì„¤í•œë‹¤.

## Classification
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/2903ce96-22c5-4cbb-ab92-f196021be04d)

- **Linear Probe:**
    - Fine-Tuningì„ í•˜ëŠ” ë°©ë²• ì¤‘ í•˜ë‚˜ë¡œ Outputì„ ì¶œë ¥í•˜ëŠ” Top Layer ë¶€ë¶„ì„ ë°ì´í„°ì…‹ë³„ë¡œ ë‹¤ë¥´ê²Œ í•™ìŠµí•˜ê³ , ê·¸ ì´ì „ ë ˆì´ì–´ì˜ parametersëŠ” ê³ ì •í•œë‹¤.
- 27ê°œì¤‘ 16ê°œì˜ ë°ì´í„°ì…‹ì—ì„œ CLIPì˜ Zero-Shot Predictionì´ Linear Probe ë³´ë‹¤ ì„±ëŠ¥ì´ ë¹„êµì  ì¢‹ì€ ê²ƒì„ í™•ì¸.

## v. Few-shot
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/2b528307-de86-47ef-8b3c-649810f0c33f)

## Applicability
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/a2345887-8d01-4925-894c-f81704ce2177)

- CLIP-ViTëŠ” ê¸°ì¡´ ImageNetì˜ pre-trained ëª¨ë¸ì— ë¹„í•´ ë‹¤ì–‘í•œ taskì— ë” ìœ ì—°í•˜ê³  ì¼ë°˜í™”ëœ ëª¨ë¸.

****
# Open Reivew ğŸ’—
NA

****
# Discussion ğŸŸ
NA

****
# Major Takeaways ğŸ˜ƒ
NA

****
# Conclusion âœ¨
NA

****
# Reference
[[1] ë…¼ë¬¸ ë¦¬ë·°: CLIP](https://dealicious-inc.github.io/2021/03/22/learning-transferable-visual-models.html)