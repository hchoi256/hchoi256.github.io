---
layout: single
title: "[논문분석] Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization (ICCV 2017)"
categories: AIPaperCV
tag: [Computer Vision, CAM, Grad-CAM, Object Localization]
toc: true
toc_sticky: true
toc_label: "쭌스log"
author_profile: false
header:
    teaser: /assets/images/posts/od.png
sidebar:
    nav: "docs"
---

<span style="color:sky"> [논문링크](https://arxiv.org/pdf/1610.02391.pdf) </span>.

****
# 한줄요약 ✔
- 딥러닝 모델의 결과의 근거를 유추할 수 없다는 blackbox 현상을 해결하고자 object localization을 수행하는 `CAM` 이 고안되었다.
    - Constraint: GAP 이후 FC layer 한개만 연결되어 있는 구조여야 한다.
- 특정 구조에 국한된 `CAM` 의 활용도를 확장하고자 `Grad-CAM` 이 등장.
    - 기존 CAM에서 FC-layer의 weights가 아닌 Gradient을 기반으로 특정 class에 대한 feature map의 영향력을 계산.
- `CAM`과 `Grad-CAM`의 성능은 같지만, 활용 범위만 다르다.

****
# Preliminaries 🍱
## CAM
### Model Architecture
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/7f1ac706-7a16-42be-b7ec-8b22ff21a26b)

- CNN의 최종 layer 출력인 feature map에 channel-wise 계산법인 GAP를 적용하여 feature map의 spatial info.를 유지 (기존 CAM에서는 1차원 배열로 point-wise하게 flatten시킨 후 fc-layer의 인풋으로 활용한다).
    - 각 채널은 이미지에서 각 객체의 특징을 표현한다 (채널 개수=커널 개수).
    
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/49132aea-08ab-4392-9494-dab4c2ed9386)

- 이후, FC-layer에서 각 특징을 담고있는 feature map의 평균값을 인풋으로 받고, 각 인풋의 각 class에 대한 민감도를 softmax를 거쳐 weights로 표현한다. 

### Equation
$$Y^c=\Sigma_k w^c_k {1 \over Z} \Sigma_{i,j} A^k_{i,j}$$

- $$Y^c$$: class $$c$$에 대한 score (모델 예측 logit/output).
- $${1 \over Z} \Sigma_{i,j} A^k_{i,j}$$:  feature map $$k$$의 GAP 값.
    - $$Z$$: feature map $$k$$에서 pixel 개수.
- $$w^c_k$$: feature map $$k$$의 class $$c$$에 대한 민감도.
- $$A^k_{i,j}$$: feature map $$k$$의 $$i,j$$에 해당하는 pixel 값.

****
# Challenges and Main Idea💣
**C1)** <span style="color:orange"> CAM은 특정 구조에서만 적용 가능한 모델이다. </span>.

**Idea)** <span style="color:lightgreen"> Grad-CAM은 gradient 계산을 통해 구조에 구애받지 않는다. </span>.

****
# Problem Definition ❤️
**Given** a CNN-based model $$\mathcal{T}$$.

**Return** a model $$\mathcal{S}$$.

**Such that $$\mathcal{S}$$** performs class prediction with reasoning for the output.

****
# Proposed Method 🧿
## Model Architecture
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/5ac56726-477f-454e-9e02-409d201d199b)

- `Grad-CAM`은 `CAM`의 일반화 버전이다.
    - FC-layer에서 weights를 사용하는 `CAM`과 달리 GAP 이후 어떤 network가 뒤따라도 weights를 gradient로 대체한 알고리즘 덕분에 task 수행이 가능하다.

## Loss Function
<span style="color:yellow"> $$L^c_{Grad_CAM}=ReLU(M^c_{i,j})$$ </span>

- $$M^c_{i,j}=\Sigma_k a^c_k A^k_{i,j}$$: 좌표 $$i,j$$의 class $$c$$에 대한 민감도.
    - $$a^c_k={1 \over Z} \Sigma_{i,j} {\partial Y^c \over \partial A^k_{i,j}}$$: gradients.
        - `CAM` 에서의 weights $$w^c_k$$ 를 상기 식으로 대체.

### How to calculate $$a^c_k=w^c_k$$?
`CAM`에서 $$Y^c$$를 계산하는 과정의 feature $$k$$에 대하여 $$w^c_k$$ 를 사용하는 FC-layer 바로 직전 layer는 GAP 결과를 $$F^k$$ 라고 부르겠다.

- <span style="color:yellow"> $$F^k={1 \over Z} \Sigma_{i,j} A^k_{i,j}$$ </span>.

모델 logit인 $$Y^c$$를 GAP 출력 $$F^k$$으로 편미분하여 얻은 gradient는 Chain Rule을 통해 다음 식처럼 $$A^k_{i,j}$$ 를 사용하여 전개될 수 있다.

- <span style="color:yellow"> $$(1)\ {\partial Y^c \over \partial F^k}={{\partial Y^c \over \partial A^k_{i,j}} \over {\partial F^k \over \partial A^k_{i,j}}}$$. <span>

여기서 $$F^k$$ 의 식을 참조하여 각 파라미터에 대한 편미분 값을 다음과 같이 계산할 수 있다. 

- $${\partial Y^c \over \partial A^k_{i,j}}=w^c_k$$.
- $${\partial F^k \over \partial A^k_{i,j}}={1 \over Z}$$.

이 편미분 값을 $$(1)$$에 대입하여 다음 식을 얻을 수 있고, 이를 한 단계 더 전개하면 `Grad-CAM`의 gradient $$a^c_k$$과 `CAM`의 weights $$w^c_k$$ 의 관계가 도출된다.
- <span style="color:yellow"> $$w^c_k={\partial Y^c \over \partial A^k_{i,j}} \cdot Z$$ </span>.
- <span style="color:yellow"> $$\Sigma_{i,j} w^c_k= \Sigma_{i,j} {\partial Y^c \over \partial A^k_{i,j}} \cdot Z=Z \Sigma_{i,j} {\partial Y^c \over \partial A^k_{i,j}}$$ </span>.
    - $$Z=\Sigma_{i,j} 1$$.
        - $$i \times j=Z;\ where\ Z\ is\ \#\ pixels$$.
- $$w^c_k=a^c_k$$.

****
# Experiment 👀
![image](https://github.com/hchoi256/hchoi256.github.io/assets/39285147/3befc3a7-84a3-461b-bfb2-7e207402198d)

`CAM`과 성능 자체는 비슷하니 생략하고, `Grad-CAM`을 사용하여 PASCAL VOC 2012 dataset에서 segmentation 수행 결과로 자세한 설명은 각설한다. 

****
# Open Reivew 💗
NA

****
# Discussion 🍟
NA

****
# Major Takeaways 😃
NA

****
# Conclusion ✨
NA

****
# Reference
https://joungheekim.github.io/2020/10/14/paper-review/