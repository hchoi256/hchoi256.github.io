---
layout: single
title: "[ë…¼ë¬¸ ë¶„ì„] End-to-End Object Detection with Transformers (ECCV 2020)"
categories: AIPaperCV
tag: [Object Detection, Transformer]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/od.png
sidebar:
    nav: "docs"
---

[**ë…¼ë¬¸**](https://link.springer.com/content/pdf/10.1007/978-3-030-58452-8_13.pdf)

****
# ë°°ê²½ ğŸ™Œ
**Object detection**ì€ ë¶„ë¥˜ë¥¼ ìœ„í•œ cateogry boxë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì´ë‹¤.

í˜„ëŒ€ detectorsë“¤ì€ *ê°„ì ‘ì ì¸ ë°©ë²•*(hand-designed = ì‚¬ì „ì‘ì—…)ìœ¼ë¡œ ê°ì²´ íƒì§€ë¥¼ êµ¬í˜„í–ˆë‹¤: anchors, non-maximal suppression, window centers, ëŒ€ìš©ëŸ‰ proposals, etc.

> **Non-Maximum Suppression**
>> ![image](https://user-images.githubusercontent.com/39285147/197414699-970639a6-076d-4b2b-b1de-763931c9082e.png)
>> object detectorê°€ ì˜ˆì¸¡í•œ bounding box ì¤‘ì—ì„œ ì •í™•í•œ bounding boxë¥¼ ì„ íƒí•˜ë„ë¡ í•˜ëŠ” ê¸°ë²•

ì´ëŸ¬í•œ ê°„ì ‘ì ì¸ ë°©ë²•ë“¤ì€ *í›„ì²˜ë¦¬*(ì˜¤ì°¨ ì˜ˆì¸¡ ë° ì œê±°)ì— ë§‰ëŒ€í•˜ê²Œ ì˜í–¥ì„ ë°›ëŠ”ë‹¤.

> ì˜¤ì°¨: ì‹¤ì œê°’ - ì˜ˆì¸¡ê°’

ë•Œë¬¸ì— ê¸°ì¡´ ëª¨ë¸ë“¤ì€ ì—¬ëŸ¬ ê°€ì§€ ë³µì¡í•œ ì˜ˆì¸¡ ë¬¸ì œì— ëŒ€í•œ ê°ì²´ íƒì§€ ë¬¸ì œì—ì„œ í•œê³„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.

ì´ëŸ¬í•œ ê°„ì ‘ì ì¸ pipeline(ê³¼ì •)ì—ì„œì˜ surrogate tasksë¥¼ ê°„ì†Œí™”í•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ê²ƒì´ **direct set prediction ë°©ë²•**ì´ë‹¤.

> **Surrogate**: outputì´ ì •í™•íˆ ì¸¡ì •ë  ìˆ˜ ì—†ì„ ë•Œ, ëŒ€ì‹  output ê¸°ì¤€ì„ ì œê³µ

ì´ë²ˆ ë…¼ë¬¸ ì£¼ì œì¸ **DETR(DEtection TRansformer)**ì€ direct set prediction(bipartite matching loss) ë°©ë²•ê³¼ Transformer(non-autoregressive)ì„ ê²°í•©í•œ ë°©ë²•ì´ë‹¤.

ìƒê¸° ì–¸ê¸‰ëœ ìš©ì–´ë“¤ì— ëŒ€í•´ ì•Œì•„ë³´ì.

****
# INTRODUCTION ğŸ‘€
 ![image](https://user-images.githubusercontent.com/39285147/197411640-e6c3de0f-b4f3-4665-ae05-6a0b45c90bf3.png)

## ë°°ê²½ì§€ì‹
### Bipartite matching(ì´ë¶„ë§¤ì¹­)
[*Bipartite Graph*]

![image](https://user-images.githubusercontent.com/39285147/197421855-3281f5d4-8b83-4983-b407-6f84649dbccc.png)

ì´ë¶„ ê·¸ë˜í”„ì—ì„œ A ê·¸ë£¹ì˜ ì •ì ì—ì„œ B ê·¸ë£¹ì˜ ì •ì ìœ¼ë¡œ ê°„ì„ ì„ ì—°ê²° í•  ë•Œ, **A ê·¸ë˜í”„ í•˜ë‚˜ì˜ ì •ì ì´ B ê·¸ë˜í”„ í•˜ë‚˜ì˜ ì •ì ë§Œ** ê°€ì§€ë„ë¡ êµ¬ì„±ëœ ê²ƒì´ ì´ë¶„ ë§¤ì¹­

ìƒê¸° ì´ë¶„ ê·¸ë˜í”„ì—ì„œ, ì¢Œì¸¡ì€ ì´ë¶„ ê·¸ë˜í”„ì´ì§€ë§Œ ì´ë¶„ ë§¤ì¹­ì€ ì•„ë‹ˆê³  ìš°ì¸¡ì€ ë‘˜ë‹¤ ë§ë‹¤.

- ground truth boxesë¥¼ ì‚¬ìš©í•´ ë…ë¦½ì  ì˜ˆì¸¡ì„ í•œë‹¤.
    - no match: "no object"
- uniquely assigns a prediction to a ground truth object
    - ê°ì²´ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ìˆœì—´ ë¶ˆë³€(invariant) --> ê°ì²´ë³„ parallellism ë³´ì¥
        - ê°œë³„ì ìœ¼ë¡œ GT(ground truth) objectì™€ ì˜ˆì¸¡ objectì— ëŒ€í•œ lossë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ ì˜ˆì¸¡ëœ objectì˜ ìˆœì„œì— ìƒê´€ì´ ì—†ì–´ ë³‘ë ¬í™”ê°€ ê°€ëŠ¥
    - ë°˜ëŒ€ë¡œ ê¸°ì¡´ RNN ëª¨ë¸ = autoregressive decoding(object ìˆœì„œ O) --> ê°ì²´ë³„ parallellism ë³´ì¥ X
- set loss function(í•˜ê¸° ì°¸ì¡°)

> **Gound-truth**
>> ![image](https://user-images.githubusercontent.com/39285147/197421710-7405f615-8cfb-40b7-bd86-3ee8f7346a96.png)
>> ë°ì´í„°ì˜ ì›ë³¸ í˜¹ì€ ì‹¤ì œ ê°’ í‘œí˜„

### Set loss function
- performs bipartite matching between predicted and ground-truth objects.
    - ë‹¤ë¥´ê²Œ ë§í•˜ë©´, í•˜ë‚˜ì˜ objectì— ëŒ€í•˜ì—¬ ê°ê° ë…ë¦½ì ìœ¼ë¡œ GT ë° ì˜ˆì¸¡ê°’ ì´ë¶„ ë§¤ì¹­ ìˆ˜í–‰
- [Hungarian algorithm](https://gazelle-and-cs.tistory.com/29)

> **Hungarian algorithm**
>> ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” ì´ë¶„ ê·¸ë˜í”„(weighted bitarted graph)ì—ì„œ maximum weight matchingì„ ì°¾ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜

### COCO
- one of the most popular object detection datasets

### Transformer Decoder
**ê¸°ì¡´ Transformer** = autoregressive (output sequenceë¥¼ ***í•˜ë‚˜í•˜ë‚˜*** ë„£ì–´ì£¼ëŠ” ë°©ì‹) 
- pairwise interactions between elements in a sequence
- duplicate predictions ì œê±° ê°€ëŠ¥

****
# DETR Model âœ’
- bipartite matching loss + transformers with (non-autoregressive) parallel decoding
- **í•˜ë‚˜ì˜ CNNë¥¼ Transformer ì•„í‚¤í…ì³ì™€ ë³‘í•©** --> **ì§ì ‘ ì˜ˆì¸¡** ê°€ëŠ¥
- extra-long training schedule
- auxiliary decoding losses in the transformer

> **ìê¸°íšŒê·€(AR; Autoregressive)**
>> ê³¼ê±°ì˜ ì›€ì§ì„ì— ê¸°ë°˜ ë¯¸ë˜ ì˜ˆì¸¡

## Set Prediction
**Indirect Set Prediction**
- multilabel classification (postprocessing)
    - near-identical boxes í•´ê²° ì–´ë µ

**Direct Set Prediction**
- postprocessing-free
    - *global inference schemes* model interactions between all predicted elements to avoid redundancy.
- Auto-regressive sequence models (i.e., recurrent neural networks)
    - bipartite matching loss            
    - permutation-invariance

## Object Detection Set Prediction Loss
- bipartite matching loss + transformers (non-autoregressive) parallel decoding
- loss = ìµœì  bipartite matching(ì˜ˆì¸¡ê°’ ~ GT)
    - ìµœì  bipartite matching = ì˜ˆì¸¡ê°’ ~ ì‹¤ì œê°’ ë§¤ì¹­ ë°©ë²• ì¤‘ ìµœì € ë¹„ìš©ì„ ê°–ëŠ” ë§¤ì¹­
    - Hungarian algorithmì„ í†µí•´ íš¨ìœ¨ì ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ìˆë‹¤

> **Hungarian algorithm**
>> ![image](https://user-images.githubusercontent.com/39285147/197422840-8c8770b5-895b-4c82-b967-da083a62c4df.png)
>> ![image](https://user-images.githubusercontent.com/39285147/197422872-acf77efd-3103-4008-921c-f62aa22a13fc.png)

> **Bounding box loss**
>> ![image](https://user-images.githubusercontent.com/39285147/197422932-1866e001-8086-4f89-a231-4582d8e304d2.png)
>> ![image](https://user-images.githubusercontent.com/39285147/197422984-634e754a-c7db-47fd-9eaa-2523296a2057.png)

## DETR Architecture
![image](https://user-images.githubusercontent.com/39285147/197422990-0d50e9ab-0866-40d2-9940-ff3ffb91fdde.png)

## Backbone
- feature extraction

## Transformer Encoder
- feature maps ìƒì„± ê³¼ì •
- ê¸°ì¡´ transformer encoderì— **positional encoding** ì¶”ê°€
    - ë•ë¶„ì— autoregressiveì™€ ë‹¤ë¥´ê²Œ ì¸í’‹ ìˆœì„œ ìƒê´€ ì•ˆ ì¨ë„ë¨

## Transformer Decoder
- ***í•œë²ˆì—*** Nê°œì˜ obejctë¥¼ ë³‘ë ¬ ì˜ˆì¸¡
    - 1) Input embedding
        - *object query(positional encoding)* í†µí•´ í‘œí˜„
    - 2) Nê°œì˜ object queryëŠ” ë””ì½”ë”ì— ì˜í•´ output embeddingìœ¼ë¡œ ë³€í™˜
    - 3) Nê°œì˜ ë§ˆì§€ë§‰ ì˜ˆì¸¡ê°’ë“¤ ì‚°ì¶œ
    - 4) self/encoder-decoderê°„ ì–´í…ì…˜ì„ í†µí•´ ê° object ê°„ì˜ global ê´€ê³„ í•™ìŠµ

## Prediction FFN
- ìµœì¢… ë””í…ì…˜ ì˜ˆì¸¡
- 3ê°œì˜ perceptron, ReLU, linea projectionìœ¼ë¡œ êµ¬ì„±
- Procedure
    - 1) FFN --> ìƒëŒ€ì ì¸ ì¤‘ì•™ê°’ ì˜ˆì¸¡
    - 2) linear layer --> softmaxë¡œ class ì˜ˆì¸¡
        - ì‹¤ì œ object ì™¸ class = âˆ…

## Auxiliary decoding losses
- ì•Œë§ì€ ê°œìˆ˜ì˜ object ì˜ˆì¸¡ ê°€ëŠ¥
- ê° decoder layerì— ëŒ€í•´ prediction FFN & Hungarian loss ì¶”ê°€
    - ëª¨ë“  prediction FFNì€ ê°™ì€ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©
- ë‹¤ë¥¸ decoder layerì˜ input ì •ê·œí™”ë¥¼ ìœ„í•´ layer norm ì¶”ê°€

> **FFN**
>> simple feed forward network(FFN)

****
# Experiments âœ

## ì„±ëŠ¥ ë¹„êµ: Faster R-CNN and RetinaNet

## Ablations

## DETR for Panoptic Segmentation

****
# ê²°ê³¼ âœ”
## DETR ì¥ì 
- DETR ì •í™•ë„ SOTA R-CNN ëª¨ë¸ ëŠ¥ê°€
- ìœ ì—°í•œ Transformer ì•„í‚¤í…ì³ --> Panoptic segmentation ì„±ëŠ¥ â†‘
- êµ¬í˜„ì´ ì‰½ë‹¤
- í° object íƒì§€ ì„±ëŠ¥ â†‘
    - global information performed by the self-attention
    - enabled by the non-local computations of the transformer
- ì»¤ìŠ¤í…€ layers í•„ìš” ì—†ìŒ --> better reproduction
    - ë•Œë¬¸ì— DETRì€ ResNet, Transformer í”„ë ˆì„ ì›Œí¬ì—ì„œë„ ì¬ì‚¬ìš© ê°€ëŠ¥ 

## DETR í•œê³„
- Training ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼
- ìµœì í™” ë¬¸ì œ
- ì‘ì€ object íƒì§€ ì„±ëŠ¥ â†“

****
# Reference ğŸ‘“
[**GitHub Repository**](https://github.com/hchoi256/carla-research-project)

[*UW Madison CARLA Research Team*](https://cavh.cee.wisc.edu/carla-simulation-project/)

[*CARLA Simulator*](https://carla.readthedocs.io/en/latest/)

[End to End Object Detection with Transformers](https://velog.io/@long8v/End-to-End-Object-Detection-with-Transformers)

[*Hungarian Algorithm*](https://gazelle-and-cs.tistory.com/29)