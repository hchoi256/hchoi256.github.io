---
layout: single
title: "Meta, Transfer, Multi-task, Continual Learning ì°¨ì´"
categories: LightWeight
tag: [Meta Learning, Transfer Learning, Multi-task Learning, Continual Learning]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/ml-thumbnail.jpg
sidebar:
    nav: "docs"
---

****
# Introduction ğŸ™Œ
ëŒ€ë¶€ë¶„ì˜ ì•±ë“¤ì€ ë†’ì€ ì§ˆì˜ Data ìˆ˜ì§‘ ë° ì´ë¥¼ Trainingí•  Computational Powerê°€ ë¶€ì¡±í•˜ì—¬, ì£¼ì–´ì§„ í™˜ê²½ì— ë§ê²Œ Re-Trainí•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ë“¤ì´ ë¶€ê°ë˜ê³  ìˆë‹¤.

í•˜ì—¬ ë‹¤ë¥¸ Task ìˆ˜í–‰ì„ ìœ„í•œ AI ì‚¬ì „ í•™ìŠµ ëª¨ë¸ë¡œ ì ì€ Datasetì„ ê°€ì§€ëŠ” ë˜ ë‹¤ë¥¸ Taskë„ ì˜ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ë°©ì‹ì´ ëŒ€ë‘ë˜ê³  ìˆë‹¤.

í•´ë‹¹ ë°©ì‹ì€ Dataì˜ ì–‘ì´ ì ê³ , HW í•œê³„ë¥¼ íƒ€íŒŒí•˜ëŠ” ì¥ì ì„ ê°–ê³  ìˆë‹¤.

****
# Multi-task Learning âœ
- ê° task ë³„ ìµœì ì˜ í”¼ë¼ë¯¸í„°ë¥¼ ê³µìœ í•˜ëŠ” í•˜ë‚˜ì˜ ê±°ëŒ€ ëª¨ë¸
- ìƒˆë¡œìš´ datasetì´ ë“¤ì–´ì˜¤ë©´ ê°€ì¥ ì í•©í•œ task ì°¾ê¸° ìœ„í•œ í•™ìŠµ

****
# Meta Learning ğŸ˜œ
- Few-shot Learning
- *Learning-to-Learn*
- ê¸°í•™ìŠµ ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ì „ì´í•™ìŠµë³´ë‹¤ ë” ì ì€ datasetì—ì„œ ë¹ ë¥´ê²Œ ìµœì í™”í•˜ëŠ” generalization ë°©ì‹
    - `Model-based Approach`
    - `Metric-based model`: ì €ì°¨ì› ê³µê°„ì— ìƒˆë¡œìš´ ë°ì´í„° ë§µí•‘í•˜ì—¬ ê°€ì¥ ê°€ê¹Œìš´ classë¡œ ë¶„ë¥˜
    - `Optimization-based Approach`: ë‹¤ìˆ˜ taskì˜ generalized model í”¼ë¼ë¯¸í„°ë¥¼ ìƒˆë¡œìš´ task ëª¨ë¸ì˜ ì´ˆê¸° í”¼ë¼ë¯¸í„° ê°’ìœ¼ë¡œ ì´ìš© $$\rightarrow$$ ìµœì  í”¼ë¼ë¯¸í„° ë” ë¹ ë¥´ê²Œ ê²€ìƒ‰.
        - `Model-Agnostic Meta-Learning (MAML)`: ë¶„ë¥˜ ì´ì™¸ ê°•í™”í•™ìŠµ ë“± ë‹¤ì–‘í•œ ì•Œê³ ë¦¬ì¦˜ ì ìš© ê°€ëŠ¥

## Model-Agnostic Meta-Learning (MAML)
$$Model-Agnostic (ëª¨ë¸ê³¼\ ìƒê´€ì—†ì´)$$

![image](https://user-images.githubusercontent.com/39285147/218943327-ec845b73-171e-47b4-8853-797429e38793.png)

![image](https://user-images.githubusercontent.com/39285147/218943056-ebad0c8d-ed9f-4cc1-bdba-30b93f9440b6.png)

ìƒê¸° ê·¸ë¦¼ì—ì„œ $$\theta$$ê°€ ê°€ë¦¬í‚¤ëŠ” pointëŠ” Task 1, 2, 3ì— ëŒ€í•œ ìµœì ì€ ì•„ë‹ˆë‹¤.

í•˜ì§€ë§Œ, Task 1, 2, 3 ì–´ëŠ ê³³ìœ¼ë¡œë“  ë¹ ë¥´ê²Œ ì´ë™í•  ìˆ˜ ìˆëŠ” pointì´ê¸° ë•Œë¬¸ì— $$\theta$$ëŠ” ìµœìƒì˜ ì´ˆê¸° ì‹œì‘ì ì¼ ê²ƒì´ë‹¤.

ê·¸ ì‹œì‘ì ì€ ë‹¤ìˆ˜ taskë¡œë¶€í„° í‰ê· ì ìœ¼ë¡œ 2íšŒì˜ Gradient Descentë§Œ ë°œìƒí•˜ë©´ ë„ë‹¬í•  ìˆ˜ ìˆëŠ” ê±°ë¦¬ì— ìˆë„ë¡ ì„¤ì •í•œë‹¤.

ì´í›„, ìƒˆë¡œìš´ Taskì— ë§ëŠ” ìµœì ì˜ $$\theta^*$$ë¥¼ ì°¾ì•„ê°€ëŠ” ë°©ì‹ìœ¼ë¡œ Gradient Descentë¥¼ ì§„í–‰í•œë‹¤.

ë”°ë¼ì„œ, ìƒˆë¡œìš´ taskê°€ ì ì€ datasetì— ëŒ€í•˜ì—¬ ìˆ˜í–‰ë˜ì–´ë„ ìš°ë¦¬ëŠ” ìµœì ì˜ ì‹œì‘ì  $$\theta^*$$ì—ì„œë¶€í„° ì‹œì‘í•˜ê¸° ë•Œë¬¸ì•  few-shot learningì— ì„±ê³µí•œë‹¤.

****
# Transfer Learning ğŸ¥°
- Few-shot Learning
- ë‹¤ë¥¸ task ê¸°í•™ìŠµ ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ, ë‹¤ë¥¸ task ìˆ˜í–‰í•˜ëŠ” ì ì€ dataset ê¸°ë°˜ fine-tuning ì•Œê³ ë¦¬ì¦˜ ì ìš©

## Knowledge Distillation
- ê°™ì€ task ê¸°í•™ìŠµ ëª¨ë¸ì—ì„œ, ë” ì ì€ dataset ê³µìœ í•˜ëŠ” ì‘ì€ ëª¨ë¸ë¡œ ì§€ì‹(ê°€ì¤‘ì¹˜) ì „ë‹¬

****
# Continual Learning ğŸŒ·
- ì „ì´í•™ìŠµì˜ ê³ ì§ˆë³‘ **Catastrophic forgetting (Semantic Draft)** ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë‚˜ì˜¨ ì•Œê³ ë¦¬ì¦˜

****
# Conclusion âœ¨


****
# Reference ğŸ’•