---
layout: single
title: "ì´ˆê±°ëŒ€AI ë©€í‹°ëª¨ë¸(MultiModal)ì´ë€?"
categories: LargeAI
tag: [HyperscaleAI, MultiModal, Transformer]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/largeai.png
sidebar:
    nav: "docs"
---

****
# í•œì¤„ìš”ì•½ âœ”
**Multimodal Learning**. ë‹¨ì¼ ëª¨ë‹¬ ë°ì´í„°, ê°€ë ¹ ì´ë¯¸ì§€, ìŒì„±, í…ìŠ¤íŠ¸ ì¤‘ í•œ ê°€ì§€ í˜•íƒœë§Œì„ í•™ìŠµì— ì´ìš©í•˜ëŠ” í•œê³„ë¥¼ ê·¹ë³µí•˜ê³ ì ì—¬ëŸ¬ ëª¨ë‹¬ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ ì£¼ì–´ì§„ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëª¨ë¸ êµ¬ì¶• ë°©ë²•ë¡ ì´ë‹¤.

ì£¼ë¡œ ì¸ê°„ì˜ í–‰ë™ ì¸ì‹ì´ë‚˜ ê°ì • ì¸ì‹ ë“±ì˜ ë¬¸ì œì—ì„œ í™œë°œíˆ ì—°êµ¬ë˜ê³  ìˆëŠ” ë¶„ì•¼ì´ë©°, ëŒ€ì²´ë¡œ ë‹¨ì¼ ëª¨ë‹¬ë³´ë‹¤ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì…ì¦í•œë‹¤.

ë©€í‹°ëª¨ë‹¬ ë”¥ëŸ¬ë‹ì€ ê° ëª¨ë‹¬ì— ì í•©í•œ ë”¥ëŸ¬ë‹ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§•ë²¡í„°ë¥¼ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê° ëª¨ë‹¬ì„ í†µí•©í•œë‹¤.

ì¶”ì¶œëœ íŠ¹ì§•ë²¡í„°ë¥¼ ë¶„ì„ ëª©ì ì— ë”°ë¼ ì–´ë–»ê²Œ í†µí•©í• ì§€ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì—°êµ¬ë“¤ì´ ì¡´ì¬í•œë‹¤.

ê·¸ ì¤‘ì—ì„œë„, ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ë“œëŠ” labeling ê³¼ì •ì„ ìƒëµí•œ `self-supervised learning` ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ì—°êµ¬ê°€ ê°€ì¥ ê°ê´‘ë°›ê³  ìˆë‹¤.

Transformerê°€ ì¶”ì¶œí•œ ê° ëª¨ë‹¬ì˜ íŠ¹ì§•ë²¡í„°ë¥¼ `contrastive learning` ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ë©°, ê° ëª¨ë‹¬ì˜ íŠ¹ì§•ì— ë§ëŠ” ì†ì‹¤í•¨ìˆ˜(NCE loss / MIL-NCE loss)ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.

> ëª¨ë‹¬(Modal): í•œ ë°ì´í„°ì˜ í˜•íƒœ

****
# Introduction ğŸ™Œ
ìµœê·¼ ë”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì˜ ë°œì „ ë° computing ì„±ëŠ¥ í™•ë³´ì— ë”°ë¼, AI ì‹œìŠ¤í…œë“¤ì´ ì¸ê°„ ìˆ˜ì¤€ì„ ì›ƒëŒê³  ìˆë‹¤.

![image](https://user-images.githubusercontent.com/39285147/218303545-ef191a40-38c0-447f-9f5e-f846603f6ec4.png)

ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì¼ ëª¨ë‹¬ì˜ ê²½ìš°, ì¸ê°„ í–‰ë™/ê°ì • ì¸ì‹ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ ì‚¬ëŒ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ê°ì • ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” CNN ëª¨ë¸ì—ê²Œ ì§‘ì–´ë„£ëŠ”ë‹¤.

í•˜ì§€ë§Œ, ìƒê¸° taskë“¤ì˜ ê²½ìš° ë‹¨ìˆœíˆ ì´ë¯¸ì§€ë§Œ ê°€ì§€ê³  ì •í™•í•œ ê°ì • ë¶„ë¥˜ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤.

![image](https://user-images.githubusercontent.com/39285147/218303655-f627a451-a0ec-469c-a8c5-ef9e60d0c980.png)

ì–¼êµ´ í‘œì •ë¿ë§Œ ì•„ë‹ˆë¼ ìŒì„± ë°ì´í„° ë˜í•œ ê°ì • ë¶„ë¥˜ì— ì§€ëŒ€í•œ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.

![image](https://user-images.githubusercontent.com/39285147/218303731-1b7ec64b-db07-419e-8edb-bcfa3f6dc2d4.png)

í•˜ì—¬ ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë°ì´í„°ë¥¼ ê³ ë ¤í•˜ì—¬ í•™ìŠµí•˜ê³ ì í•œ ê°œë…ì´ ë°”ë¡œ **ë©€í‹°ëª¨ë‹¬**ì´ë‹¤.

****
# Multimodal Deep Learning ğŸ’£
![image](https://user-images.githubusercontent.com/39285147/218304174-ee7d956e-12bf-4425-aabb-82f64e391052.png)

- ê° ëª¨ë‹¬ì— ì í•©í•œ DL êµ¬ì¡° ê¸°ë°˜ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
- ë‘ ê°€ì§€ ëª¨ë‹¬ í†µí•© ë°©ì‹:
    - (1) [**Feature Concatenation**](#1-feature-vector-concatenation-âœ)        
        - ì´ë¯¸ì§€ ë°ì´í„°ëŠ” CNN, í…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” RNN ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œí•œë‹¤.

        ![image](https://user-images.githubusercontent.com/39285147/218304065-5d613180-0add-4cec-9cf0-97cc75e945f1.png)

    - (2) **Ensemble Classifier**
        - ê° ëª¨ë‹¬ ë°ì´í„° ë³„ classifierì˜ output labelsë¥¼ ê°€ì§€ê³  ensemble(voting, etc.) ì§„í–‰í•˜ì—¬ final output ì˜ˆì¸¡.

        ![image](https://user-images.githubusercontent.com/39285147/218303986-d8ae18c9-5cb6-4c9e-8844-b8d7a893a0d8.png)

Feature Concat ë°©ë²•ì´ ëŒ€ì¤‘ì ì´ë©°, ì´ ë°©ì‹ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ì—°êµ¬ê°€ í˜„ì¬ê¹Œì§€ ì–´ë–»ê²Œ ì§„í–‰ë˜ì–´ ì™”ëŠ”ì§€ ê·¸ ë…¼ë¬¸ë“¤ì˜ ì—­ì‚¬ë¥¼ í•µì‹¬ë§Œ ê°„ë‹¨íˆ ì‚´í´ë³´ì.

****
# Feature Vector Concatenation âœ
## Fusion Network
[ë…¼ë¬¸ë§í¬: Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional Neural Networks](https://arxiv.org/abs/1703.10893)

- í•´ë‹¹ ë…¼ë¬¸ì€ ì´ë¯¸ì§€+ìŒì„± í†µí•© ë°ì´í„°ë¥¼ í†µí•œ ìŒì„± í–¥ìƒìœ¼ë¡œ ìŒì„± ì‹ í˜¸ì˜ ë…¸ì´ì¦ˆ ìµœì†Œí™”í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤.
- ê° ëª¨ë‹¬ ë³„ íŠ¹ì§• ë²¡í„°ë¥¼ ì˜ ì¶”ì¶œí•œ í›„, FCì—ì„œ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ ê¸°ë³¸ìœ¼ë¡œ í•œë‹¤.

[*AVDCNN êµ¬ì¡°*]

![image](https://user-images.githubusercontent.com/39285147/218304420-a6361c55-6149-4479-81bf-4e70fb247164.png)

ì´ë¯¸ì§€, ìŒì„± ë°ì´í„°ì— ëŒ€í•œ ê° networkê°€ ì¶”ì¶œí•œ feature vectorë“¤ì„ concatí•˜ì—¬ ê·¸ë¦¼ì—ì„œ `Merged Layer`ì„ ë§Œë“ ë‹¤.

ì´í›„, FCLë¡œ ì´ì–´ì ¸ í•˜ê¸° ì†ì‹¤í•¨ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì´ í•™ìŠµí•˜ë©° ìµœì ì˜ parametersë¥¼ ì°¾ëŠ”ë‹¤.

![image](https://user-images.githubusercontent.com/39285147/218304522-b7227a5b-1f63-4269-9aab-37eeddb5325a.png)

> CNNì— ëŒ€í•œ ìì„¸í•œ ì´í•´ëŠ” [ì—¬ê¸°](https://github.com/hchoi256/ai-terms/blob/main/README.md)ë¥¼ ì°¸ì¡°í•˜ê¸¸ ë°”ë€ë‹¤.

[*AVDCNN ëª¨ë¸ í”¼ë¼ë¯¸í„° ê°œìˆ˜*]

![image](https://user-images.githubusercontent.com/39285147/218304649-4f2f286f-ac83-41e1-abec-2bdcc6038d03.png)

ìƒê¸° í‘œì—ì„œ `Merged Layer`ê°€ ê°–ê³ ìˆëŠ” ë‰´ëŸ°ì˜ ê°œìˆ˜ê°€ 2804ê°œì¸ ëª¨ìŠµì´ë‹¤.

ëŒ€ì²´ë¡œ FCLê°€ ì§„í–‰ë ìˆ˜ë¡ ë‰´ëŸ° ê°œìˆ˜ê°€ FC2ê¹Œì§€ ì¤„ì–´ë“¤ë©° í•™ìŠµì´ ì§„í–‰ëœë‹¤.

> Fully Connecter Layer
>
>> ![image](https://user-images.githubusercontent.com/39285147/218305000-55820718-4661-4c6a-bb84-b342ed3ef11f.png)
>>
>> CNN/Pooling ê²°ê³¼ë¥¼ ì¸í’‹ìœ¼ë¡œ ë°›ì•„ ê°€ì¤‘ì¹˜ ì ìš©ì„ í†µí•´ ì •ì˜ëœ ë¼ë²¨ë¡œ ë¶„ë¥˜í•˜ëŠ” êµ¬ê°„ì´ë‹¤.

ë˜ ë‹¤ë¥¸ feature vector concatenation ê¸°ë°˜ ì—°êµ¬ë“¤ë¡œëŠ” ì°¨ëŸ‰ ì‚¬ê³ ì— í° ì˜í–¥ì„ ì£¼ëŠ” ìš´ì „ìì˜ ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ì„ ë¶„ì„í•˜ëŠ” ë…¼ë¬¸ì´ ìˆë‹¤.


í•´ë‹¹ ë…¼ë¬¸ì€ ìš´ì „ìì˜ ìŠ¤íŠ¸ë ˆìŠ¤ì— ì˜í–¥ì„ ì£¼ëŠ” ECG ì‹ í˜¸, ì°¨ëŸ‰ ë°ì´í„°, ìƒí™© ë°ì´í„° ë“± ë‹¤ì–‘í•œ ëª¨ë‹¬ í˜•íƒœì˜ ë°ì´í„° ê¸°ë°˜ ë”¥ëŸ¬ë‹ í•™ìŠµì„ í†µí•´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ì´ëŒì–´ë‚¸ ë°” ìˆë‹¤.

![image](https://user-images.githubusercontent.com/39285147/218305213-e3a95783-18be-4ae6-a5b3-0ebc514ca21a.png)

í•´ë‹¹ taskëŠ” time seriesê°€ ì£¼ìš”í•œ ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ìˆê¸°ì—, networkì— **LSTM**ì„ FC ì§ì „ ì¶”ê°€í•˜ì—¬ ì‹œê°„ ì—°ì†ì„± íŠ¹ì„±ì„ ì–»ëŠ” ëª¨ìŠµì´ë‹¤.

> LSTMì— ëŒ€í•œ ìì„¸í•œ ì´í•´ëŠ” [ì—¬ê¸°](https://github.com/hchoi256/ai-terms/blob/main/README.md)ë¥¼ ì°¸ì¡°í•˜ê¸¸ ë°”ë€ë‹¤.

## Transformer
[ë…¼ë¬¸ë§í¬: Vatt: Transformers for Multimodal Self-supervised Learning](https://arxiv.org/abs/2104.11178)
- í•´ë‹¹ ë…¼ë¬¸ì€ ì£¼ì–´ì§„ Labelì— ì—†ëŠ”(unlabeled dataset) ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì— ëŒ€í•œ ìµœì ì˜ multimodal feature ì¶”ì¶œì„ ëª©í‘œë¡œ í•œë‹¤.

> Self-supervised Learningì— ëŒ€í•œ ìì„¸í•œ ì´í•´ëŠ” [ì—¬ê¸°](https://github.com/hchoi256/ai-terms/blob/main/README.md)ë¥¼ ì°¸ì¡°í•˜ê¸¸ ë°”ë€ë‹¤.

[*VATT Transformer êµ¬ì¡°*]

![image](https://user-images.githubusercontent.com/39285147/218306210-15c95a76-a03e-4f3a-8930-6e5e71024c56.png)

ê° ëª¨ë‹¬ ë°ì´í„° í† í°í™” ì´í›„, Linear Projectionì„ í†µí•´ ë‚˜ì˜¨ ê°’ì„ Encoder ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ëª¨ìŠµì´ë‹¤.

![image](https://user-images.githubusercontent.com/39285147/218306284-6ce92b69-54bb-4b76-80b7-42a4afdb7676.png)

- Transformerì—ì„œ ì¶”ì¶œëœ ì—¬ëŸ¬ ëª¨ë‹¬ì˜ íŠ¹ì§• ë²¡í„°ë¥¼ `contrastive learning` ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•œë‹¤.
    - Video-audio pair: NCE-loss
    - video-text pair: MIL-NCE

ê°€ë ¹, ë°”ëŒ ì˜ìƒì€ ë°”ëŒ ì†Œë¦¬ì™€ì˜ ìœ ì‚¬ë„ê°€ ë†’ì„ ê²ƒì´ê³ , ì´ ê²½ìš° NCE-lossê°€ ë‚®ê²Œ ë‚˜íƒ€ë‚  ê²ƒì´ë‹¤.
- NCE-lossëŠ” ì†ì‹¤í•¨ìˆ˜ë¡œì¨, ê·¸ ê°’ì´ í¬ë‹¤ëŠ” ê²ƒì€ ëª¨ë¸ì˜ ë¶„ë¥˜ ê²°ê³¼ê°€ ì •í™•í•˜ì§€ ì•Šë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.

> `Contrastive Learning`
>
>> ë¹„ìŠ·í•œ ê²ƒë“¤ë¼ë¦¬ëŠ” ìœ ì‚¬ë„ê°€ ë†’ê³ , ë‹¤ë¥¸ ê²ƒë“¤ì€ ìœ ì‚¬ë„ê°€ ë‚®ê²Œë” ì „ê°œí•˜ëŠ” ë°©ì‹ì´ë‹¤.

****
# Reference
[1] Hou, J. C., Wang, S. S., Lai, Y. H., Tsao, Y., Chang, H. W., & Wang, H. M. (2018). Audio-visual speech enhancement using multimodal deep convolutional neural networks. IEEE Transactions on Emerging Topics in Computational Intelligence, 2(2), 117-128.

[2] Rastgoo, M. N., Nakisa, B., Maire, F., Rakotonirainy, A., & Chandran, V. (2019). Automatic driver stress level classification using multimodal deep learning. Expert Systems with Applications, 138, 112793.

[3] Akbari, H., Yuan, L., Qian, R., Chuang, W. H., Chang, S. F., Cui, Y., & Gong, B. (2021). Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text. arXiv preprint arXiv:2104.11178.