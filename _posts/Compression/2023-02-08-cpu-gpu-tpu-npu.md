---
layout: single
title: "CPU, GPU(CUDA), FPGA, NPU, TPU ì´í•´"
categories: Study
tag: [CPU, GPU, NPU, TPU, FPGA, CUDA]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
header:
    teaser: /assets/images/posts/gpu.jfif
sidebar:
    nav: "docs"
---

****
# í•œì¤„ìš”ì•½ âœ”
- ì²˜ë¦¬ë°©ì‹
    - ì§ë ¬: CPU
    - ë³‘ë ¬: ë‚˜ë¨¸ì§€ GPU, TPU, NPU

****
# Introduction ğŸ™Œ
í˜„ëŒ€ì— ì´ë¥´ëŸ¬ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆê°€ ê¸‰ì¦í•˜ë©´ì„œ, AI ëª¨ë¸ í•™ìŠµì´ í•„ìˆ˜ì ì¸ ë” ë‚˜ì€ í•˜ë“œì›¨ì–´ ì¹©ì— ëŒ€í•œ ìˆ˜ìš” ë˜í•œ ì¦ê°€í•˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤.

ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ í•˜ë“œì›¨ì–´ ì¹©ì´ í˜„ì¬ ì‹œì¥ì—ì„œ í™œìš©ë˜ê³  ìˆìœ¼ë‚˜, ë”¥ëŸ¬ë‹ í•™ìŠµê³¼ ê´€ë ¨í•˜ì—¬ ëŒ€í‘œì ìœ¼ë¡œ ì‚¬ìš©ë˜ì™”ë˜, ê·¸ë¦¬ê³  ìƒˆë¡œìš´ ì°¨ì„¸ëŒ€ ê°•ìë¡œ ê°ê´‘ë°›ëŠ” ì¹©ë“¤ì— ëŒ€í•´ ì•Œì•„ë´…ì‹œë‹¤.

****
# CPU(Centralized Processing Unit) ğŸ’£
$$CPU\ ë²”ìš©\ ê³„ì‚°ê¸°$$

## CPU íŠ¹ì§•
[*í° ë…¸ì´ë§Œ ì•„í‚¤í…ì³*]

![image](https://user-images.githubusercontent.com/39285147/217796521-ee649b42-a210-4fdb-ada2-4981ca9ed28a.png)

- í˜„ì¬ CPUëŠ” í°ë…¸ì´ë§Œ êµ¬ì¡°ì— ê¸°ë°˜
- ìœ ì—°í•œ **ì§ë ¬ê³„ì‚° ëŠ¥ë ¥** (ì´ì „-ë‹¤ìŒ ê³„ì‚° ê²°ê³¼ì˜ ì—°ê³„)
    - ALU ì—°ì‚° ì´í›„ Memory ì €ì¥ í•„ìˆ˜
    - í•œ ë²ˆì— í•˜ë‚˜ì˜ transaction ìˆœì°¨ì  ì²˜ë¦¬
- í‰ê·  ì´ìƒì˜ íš¨ìœ¨ $$\rightarrow$$ ì»´í“¨í„°, mobile devices, ì„ë² ë””ë“œ ì¥ë¹„ë“¤ì˜ main processor ì—­í• 
    - ë³µì¡í•œ ëª…ë ¹ì–´ì„¸íŠ¸ë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì •êµí•œ ì•„í‚¤í…ì³
        - ë³µì¡í•œ ëª…ë ¹ì–´ ì„¸íŠ¸ë‚˜ ë§ì€ ìˆ˜ì˜ ë ˆì§€ìŠ¤í„° ë° ë³µì¡í•œ ìºì‹œ êµ¬ì¡°ë¥¼ ê°€ì§„ë‹¤
    - ë˜‘ë˜‘í•œ ë§Œí¼ ê°œë³„ ê³„ì‚°ë‹¹ ë¹„ìš©ì´ í¬ë‹¤

## CPU ì—°ì‚°
### Instruction Set Architecture(ISA)
ê°ê¸° ë‹¤ë¥¸ ì¢…ë¥˜ì˜ CPUëŠ” ì‹¤í–‰ ê°€ëŠ¥í•œ ê¸°ê³„ì–´ ëª¨ìŒ(Instruction Set Architecture, ISA)ì„ ê°–ìŠµë‹ˆë‹¤.

ê°€ë ¹, í•˜ê¸° ì˜¤ì§ 3ê°œì˜ registerë¥¼ ê°–ëŠ” ê°„ë‹¨í•œ ISAê°€ ìˆë‹¤ê³  ê°€ì •í•´ë´…ì‹œë‹¤.

                ëª…ë ¹ì–´      ì„¤ëª…
                LDR	        ë°ì´í„° ë¡œë“œ (--> CPU)
                STR	        ë°ì´í„° ì´ë™ (CPU --> Memory) 
                ADD	        Addition

                LDR reg1, #1;
                LDR reg2, #2;
                ADD reg1, reg2, reg3;
                STR reg3, [0x00040222h];

1. `1 CLOCK`: $$1 \rightarrow\ R1$$.
2. `2 CLOCK`: $$2 \rightarrow\ R2$$.
3. `3 CLOCK`: $$R1+R2\ \rightarrow\ R3$$ (ALU).
4. `4 CLOCK`: $$R3\ \rightarrow\ 0x00040222h$$.

> `Register`: CPU ë‚´ë¶€ ì €ì¥ì†Œ
>
> `Memory`: CPU ë°”ê¹¥ ì €ì¥ì†Œ

`4 CLOCK`ì´ ìˆœì°¨ì ìœ¼ë¡œ ì§€ë‚œ í›„, ìµœì¢… additionì˜ ê²°ê³¼ê°€ CPU ì™¸ë¶€ Memoryì˜ 0x00040222h ì£¼ì†Œê°’ ìœ„ì¹˜ì— ì €ì¥ë  ê²ƒì…ë‹ˆë‹¤.

****
# Graphic Processing Unit(GPU) âœ
$$ëŒ€ê·œëª¨\ ë³‘ë ¬\ ê³±ì…ˆ\ ê³„ì‚°ê¸°$$

![image](https://user-images.githubusercontent.com/39285147/217838136-115071f3-7445-4c14-93f5-3bdd6aa85c7d.png)

CPU ì²˜ë¦¬ ê¸°ë°˜ì—ì„œëŠ” ê³ ì‚¬ì–‘ ê²Œì„ì„ ëª¨ë‹ˆí„° í™”ë©´ì— í‘œí˜„í•˜ëŠ” ë™ì•ˆ í‚¤ë³´ë“œ ì…ë ¥ì´ ì•ˆë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ëŠ” CPUê°€ ì§ë ¬ì²˜ë¦¬ ë°©ì‹ì— ê¸°ë°˜í•˜ê³  ìˆì–´ì„œ, ëª¨ë‹ˆí„° í™”ë©´ì´ ë‹¤ í‘œí˜„ë  ë•Œê¹Œì§€ í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬ê°€ awaiting ë˜ê¸° ë•Œë¬¸ì¸ë°ìš”.

ì´ëŸ¬í•œ í•œê³„ì ì„ íƒ€íŒŒí•˜ê³ ì ë“±ì¥í•œ ê²ƒì´ ë°”ë¡œ ë³‘ë ¬ì²˜ë¦¬ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ëŠ” GPUì…ë‹ˆë‹¤.

## GPU íŠ¹ì§•
- CPU ì½”ì–´ì˜ ë³µì¡í•œ êµ¬ì¡°ë¥¼ ë‹¨ìˆœí™” $$\rightarrow$$ ê°œë³„ ê³„ì‚° ë¹„ìš© ìµœì†Œí™”
- ë‹¨ìˆœí•œ í˜•íƒœì˜ ì½”ì–´ ëŒ€ëŸ‰ ì§‘ì  $$\rightarrow$$ ë‹¨ìˆœ ì—°ì‚° ë³‘ë ¬ ìˆ˜í–‰
- ì „ë ¥ì†Œëª¨, ë‚´êµ¬ì„±, ê¸°ëŒ€ìˆ˜ëª… â†“ $$\rightarrow$$ ë§ë‹¨ ì¥ì¹˜ì—ì„œ ìƒìš©í™” í•œê³„ì 
- ê³ ë¹„ìš©

## GPU ì“°ì„
### ê·¸ë˜í”½ ì²˜ë¦¬
GPUëŠ” ë‹¨ìˆœí•œ ëŒ€ëŸ‰ ê³„ì‚°ì„ ë³µì¡í•œ ê³„ì‚°ì— ìœ ë¦¬í•œ CPUë¡œë¶€í„° ë…ë¦½ì‹œí‚¤ê¸° ìœ„í•´ ê³ ì•ˆëœ Co-processorì…ë‹ˆë‹¤.

í•˜ì—¬ GPUëŠ” ì£¼ë¡œ ê·¸ë˜í”½ ì²˜ë¦¬ì— ë§ì´ í™œìš©ë˜ì–´ NVIDIA ê°™ì€ ì—…ì²´ê°€ ê·¸ ëŒ€í‘œì ì¸ ì˜ˆì‹œì…ë‹ˆë‹¤.

ê·¸ë˜í”½ ì²˜ë¦¬ì— í•„ìš”í•œ ê³„ì‚°ì—ëŠ” ë™ì¼í•œ í˜•íƒœì˜ ë¶€ë™ ì†Œìˆ˜ì  ê³±ì…ˆ ëŒ€ëŸ‰ ìˆ˜í–‰ì´ ì „ë¶€ì…ë‹ˆë‹¤.

### AI ë”¥ëŸ¬ë‹ í•™ìŠµ
AI ì¶”ë¡ ì´ë‚˜ í•™ìŠµì„ í•  ë•Œ í•µì‹¬ì ìœ¼ë¡œ í•„ìš”í•œ ì—°ì‚°ì´ ë°”ë¡œ í–‰ë ¬ í•©ì„±ê³±(convolution) ì—°ì‚°ì…ë‹ˆë‹¤.

í•©ì„±ê³± ì—°ì‚° ë¹„ì¤‘ì— ë”°ë¼, ëª¨ë¸ì˜ training/inference ì„±ëŠ¥ì´ ê²°ì •ë©ë‹ˆë‹¤.

#### í•©ì„±ê³± ì—°ì‚°
![image](https://user-images.githubusercontent.com/39285147/217868536-382aa0d1-61f4-4657-9ba6-fa54d734c9b1.png)

**Feature Extraction**ì´ë€ ì´ë¯¸ì§€ì—ì„œ í•„í„°ê°€ ì§€ì •í•œ ë°©í–¥ì— ë”°ë¥¸ ê²½ê³„ì„  ëª¨ì–‘ì„ ëŒ€ëµì ìœ¼ë¡œ ì•Œì•„ë‚´ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

ì´ ë•Œ ì‚¬ìš©ë˜ëŠ” ì—°ì‚° ê¸°ë²•ì´ ë°”ë¡œ í•©ì„±ê³± ì—°ì‚°ì…ë‹ˆë‹¤.

ì¶”ì¶œëœ ê²½ê³„ì„  ëª¨ì–‘ Feature Mapì„ ì ì ˆí•˜ê²Œ ë³€í˜•í•˜ì—¬ ì•Œê³  ìˆëŠ” ì •ë‹µì— ê·¼ì ‘í•˜ë„ë¡ ê° í•„í„°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ìˆ˜ì •í•´ ë‚˜ê°€ëŠ” ê²ƒì´ ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì…ë‹ˆë‹¤.

Filter(ì»¤ë„)ì€ ì´ë¯¸ì§€ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ë³€ìˆ˜ì…ë‹ˆë‹¤.

ë”¥ëŸ¬ë‹ í•™ìŠµì„ í•œë‹¤ëŠ” ê²ƒì€ ë§ì€ í•„í„°ì˜ ê³„ìˆ˜ë¥¼ ë³€ê²½í•˜ì—¬ ì •ë‹µì— ê°€ê¹ê²Œ ë§Œë“œëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

> ì´ ê¸€ì˜ ì·¨ì§€ì— ì–´ê¸‹ë‚˜ëŠ” í•©ì„±ê³±ì— ëŒ€í•œ ë” ìì„¸í•œ ì„¤ëª…ì€ ìƒëµí•œë‹¤.

## CUDA
- GPUì—ê²Œ ê³±ì…ˆì„ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ì •ë¦¬í•  ê²ƒì¸ì§€ ì§€ì‹œ
    - ë³‘ë ¬ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ê°€ëŠ¥
- Cê¸°ë°˜ GPU ê³„ì‚° ìŠ¤ì¼€ì¤„ë§ SDK

## cuDNN
- ê¸°ë³¸ì ì¸ ë”¥ëŸ¬ë‹ primitive í¸ë¦¬í•˜ê²Œ êµ¬í˜„

****
# Field Programmable Gate Array(FPGA) ğŸ‘€
![image](https://user-images.githubusercontent.com/39285147/218299733-f29d110a-e6ca-4d90-8991-10607d81399f.png)

- í”„ë¡œê·¸ë˜ë° ê°€ëŠ¥í•œ ë…¼ë¦¬ì†Œì ë°°ì—´ì˜ ì¼ì¢…
- ì›í•˜ëŠ” ì˜ë„ì•  ë§ê²Œ ë…¼ë¦¬íšŒë¡œ ë™ì‘ ê°€ëŠ¥
    - Logic ì„¤ê³„ê°€ ì´ë£¨ì–´ì§€ì§€ ì•Šì€ í˜•íƒœë¡œ ë‚©í’ˆ í›„ ê°œë°œìê°€ ì§ì ‘ ì„¤ê³„

## FPGA ì¥ì 
- ì „ë ¥ ì†Œëª¨ëŸ‰ â†“, Latency â†“, throughput â†‘
    - ì²˜ìŒë¶€í„° Neural Network ëª¨ë¸ í•™ìŠµì— ì í•©í•˜ë„ë¡ FPGA êµ¬ì„± ê°€ëŠ¥

## FPGA ë‹¨ì 
- ë†’ì€ ê°€ê²©, ì‚¬ì¹˜ìŠ¤ëŸ¬ìš´ ë¹„íš¨ìœ¨ì ì´ê²Œ ë›°ì–´ë‚œ ì„±ëŠ¥

****
# Neural Processing Unit(NPU) ğŸ§¿
## NPU íŠ¹ì§•
- GPUì—ì„œ í™•ì¥ëœ **ì‹ ê²½ë§ í•™ìŠµ íŠ¹í™”** AI ì—°ì‚° ë³‘ë ¬ì²˜ë¦¬
- ë”¥ëŸ¬ë‹ ë„¤íŠ¸ì›Œí¬ì˜ ê° layerë¥¼ ì‹¤ë¦¬ì½˜ìœ¼ë¡œ êµ¬í˜„í•œ ì¹©ì…‹
    - ANNì˜ ë‰´ëŸ°ë“¤(Convolution, FCL, etc.) í•˜ë“œì›¨ì–´ì ìœ¼ë¡œ êµ¬í˜„
    - í•˜ì—¬ SW ìœ ì—°í•¨ì— ìˆì–´ì„œ í•œê³„ë¥¼ ê°€ì§
- GPU, cuDNN ì‚¬ìš©í•  ë•Œì™€ ê°™ì€ performance ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„± ë¶ˆê°€ëŠ¥
    - NPUì—ì„œ êµ¬í˜„í•˜ì§€ ì•Šì€ DNN ë‰´ëŸ°ì€ í•˜ë“œì›¨ì–´ ê°€ì† ë¶ˆê°€ $$\rightarrow$$ CPU ì§ë ¬ì—°ì‚° ìˆ˜í–‰ $$\rightarrow$$ CPU ì‚¬ìš©ì— ë”°ë¥¸ ì„±ëŠ¥ ì €í•˜
- ìŠ¤ë§ˆíŠ¸í°ì— ëŒ€ë¶€ë¶„ ì‚¬ìš© (ì˜ìƒ, ì´ë¯¸ì§€, ìŒì„±ì¸ì‹ AI ìŠ¤ë§ˆíŠ¸í° ê¸°ìˆ )

> ë§Œì•½ CPUê°€ FC ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, í•´ë‹¹ ë„¤íŠ¸ì›Œí¬ íš¨ìœ¨ ì €í•˜
>
>> ![image](https://user-images.githubusercontent.com/39285147/218299038-d097d82c-e84c-4313-96c6-3dc657b7f11c.png)

## NPU ì¥ì 
- ì‹ ê²½ë§ AI ì—°ì‚° ì²˜ë¦¬ì— ìš©ì´
- ì €ë¹„ìš©

## NPU ë‹¨ì 
- GPUë³´ë‹¤ ë²”ìš©ì„± â†“
- ì‹ ê²½ë§ ë…¸ë“œë¥¼ í•˜ë“œì›¨ì–´ì ìœ¼ë¡œ êµ¬í˜„í–ˆê¸°ì—, HW êµ¬ì¡°ìƒ ë‹¤ë¥¸ AI ì•Œê³ ë¦¬ì¦˜ ìŠµë“ í•œê³„
    - HW êµ¬ì¡° ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ì‹œ, ì˜¤íˆë ¤ ë” í° ì‹œê°„ ë° ë¹„ìš© ì†Œëª¨

## NPU ëª©ì 
- ê¸°ì¡´ ë”¥ëŸ¬ë‹ ë¹„ìš© ìµœì†Œí™”
    - ê¸°ì¡´ GPU ì‹œìŠ¤í…œ = ë¹„ìŒˆ, íœ´ëŒ€ ë¶ˆê°€ëŠ¥, ì „ë ¥ ì†Œëª¨ ìƒë‹¹
    - ë§ë‹¨ device, ê°€ë ¹ íœ´ëŒ€í°ì— GPU ë„£ê¸° ë¶ˆê°€ëŠ¥

> Smart Phoneì—ëŠ” **AP(Application Processor)ì¹©**ì´ë¼ëŠ” GPU + CPU í†µí•© on-deviceê°€ ìˆë‹¤.

> **Edge computing/inference**: ë§ë‹¨ devicesì—ì„œ ì¶”ë¡  ë° í•™ìŠµ ìˆ˜í–‰í•˜ëŠ” ê²ƒ

## GPU + NPU êµ¬ì¡°
- GPU: ëª¨ë¸ í•™ìŠµ ê°€ì†
- NPU: ë§ë‹¨ ì¥ë¹„ì—ì„œ ì €ì „ë ¥ ì¶”ë¡ 

> ì ì°¨ ëª¨ë¸ í•™ìŠµ ê°€ì†ë„ NPU ë³‘ë ¬ì²˜ë¦¬ë¡œ ë°”ë€ŒëŠ” ì¶”ì„¸

****
# TensorFlow Processing Unit(TPU) ğŸ‘€
- A type of NPU by Google
- ê¸°ì¡´ NPUì™€ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šìœ¼ë‚˜, `Tensorflow lite` í˜¸í™˜ì„± â†‘
- Bfloat16 ê¸°ë°˜
- Systolic matrix multiplication
- Very high throughput

****
# Conclusion âœ¨
![image](https://user-images.githubusercontent.com/39285147/218299539-ee113c3f-8c58-4c22-8e3e-d721e0800199.png)

****
# Reference