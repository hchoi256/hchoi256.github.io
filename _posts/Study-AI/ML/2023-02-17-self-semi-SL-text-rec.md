---
layout: single
title: "Self/Semi-supervised Learning for Scene Text Recognition"
categories: Others
tag: [Self/Semi Supervised Learning, Scene Text Recognition]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
# header:
#     teaser: /assets/images/posts/qntzn.png
sidebar:
    nav: "docs"
---

****
# Preliminaries âœ”
# Scene Text Spotting 
![image](https://user-images.githubusercontent.com/39285147/219853577-8745d4bb-7183-49df-b325-b2622e2a9ceb.png)

- ì¼ìƒ ì´ë¯¸ì§€ ì•ˆì˜ ê¸€ì ê²€ì¶œ ë° ì¸ì‹
    - (1) **Scene Text Detection**: ì´ë¯¸ì§€ ê¸€ì ì¸ì‹
    - (2) **Scene Text Recognition**: ì´ë¯¸ì§€ ê¸€ì ì¶œë ¥

> **Optical Character Recognition (OCR)**
>
>> ê·œê²©í™”ëœ ì¸ì‡„ì²´ ë¬¸ì ì¸ì‹
>>
>> ![image](https://user-images.githubusercontent.com/39285147/219853660-3ff10cc9-83be-4b26-a1db-f8561831a324.png)

****
# Scene Text Recognition (STR) ğŸ‘Œ
## Sequence Prediction Task
![image](https://user-images.githubusercontent.com/39285147/219853744-8a79b08b-144f-41bc-9052-eaeb5413bd8b.png)

- í•˜ë‚˜ì˜ ì…ë ¥ê°’ì— ëŒ€í•´ ì—¬ëŸ¬ ê°œì˜ ìˆœì°¨ì  ì¶œë ¥ê°’
    - ì „ì²´ ë¬¸ìì—´ ë‹¨ìœ„ê°€ ì•„ë‹Œ, ê° ê¸€ì ë‹¨ìœ„ í•™ìŠµ
- Input: ì´ë¯¸ì§€ / Output: ê¸€ì(label)

## STR êµ¬ì„±
![image](https://user-images.githubusercontent.com/39285147/219854050-61aa9f58-dcf2-43d8-95d2-2ed37210c4a9.png)

Encoder
- 1) **Transformation**: ì¸í’‹ ì´ë¯¸ì§€ ì •ë ¬ (Affine)
- 2) **Feature Extraction**: ì •ë ¬ëœ ì´ë¯¸ì§€ to Visual Feature ì¶”ì¶œ (ResNet)
- 3) **Sequence Modeling**: Visual Feature to Context Feature ë³€í™˜ (LSTM)

Decoder
- 4) **Prediction**: Context Feature ê¸°ë°˜ ì´ë¯¸ì§€ ê¸€ì ì˜ˆì¸¡ (Attention)

## STR í•œê³„
- Labeling ë¹„ìš© â†‘
    - 2ë‹¨ê³„ ì ˆì°¨: Detection + Labeling(í‘œê¸°)
- ê° ë‚˜ë¼ ì–¸ì–´ë§ˆë‹¤ input ë°ì´í„° ìˆ˜ì§‘ í•„ìš” 

### STR í•´ê²° (1): Synthesized Data
![image](https://user-images.githubusercontent.com/39285147/219854165-58ef7a12-7f8c-4e28-8f7d-0420d73acc4e.png)

ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ëª¨ë¸ í•™ìŠµì— synthesized data í™œìš©í•˜ì§€ë§Œ, í•˜ê¸° ë¬¸ì œì ë“¤ì´ ì—¬ì „íˆ ì¡´ì¬í•œë‹¤.

- `Synthesized data`: ì¸ê°„ì´ ë§Œë“¤ì–´ë‚¸ ì¸ìœ„ì ì¸ ë°ì´í„° (ë¶€ìì—°ìŠ¤ëŸ¬ì›€)
- Test set ì¼ë°˜í™” ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„± â†‘

### STR í•´ê²° (2): Unlabeled Data
![image](https://user-images.githubusercontent.com/39285147/219854262-a1e02a84-986f-46c9-8354-17aa47c9f121.png)

- ì†Œìˆ˜ Labeled ë°ì´í„° ì¡´ì¬í•  ë•Œ, Unlabeled ë°ì´í„° í•¨ê»˜ í™œìš©.
    - Self-supervised Learning
    - Semi-supervised Learning
- Unlabeled data $$\rightarrow$$ ë°ì´í„° ìˆ˜ì§‘ ë¹„ìš© â†“.
- ì‹¤ì œ ì´ë¯¸ì§€ ê¸°ë°˜ $$\rightarrow$$ ì¼ë°˜í™” ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„± â†“. 

> Unsupervised Learning: supervisionì´ ì•„ì— ì—†ëŠ” í•™ìŠµ.

****
# Self-supervised Learning ğŸ™Œ
- `Pretext Task`: ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ë¥¸ downstream taskì— ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì–´ë–¤ ì‹œê°ì  íŠ¹ì§•ì„ ë°°ìš°ëŠ” ë‹¨ê³„ (Supervision)
- `Contrastive Learning`: ì£¼ì–´ì§„ input ë°ì´í„°ì— Pos/Neg Pair ì •ì˜ í›„, ë°ì´í„° ê´€ê³„(ë¹„ìŠ·í•œ ë°ì´í„°ëŠ” ìœ ì‚¬ë„ ë†’ìŒ) í†µí•´ íŠ¹ì§• í•™ìŠµ
- `Non Contrastive Learning`: Neg Sample ì •ì˜ X, Pos Pairë¡œë§Œ í•™ìŠµ 

> Pretext Task ì˜ˆì‹œ: *Context Prediction*
>
>> ![image](https://user-images.githubusercontent.com/39285147/219855901-51013415-18d8-4b03-a718-876cc7ea7327.png)

> ìƒê¸° ìš©ì–´ë“¤ì— ëŒ€í•œ ë³´ë‹¤ ìì„¸í•œ ì„¤ëª…ì€ í•˜ê¸° [References](#reference)ì—ì„œ ê´€ë ¨ concept ì°¸ì¡° ìš”ë¨•

![image](https://user-images.githubusercontent.com/39285147/219854407-4547feee-6097-4c62-87cd-e30b1767d5d2.png)

ëŒ€ë¶€ë¶„ ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ ì£¼ì–´ì§„ ì˜ìƒìœ¼ë¡œë¶€í„° ì„ì˜ì˜ íŒ¨ì¹˜ì— ëŒ€í•œ ê³µê°„ì  íŠ¹ì„±ì„ ì •í™•í•˜ê²Œ í•™ìŠµí•œ ë’¤, feature extraction layersë¥¼ downstream taskë¥¼ ìœ„í•œ ëª¨ë¸ë¡œ weightsëŠ” freezeì‹œí‚¨ ì±„ transfer learningí•˜ì—¬ ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ í•™ìŠµ ê³¼ì •ì„ ê±°ì¹˜ëŠ” ì „ëµì´ë‹¤.

ì…ë ¥ ë°ì´í„° ë³€í˜• $$\rightarrow$$ ê¸°ì¡´ input ë°ì´í„°ì— ì§€ë„ ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ë°ì´í„° íŠ¹ì§•ì„ í•™ìŠµí•œë‹¤.
- **Stage 1**: Unlabeled ë°ì´í„°ë¡œ Pretraining
- **Stage 2**: Labeled ë°ì´í„°ë¡œ Fine-tuning

## Self-supervised Learning-based Scene Text Recognition
[[ë…¼ë¬¸] Sequence-to-Sequence Contrastove Learning for Text Recognition](https://arxiv.org/abs/2012.10873)

![image](https://user-images.githubusercontent.com/39285147/219864470-36f5ad65-bc86-4cb1-8b20-018576cb9865.png)
- Text Recognitionì— Self-supervised Learningì˜ Constrastive Learning ì ìš©
- ë¬¸ìì¸ì‹ì— Unlabeled ë°ì´í„°ë¥¼ í•¨ê»˜ í™œìš© ê°€ëŠ¥í•œ ìê¸°ì§€ë„í•™ìŠµ Framework ì œì•ˆ
    - Contrastive Learning í™œìš©

ì¼ë°˜ì ì¸ ìê¸°ì§€ë„í•™ìŠµ STR ì ìš©ì‹œ í•˜ê¸° í•œê³„ ì¡´ì¬í•œë‹¤:
- ê¸°ì¡´ Data Augmentation (RandAugment) Sequence í•´ì¹¨
- STR ëª¨ë¸ì˜ Sequential íŠ¹ì§•(ì¶œë ¥ê°’ì— sequence ì¡´ì¬) ë°˜ì˜ ì–´ë ¤ì›€

í•˜ì—¬ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì™€ ë‹¤ë¥´ê²Œ ì—¬ëŸ¬ ê°œì˜ Sequentialí•œ ì¶œë ¥ê°’ ë°˜ì˜ì´ í•„ìš”í•˜ë‹¤.

![image](https://user-images.githubusercontent.com/39285147/219908547-cdb74ac3-77a5-4377-a135-e881d4c56d93.png)

**Stage 1 (Pretraining Phase)**:
- `Data Augmentation`: ì´ë¯¸ì§€ sequence í•´ì¹˜ì§€ ì•Šë„ë¡ aug ìˆ˜í–‰
- `Base Encoder`: Context feature ì¶”ì¶œ
- `Projection Head`: ì´ë¯¸ì§€ representation í€„ë¦¬í‹° í–¥ìƒ 
- `Instance Mapping Function`: ì´ë¯¸ì§€ sequencesë¥¼ sub-wordsë¡œ ë³€í™˜í•˜ê³ , ê° contrastive loss ì‚°ì¶œ
- `Contrastive Loss`

> ![image](https://user-images.githubusercontent.com/39285147/219908598-20d1c262-0bbc-43c1-8442-586c1a75bb6d.png)

**Stage 2 (Fine-tuning Phase)**:
- ì¼ë°˜ì ì¸ ìê¸°ì§€ë„í•™ìŠµì²˜ëŸ¼ feature extractorë¥¼ freeze í›„, decoderë§Œ í•™ìŠµ
    - Stage 1ì—ì„œ ì–»ì€ Base Encoder ì •ë³´ í™œìš©í•˜ì—¬ decoder í•™ìŠµ

### Experiment
![image](https://user-images.githubusercontent.com/39285147/219908695-11b2adce-6f05-4de2-b042-2d8ab3dee058.png)

- *Window-to-instance* ë°©ì‹ì´ ëŒ€ì²´ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ ë³´ì„
- Seq ê³ ë ¤í•œ Contrastive Learningì´ ë¬¸ì ì¸ì‹ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ ë³´ì„
- instance ê°œìˆ˜:
    - ë„ˆë¬´ ë§ì€ instance mapping ìˆ˜í–‰ $$\rightarrow$$ misalignment pair ë¬¸ì œ ë°œìƒ.
    - ë„ˆë¬´ ì ì€ instance mapping ìˆ˜í–‰ $$\rightarrow$$ negative pair ê°œìˆ˜ ê°ì†Œ.

****
# Semi-supervised Learning ğŸ†
- `Pseudo-Labeling Method`: Unlabeled ë°ì´í„° ì˜ˆì¸¡ê²°ê³¼ í™œìš©í•˜ì—¬ ê°€ì§œë¡œ ë ˆì´ë¸”ë§ í›„ labeled ë°ì´í„°ì²˜ëŸ¼ í™œìš©
- `Consistency Regularization Method`: ë°ì´í„° ë° ëª¨ë¸ì— ë³€í˜• í›„ì—ë„ ì˜ˆì¸¡ ì¼ê´€ì„± ê°–ë„ë¡ í•™ìŠµ
- `Hybrid Method`: ì—¬ëŸ¬ ì¤€ì§€ë„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì•„ì´ë””ëŸ¬ í˜¼í•© í™œìš© í•™ìŠµ.

![image](https://user-images.githubusercontent.com/39285147/219855596-24bea078-25c1-4e7d-9c01-647e468773fb.png)

- Unlabeled ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ ì˜ˆì¸¡ê²°ê³¼ë¡œ Labelì„ ì„ì˜ë¡œ ë§Œë“¤ì–´ì£¼ì–´ í•™ìŠµ
- Labeled/Unlabeled ë°ì´í„° í•¨ê»˜ í™œìš© í•™ìŠµ

## Semi-supervised Learning-based Scene Text Recognition
[[ë…¼ë¬¸ë¶„ì„] Pushing the Performance Limit of Scene Text Recognizer without Human Annotation](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Pushing_the_Performance_Limit_of_Scene_Text_Recognizer_Without_Human_CVPR_2022_paper.pdf)

![image](https://user-images.githubusercontent.com/39285147/219908893-a3c14cb7-6481-4f9a-bff9-bae0d26daed4.png)

- STRì— `Consistency Regularization` ì ìš©
    - `Consistency Regularization`: ë™ì¼í•œ ì´ë¯¸ì§€ì—ì„œ ë‹¤ë¥´ê²Œ ë³€í˜•ëœ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ë”ë¼ë„, ë™ì¼í•œ ê²°ê³¼ ê°–ë„ë¡ í•™ìŠµ
- STRì— í•©ì„± ë°ì´í„°+ì‹¤ì œ Unlabeled ë°ì´í„° í•¨ê»˜ í™œìš©í•˜ëŠ” ì¤€ì§€ë„í•™ìŠµ

ì¼ë°˜ì ì¸ ì¤€ì§€ë„í•™ìŠµì„ STR ì ìš© ì‹œ, í•˜ê¸° í•œê³„ì  ì¡´ì¬:
- í•©ì„±ì´ë¯¸ì§€ ~ ì‹¤ì œì´ë¯¸ì§€ ë°ì´í„° ë¶„í¬ ì°¨ì´ë¡œ í•™ìŠµë¥  ì €í•˜
- ê¸€ì ê°„ Misalignment ë¬¸ì œ ë°œìƒí•˜ì—¬ ë™ì¼í•˜ì§€ ì•Šì€ ê¸€ìë¼ë¦¬ consistency regularization ìˆ˜í–‰ë˜ì–´ í•™ìŠµ ë°©í•´

### Model Architecture
![image](https://user-images.githubusercontent.com/39285147/219908957-e62a71ef-47c9-409d-9d41-93ebffd927ce.png)

- `Encoder`: ì…ë ¥ ì´ë¯¸ì§€ feature ì¶”ì¶œ
- `Decoder`: ì´ë¯¸ì§€ ë‹¨ìœ„ featureì—ì„œ ê¸€ì ë‹¨ìœ„ feature ìƒì„±
- `Classifier`: ê¸€ì ë‹¨ìœ„ featureì—ì„œ ê° ê¸€ìë“¤ì„ ì˜ˆì¸¡

![image](https://user-images.githubusercontent.com/39285147/219909589-d202fd8c-a6eb-4264-bbda-a78e63400a43.png)

#### Supervised Branch
![image](https://user-images.githubusercontent.com/39285147/219908976-2a765cad-44dd-4313-b43a-aa3105fde208.png)

- Labeled ë°ì´í„°(í•©ì„±ë°ì´í„°) í™œìš© í•™ìŠµ
    - cross entropy ì‚¬ìš©
- Labeled ê¸€ìë“¤ decoderì˜ ì…ë ¥ ê¸€ìë¡œ í™œìš©
- í•™ìŠµëœ weightsë“¤ unsupervised branchì˜ online modelì— ê³µìœ 

#### Unsupervised Branch
![image](https://user-images.githubusercontent.com/39285147/219909227-dfc89594-9cef-489b-b2b4-9e63fd42786b.png)
![image](https://user-images.githubusercontent.com/39285147/219909455-aec2b168-68d1-44fe-b300-91fa7a065803.png)

- Unlabeled ë°ì´í„° í™œìš© í•™ìŠµ
- Online ëª¨ë¸, Target Model ëª¨ë‘ Asymmetric    
    - Target Modelì˜ ê¸€ì ë³„ ì˜ˆì¸¡ í™•ë¥  í™œìš© Noisy ë°ì´í„° í•„í„°ë§
        - Thresholdë³´ë‹¤ ê¸€ìë³„ ì˜ˆì¸¡ í™•ë¥ ì˜ ê°€ì¤‘í•©ì´ ì‘ìœ¼ë©´ í•™ìŠµì—ì„œ í™œìš©í•˜ì§€ ì•ŠìŒ (ìƒê¸° ì´ë¯¸ì§€ Score: 0.5814)
- **Character-level Consistency Regularization**: í•˜ë‚˜ì˜ ì´ë¯¸ì§€ ë‘ ë²ˆ ì¦ê°• í›„ ë‘ ì˜ˆì¸¡ ê°’ì´ ê¸€ì ë‹¨ìœ„ë¡œ ìœ ì‚¬í•´ì§€ë„ë¡ í•™ìŠµ (KL Divergence)
    - *Online Model*: Strong augmentation ì´ë¯¸ì§€ ì…ë ¥ / Encoder + Decoder + Projection + Classifier / Weight Decay
    - *Target Model*: Weak Augmentation ì´ë¯¸ì§€ ì…ë ¥ / Encoder + Decoder + Classifier / Stop Gradient (EMA í™œìš©) 
- Autoregressive decoder: ì´ì „ ì¶œë ¥ê°’ í™œìš©
    - *Target Model*: Autoregressiveí•˜ê²Œ ì´ì „ ì‹œì ê°’ í™œìš©
    - *Online Model*: Target Modelì˜ ì´ì „ ì‹œì  ê°’ í™œìš©

> **EMA**: $$\theta_t=\alpha \theta_t + (1-\alpha)\theta_{\alpha}$$.

![image](https://user-images.githubusercontent.com/39285147/219909528-5251a630-4d79-43ea-ada6-f714568993bc.png)

#### Domain Adaptation
![image](https://user-images.githubusercontent.com/39285147/219909579-7ada65c8-b0cb-40a6-8bc3-dbbfda8ffcf9.png)
![image](https://user-images.githubusercontent.com/39285147/219909575-d9104325-aed7-42f3-a2d0-091fd09d9e9e.png)

í•©ì„± ë°ì´í„° ~ ì‹¤ì œ ë°ì´í„° ë„ë©”ì¸ ì°¨ì´ ìµœì†Œí™”
- Supervised ~ Unsupervised Branchì˜ Target Modelì˜ Vision featureì—ì„œ ê°ê° ê³µë¶„ì‚° í–‰ë ¬ì„ êµ¬í•œ í›„, ì´ë“¤ì˜ ì°¨ì´ë¥¼ í†µí•´ Domain Shift ìµœì†Œí™”

### Summary
- **1) Supervised Branch Loss ì‚°ì¶œ**
    - ì˜ˆì¸¡ê°’ ~ ë ˆì´ë¸” í™œìš© êµì°¨ ì—”íŠ¸ë¡œí”¼
- **2) Unsupervised Branch Loss ì‚°ì¶œ**
    - ë°ì´í„° ì¦ê°• 2íšŒ í›„ Online/Target Model ì…ë ¥
    - Encoder ~ Classifier í†µê³¼ í›„ ê° Model ì˜ˆì¸¡ ìˆ˜í–‰
    - Target Model ì˜ˆì¸¡ í™•ë¥ ê°’ í†µí•´ Score ì ìˆ˜ ì‚°ì • í›„ Threshold ë¹„êµí•˜ì—¬ Noisy ë°ì´í„° í•™ìŠµ ë¯¸ë°˜ì˜
    - Noisy ì•„ë‹ˆë¼ë©´, ê¸€ì ë‹¨ìœ„ Consistency Loss ì‚°ì¶œ (Context Information ê³µìœ )
- **3) Domain Adaptation Loss ì‚°ì¶œ**
    - Supervised Branchì™€ Unsupervised Branchì˜ Target Model í™œìš© Loss ì‚°ì¶œ
- **4) Overall Loss ì‚°ì¶œ**
- **5) Weight Update**

### Experiment
![image](https://user-images.githubusercontent.com/39285147/219909733-4f28dcda-f9f8-4590-97f1-696da6319885.png)

- í•´ë‹¹ ì—°êµ¬ ì¤€ì§€ë„í•™ìŠµ >> ê¸°ì¡´ ì§€ë„í•™ìŠµ
- í•´ë‹¹ ì—°êµ¬ ì¤€ì§€ë„í•™ìŠµ vs. íƒ€ ì¤€ì§€ë„í•™ìŠµ
    - depends!

****
# Self&Semi-supervised Learning ğŸ
[[ë…¼ë¬¸ë¶„ì„] Multimodal Semi-Supervsied Learning for Text Recognition]

> ìµœê·¼ ì—°êµ¬ íë¦„: STRì— Unlabeled ë°ì´í„° í™œìš© ì—°êµ¬ëŠ” Vision Featureë§Œ ê³ ë ¤ë¨ / STRì€ í•™ìŠµ ìœ„í•œ Labeled ë°ì´í„° ë§¤ìš° ë¶€ì¡±

![image](https://user-images.githubusercontent.com/39285147/219916155-6734372f-dc70-4534-9254-6628e4c91db3.png)

- **STRì— Semi, Self ëª¨ë‘ ì ìš©**
    - Self: Contrastive Learning
    - Semi: Consistency Regularization
- **Vision/Language ëª¨ë‘ ê³ ë ¤í•œ Multimodal ëª¨ë¸**
    - Vision Model Pretraining: Constrastive Learning + Supervised Loss
    - Language Model Pretraining: Masked Language Model (MLM)ìœ¼ë¡œ ì‚¬ì „í•™ìŠµ

> **MLM**: íŠ¹ì • Text tokenì„ ê°€ë¦¬ê³  ê°€ë ¤ì§„ ë¶€ë¶„ì˜ text token ë§ì¶”ëŠ” ë°©ì‹ / unlabeled data í™œìš© large text corpus ì‚¬ì „í•™ìŠµ

- **Fine-tuning & Fusion Model Training**
    - ê° Modalityë³„ Prediction
    - ê° Modalityë³„ Consistency Regularization

ìƒê¸° ìš©ì–´ë“¤ ëª¨ë‘ ì‚¬ì „ì— ë‹¤ë£¨ì—ˆë˜ ë‚´ìš©ì´ë¯€ë¡œ, ì˜ ì½ì–´ë³´ë©´ ì´í•´ë  ê²ƒì´ë‹¤.

****
# Reference
[Self-supervised Learning](https://greeksharifa.github.io/self-supervised%20learning/2020/11/01/Self-Supervised-Learning/)

[Self/Semi-supervised Learning for Scene Text Recognition](http://dmqm.korea.ac.kr/activity/seminar/388)