---
layout: single
title: "Self/Semi-supervised Learning for Scene Text Recognition"
categories: Others
tag: [Self/Semi Supervised Learning, Scene Text Recognition]
toc: true
toc_sticky: true
toc_label: "ì­ŒìŠ¤log"
#author_profile: false
# header:
#     teaser: /assets/images/posts/qntzn.png
sidebar:
    nav: "docs"
---

****
# Preliminaries âœ”
# Scene Text Spotting 
![image](https://user-images.githubusercontent.com/39285147/219853577-8745d4bb-7183-49df-b325-b2622e2a9ceb.png)

- ì¼ìƒ ì´ë¯¸ì§€ ì•ˆì˜ ê¸€ì ê²€ì¶œ ë° ì¸ì‹
    - (1) **Scene Text Detection**: ì´ë¯¸ì§€ ê¸€ì ì¸ì‹
    - (2) **Scene Text Recognition**: ì´ë¯¸ì§€ ê¸€ì ì¶œë ¥

> **Optical Character Recognition (OCR)**
>
>> ê·œê²©í™”ëœ ì¸ì‡„ì²´ ë¬¸ì ì¸ì‹
>>
>> ![image](https://user-images.githubusercontent.com/39285147/219853660-3ff10cc9-83be-4b26-a1db-f8561831a324.png)

****
# Scene Text Recognition (STR) ğŸ‘Œ
## Sequence Prediction Task
![image](https://user-images.githubusercontent.com/39285147/219853744-8a79b08b-144f-41bc-9052-eaeb5413bd8b.png)

- í•˜ë‚˜ì˜ ì…ë ¥ê°’ì— ëŒ€í•´ ì—¬ëŸ¬ ê°œì˜ ìˆœì°¨ì  ì¶œë ¥ê°’
    - ì „ì²´ ë¬¸ìì—´ ë‹¨ìœ„ê°€ ì•„ë‹Œ, ê° ê¸€ì ë‹¨ìœ„ í•™ìŠµ
- Input: ì´ë¯¸ì§€ / Output: ê¸€ì(label)

## STR êµ¬ì„±
![image](https://user-images.githubusercontent.com/39285147/219854050-61aa9f58-dcf2-43d8-95d2-2ed37210c4a9.png)

Encoder
- 1) **Transformation**: ì¸í’‹ ì´ë¯¸ì§€ ì •ë ¬ (Affine)
- 2) **Feature Extraction**: ì •ë ¬ëœ ì´ë¯¸ì§€ to Visual Feature ì¶”ì¶œ (ResNet)
- 3) **Sequence Modeling**: Visual Feature to Context Feature ë³€í™˜ (LSTM)

Decoder
- 4) **Prediction**: Context Feature ê¸°ë°˜ ì´ë¯¸ì§€ ê¸€ì ì˜ˆì¸¡ (Attention)

## STR í•œê³„
- Labeling ë¹„ìš© â†‘
    - 2ë‹¨ê³„ ì ˆì°¨: Detection + Labeling(í‘œê¸°)
- ê° ë‚˜ë¼ ì–¸ì–´ë§ˆë‹¤ input ë°ì´í„° ìˆ˜ì§‘ í•„ìš” 

### STR í•´ê²° (1): Synthesized Data
![image](https://user-images.githubusercontent.com/39285147/219854165-58ef7a12-7f8c-4e28-8f7d-0420d73acc4e.png)

ìµœê·¼ ì—°êµ¬ì—ì„œëŠ” ëª¨ë¸ í•™ìŠµì— synthesized data í™œìš©í•˜ì§€ë§Œ, í•˜ê¸° ë¬¸ì œì ë“¤ì´ ì—¬ì „íˆ ì¡´ì¬í•œë‹¤.

- `Synthesized data`: ì¸ê°„ì´ ë§Œë“¤ì–´ë‚¸ ì¸ìœ„ì ì¸ ë°ì´í„° (ë¶€ìì—°ìŠ¤ëŸ¬ì›€)
- Test set ì¼ë°˜í™” ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„± â†‘

### STR í•´ê²° (2): Unlabeled Data
![image](https://user-images.githubusercontent.com/39285147/219854262-a1e02a84-986f-46c9-8354-17aa47c9f121.png)

- ì†Œìˆ˜ Labeled ë°ì´í„° ì¡´ì¬í•  ë•Œ, Unlabeled ë°ì´í„° í•¨ê»˜ í™œìš©.
    - Self-supervised Learning
    - Semi-supervised Learning
- Unlabeled data $$\rightarrow$$ ë°ì´í„° ìˆ˜ì§‘ ë¹„ìš© â†“.
- ì‹¤ì œ ì´ë¯¸ì§€ ê¸°ë°˜ $$\rightarrow$$ ì¼ë°˜í™” ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥ì„± â†“. 

> Unsupervised Learning: supervisionì´ ì•„ì— ì—†ëŠ” í•™ìŠµ.

****
# Self-supervised Learning ğŸ™Œ
- `Pretext Task`: ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ í›ˆë ¨ëœ ë„¤íŠ¸ì›Œí¬ê°€ ë‹¤ë¥¸ downstream taskì— ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì–´ë–¤ ì‹œê°ì  íŠ¹ì§•ì„ ë°°ìš°ëŠ” ë‹¨ê³„ (Supervision)
- `Contrastive Learning`: ì£¼ì–´ì§„ input ë°ì´í„°ì— Pos/Neg Pair ì •ì˜ í›„, ë°ì´í„° ê´€ê³„(ë¹„ìŠ·í•œ ë°ì´í„°ëŠ” ìœ ì‚¬ë„ ë†’ìŒ) í†µí•´ íŠ¹ì§• í•™ìŠµ
- `Non Contrastive Learning`: Neg Sample ì •ì˜ X, Pos Pairë¡œë§Œ í•™ìŠµ 

> Pretext Task ì˜ˆì‹œ: *Context Prediction*
>
>> ![image](https://user-images.githubusercontent.com/39285147/219855901-51013415-18d8-4b03-a718-876cc7ea7327.png)

> ìƒê¸° ìš©ì–´ë“¤ì— ëŒ€í•œ ë³´ë‹¤ ìì„¸í•œ ì„¤ëª…ì€ í•˜ê¸° [References](#reference)ì—ì„œ ê´€ë ¨ concept ì°¸ì¡° ìš”ë¨•

![image](https://user-images.githubusercontent.com/39285147/219854407-4547feee-6097-4c62-87cd-e30b1767d5d2.png)

ëŒ€ë¶€ë¶„ ë ˆì´ë¸”ì´ ì—†ëŠ” ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ ì£¼ì–´ì§„ ì˜ìƒìœ¼ë¡œë¶€í„° ì„ì˜ì˜ íŒ¨ì¹˜ì— ëŒ€í•œ ê³µê°„ì  íŠ¹ì„±ì„ ì •í™•í•˜ê²Œ í•™ìŠµí•œ ë’¤, feature extraction layersë¥¼ downstream taskë¥¼ ìœ„í•œ ëª¨ë¸ë¡œ weightsëŠ” freezeì‹œí‚¨ ì±„ transfer learningí•˜ì—¬ ì†ŒëŸ‰ì˜ labeled ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ í•™ìŠµ ê³¼ì •ì„ ê±°ì¹˜ëŠ” ì „ëµì´ë‹¤.

ì…ë ¥ ë°ì´í„° ë³€í˜• $$\rightarrow$$ ê¸°ì¡´ input ë°ì´í„°ì— ì§€ë„ ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ë°ì´í„° íŠ¹ì§•ì„ í•™ìŠµí•œë‹¤.
- **Stage 1**: Unlabeled ë°ì´í„°ë¡œ Pretraining
- **Stage 2**: Labeled ë°ì´í„°ë¡œ Fine-tuning

## Self-supervised Learning-based Scene Text Recognition
[[ë…¼ë¬¸] Sequence-to-Sequence Contrastove Learning for Text Recognition](https://arxiv.org/abs/2012.10873)

![image](https://user-images.githubusercontent.com/39285147/219864470-36f5ad65-bc86-4cb1-8b20-018576cb9865.png)
- Text Recognitionì— Self-supervised Learningì˜ Constrastive Learning ì ìš©
- ë¬¸ìì¸ì‹ì— Unlabeled ë°ì´í„°ë¥¼ í•¨ê»˜ í™œìš© ê°€ëŠ¥í•œ ìê¸°ì§€ë„í•™ìŠµ Framework ì œì•ˆ
    - Contrastive Learning í™œìš©

ì¼ë°˜ì ì¸ ìê¸°ì§€ë„í•™ìŠµ STR ì ìš©ì‹œ í•˜ê¸° í•œê³„ ì¡´ì¬í•œë‹¤:
- ê¸°ì¡´ Data Augmentation (RandAugment) Sequence í•´ì¹¨
- STR ëª¨ë¸ì˜ Sequential íŠ¹ì§•(ì¶œë ¥ê°’ì— sequence ì¡´ì¬) ë°˜ì˜ ì–´ë ¤ì›€

í•˜ì—¬ ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ë¬¸ì œì™€ ë‹¤ë¥´ê²Œ ì—¬ëŸ¬ ê°œì˜ Sequentialí•œ ì¶œë ¥ê°’ ë°˜ì˜ì´ í•„ìš”í•˜ë‹¤.

****
# Semi-supervised Learning ğŸ™Œ
- `Pseudo-Labeling Method`: Unlabeled ë°ì´í„° ì˜ˆì¸¡ê²°ê³¼ í™œìš©í•˜ì—¬ ê°€ì§œë¡œ ë ˆì´ë¸”ë§ í›„ labeled ë°ì´í„°ì²˜ëŸ¼ í™œìš©
- `Consistency Regularization Method`: ë°ì´í„° ë° ëª¨ë¸ì— ë³€í˜• í›„ì—ë„ ì˜ˆì¸¡ ì¼ê´€ì„± ê°–ë„ë¡ í•™ìŠµ
- `Hybrid Method`: ì—¬ëŸ¬ ì¤€ì§€ë„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì•„ì´ë””ëŸ¬ í˜¼í•© í™œìš© í•™ìŠµ.

![image](https://user-images.githubusercontent.com/39285147/219855596-24bea078-25c1-4e7d-9c01-647e468773fb.png)

- Unlabel ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ ì˜ˆì¸¡ê²°ê³¼ë¡œ Labelì„ ì„ì˜ë¡œ ë§Œë“¤ì–´ì£¼ì–´ í•™ìŠµ
- Labeled/Unlabeled ë°ì´í„° í•¨ê»˜ í™œìš© í•™ìŠµ

****
# Conclusion âœ¨


****
# Reference
[Self-supervised Learning](https://greeksharifa.github.io/self-supervised%20learning/2020/11/01/Self-Supervised-Learning/)