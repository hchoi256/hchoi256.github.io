<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>ML Project 5: Natural Language Processing | 정리하여 내 것으로, AI</title>
<meta name="description" content="Code [Notice] download here">


  <meta name="author" content="Hojun Eric Choi">
  
  <meta property="article:author" content="Hojun Eric Choi">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="정리하여 내 것으로, AI">
<meta property="og:title" content="ML Project 5: Natural Language Processing">
<meta property="og:url" content="http://localhost:4000/ml/ml-projects-5/">


  <meta property="og:description" content="Code [Notice] download here">



  <meta property="og:image" content="http://localhost:4000/assets/images/posts/ml-thumbnail.jpg">





  <meta property="article:published_time" content="2022-07-24T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/ml/ml-projects-5/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Hojun Eric Choi",
      "url": "http://localhost:4000/"
    
  }
</script>






  <meta name="naver-site-verification" content="57d020c8f9b26bf56ed7846608b8d873481e9b84">


<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="정리하여 내 것으로, AI Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/logo.ico/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/logo.ico/favicon-16x16.png">
<link rel="mask-icon" href="/assets/logo.ico/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          정리하여 내 것으로, AI
          <span class="site-subtitle">with jjuns</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tag</a>
            </li><li class="masthead__menu-item">
              <a href="/search/">Search</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">토글 메뉴</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      




  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/" itemprop="item"><span itemprop="name">Home</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#ml" itemprop="item"><span itemprop="name">Ml</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">ML Project 5: Natural Language Processing</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/echoi.jpg" alt="Hojun Eric Choi" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Hojun Eric Choi</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>I am a senior-year B.S. student in Computer Science and Data Science at the University of Wisconsin, Madison.</p>

<p>My research interests are <strong>ML</strong>, <strong>deep NLP</strong>, and <strong>computer vision</strong> for emerging application domains.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">팔로우</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Madison</span>
        </li>
      

      
        
          
            <li><a href="https://www.linkedin.com/in/hojun-choi-2b10b11a0/" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://github.com/hchoi256" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="/assets/CV.pdf" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">CV</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:hchoi256@wisc.edu" rel="me" class="u-email">
            <meta itemprop="email" content="hchoi256@wisc.edu" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">이메일</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">토글 메뉴</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Table of Contents</span>
        

        
        <ul>
          
            <li><a href="/categories/">Category</a></li>
          
            <li><a href="/tags/">Tag</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="ML Project 5: Natural Language Processing">
    <meta itemprop="description" content="Code[Notice] download here">
    <meta itemprop="datePublished" content="2022-07-24T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/ml/ml-projects-5/" class="u-url" itemprop="url">ML Project 5: Natural Language Processing
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-07-24T00:00:00+09:00">2022-07-24</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 분 소요
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> GITHUB BLOG JJUNS</h4></header>
              <ul class="toc__menu"><li><a href="#code">Code</a></li><li><a href="#learning-goals">Learning Goals</a></li><li><a href="#part-1-email-spam-filtering">PART 1: Email Spam Filtering</a><ul><li><a href="#loading-the-dataset">Loading the dataset</a></li><li><a href="#data-visualization">Data visualization</a></li><li><a href="#nlp">NLP</a><ul><li><a href="#data-preprocessing">Data Preprocessing</a><ul><li><a href="#불용어-제거--소문자-통일하기-stopwords-and-lowercase">불용어 제거 &amp; 소문자 통일하기 (Stopwords and lowercase)</a></li><li><a href="#removing-punctuation">Removing punctuation</a></li></ul></li><li><a href="#count-vectorizer">Count Vectorizer</a></li></ul></li><li><a href="#creating-the-trainingtest-dataset">Creating the Training/Test dataset</a></li><li><a href="#evaluating-the-model-confusion-matrixclassification-report">Evaluating the model: Confusion Matrix/Classification Report</a><ul><li><a href="#혼동-행렬-confusion-matrix">혼동 행렬 (Confusion Matrix)</a></li><li><a href="#성능-지표-classification-report">성능 지표 (Classification Report)</a></li></ul></li></ul></li><li><a href="#part-2-yelp-reviews">PART 2: YELP Reviews</a><ul><li><a href="#loading-the-dataset-1">Loading the dataset</a></li><li><a href="#data-visualization-1">Data Visualization</a></li><li><a href="#nlp-1">NLP</a><ul><li><a href="#불용어구두점-제거-stopwordspunctuation">불용어/구두점 제거 (Stopwords/Punctuation)</a></li><li><a href="#count-vectorizer-1">Count Vectorizer</a></li></ul></li><li><a href="#creating-the-trainingtest-dataset-1">Creating the Training/Test dataset</a></li><li><a href="#training-the-model-naive-beyas">Training the model (Naive Beyas)</a></li><li><a href="#evaluating-the-model">Evaluating the model</a><ul><li><a href="#confusion-matrix">Confusion Matrix</a></li><li><a href="#성능-지표-classification-report-1">성능 지표 (Classification Report)</a></li></ul></li><li><a href="#tf-idf-term-frequency-inverse-document-frequency">TF-IDF (term frequency-inverse document frequency)</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <h1 id="code">Code</h1>
<p class="notice--danger"><strong>[Notice]</strong> <a href="https://github.com/hchoi256/machine-learning-development">download here</a></p>

<h1 id="learning-goals">Learning Goals</h1>
<ol>
  <li><strong>Naive Beyas Theorem</strong>
    <ul>
      <li><em>베이즈 정리</em>에 기반한 분류 기술 <span style="color: blue">Classification techniques with beyas theorem</span></li>
    </ul>
  </li>
  <li>자연어 처리의 기초 <span style="color: blue">Understanding NLP</span>
    <ul>
      <li>tokenization with <em>NLTK</em></li>
      <li>Extracting features with <em>Count Vectorizer</em></li>
    </ul>
  </li>
  <li>
    <p>우도, 사전 확률, 주변 우도의 차이점 <span style="color: blue">Likelihood, prior, marginal likelihood</span></p>
  </li>
  <li>불균형 데이터 처리 방법 <span style="color: blue">How to handle unbalanced data</span></li>
</ol>

<h1 id="part-1-email-spam-filtering">PART 1: Email Spam Filtering</h1>
<p>이 프로젝트는 <a href="https://github.com/hchoi256/ai-terms/blob/main/README.md">Naive Beyas Classifier</a>를 활용하여 SMS 스팸 분류 방법을 제시한다. <span style="color: blue">Presenting the method of SMS Spam Classification using Naive Beyas Classifier</span></p>

<h2 id="loading-the-dataset">Loading the dataset</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spam_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"emails.csv"</span><span class="p">)</span>
<span class="n">spam_df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180648071-f7e5cc4d-ef12-457b-8777-bc7419665b16.png" alt="image" /></p>

<h2 id="data-visualization">Data visualization</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># spam 0 or 1
</span><span class="n">ham</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">[</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
<span class="n">spam</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">[</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Visualizing the distribution 
</span><span class="n">spam</span><span class="p">[</span><span class="s">'length'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span> <span class="s">'Spam percentage ='</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">spam</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">spam_df</span><span class="p">)</span> <span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">"%"</span><span class="p">)</span>

<span class="n">ham</span><span class="p">[</span><span class="s">'length'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span> <span class="s">'Ham percentage ='</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ham</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">spam_df</span><span class="p">)</span> <span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">"%"</span><span class="p">)</span>
</code></pre></div></div>

<p>[<em>spam</em>]</p>

<p><img src="https://user-images.githubusercontent.com/39285147/180648230-596590f7-e756-42a4-83a0-92f6bc7cce72.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Spam percentage = 23.88268156424581 %
</code></pre></div></div>

<p>[<em>ham</em>]</p>

<p><img src="https://user-images.githubusercontent.com/39285147/180648232-5b6010a1-797f-4da6-b2c0-d0487d4c1f9c.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Ham percentage = 76.11731843575419 %
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Count"</span><span class="p">)</span> <span class="c1"># 각 카테고리 값별로 데이터가 얼마나 있는지 표시 Data distribution by category
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180648340-8fab09eb-0467-4352-9a2e-45bc857caf33.png" alt="image" /></p>

<h2 id="nlp">NLP</h2>

<h3 id="data-preprocessing">Data Preprocessing</h3>
<h4 id="불용어-제거--소문자-통일하기-stopwords-and-lowercase">불용어 제거 &amp; 소문자 통일하기 (Stopwords and lowercase)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)</span> <span class="c1"># 불용어 리스트 불러오기 Loading the list of stopwords
</span>
<span class="n">sample_data</span> <span class="o">=</span> <span class="p">[</span><span class="s">'This is the first document.'</span><span class="p">,</span><span class="s">'This document is the second document.'</span><span class="p">,</span><span class="s">'And this is the third one.'</span><span class="p">,</span><span class="s">'Is this the first document?'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ['i',
    'me',
    'my',
    'myself',
    'we',
    'our',
    'ours',
    'ourselves',
    'you',
    "you're",
    "you've",
    "you'll",
    "you'd",
    ...
    "weren't",
    'won',
    "won't",
    'wouldn',
    "wouldn't"]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sample_data</span><span class="p">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)]</span>
</code></pre></div></div>

<h4 id="removing-punctuation">Removing punctuation</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">string</span>
<span class="n">string</span><span class="p">.</span><span class="n">punctuation</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    '!"#$%&amp;\'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~'
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">sample_data</span> <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="count-vectorizer">Count Vectorizer</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span> <span class="c1"># Text to number
</span><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">())</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>  
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[0 1 1 1 0 0 1 0 1]
    [0 2 0 1 0 1 1 0 1]
    [1 0 0 1 1 0 1 1 1]
    [0 1 1 1 0 0 1 0 1]]
</code></pre></div></div>

<p>샘플에 존재하는 각 단어들이 인덱스로써 할당되는 <em>인코딩</em> 과정이 수행되었다. <span style="color: blue">Encoding process is complete.</span></p>

<p>무슨 말이냐면, ‘[0 1 1 1 0 0 1 0 1]’이라는 숫자화된 값은 하기처럼 매칭됩니다:</p>
<ul>
  <li><em>this: 0, is: 1, the: 1, first: 1, second: 0, third: 0, document: 1, and: 0, one: 0</em></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">message_cleaning</span><span class="p">)</span>
<span class="n">spamham_countvectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'text'</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="n">spamham_countvectorizer</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    ...
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spamham_countvectorizer</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (5728, 37229)
</code></pre></div></div>

<h2 id="creating-the-trainingtest-dataset">Creating the Training/Test dataset</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">].</span><span class="n">values</span> <span class="c1"># Loading the spam index (0 or 1)
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">spamham_countvectorizer</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span> 

<span class="n">NB_classifier</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">NB_classifier</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_countvectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># vectorizing the sample
</span><span class="n">test_predict</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_countvectorizer</span><span class="p">)</span> <span class="c1"># applying the classifier to the sample
</span></code></pre></div></div>

<p>만약, 메시지 내용의 spam 인자값이 1이라면, NBClassifier에 의해 스팸 메시지로 분류된 것이다. <span style="color: blue">If the spam parameter value of the message content is 1, it is classified as a spam message by the NBClassifier.</span></p>

<h2 id="evaluating-the-model-confusion-matrixclassification-report">Evaluating the model: Confusion Matrix/Classification Report</h2>

<h3 id="혼동-행렬-confusion-matrix">혼동 행렬 (Confusion Matrix)</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Confusion Matrix
</span><span class="n">y_predict_train</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_predict_train</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_predict_train</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180649439-46c5a9af-0ef0-4e10-80ca-41d6e978da11.png" alt="image" /></p>

<p>14(FN + FP)개의 오분류만 존재하고, 나머지는 전부 옳게 분류한 것을 볼 수 있다. <span style="color: blue">Training dataset –&gt; # errors = 14(FN + FP)</span></p>

<p>하지만, 이 결과값은 어디까지나 학습 데이터 훈련 성능이므로 테스트셋에서는 역전될 수 있으니 절대적 신뢰는 금물이다. <span style="color: blue">Cannot trust this result 100% because it is just based on the training dataset.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predicting the Test set results
</span><span class="n">y_predict_test</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180649505-8fd871fa-cd4b-4ae2-be89-b85f67a7a0b7.png" alt="image" /></p>

<p>다행히 테스트 데이터에서도 비슷한 성능 평가를 보여준다. 12개의 오분류만 존재하는 것을 확인해볼 수 있다. <span style="color: blue">Test dataset –&gt; # errors = 12(FN + FP)</span></p>

<p>하지만, 테스트셋과 training 데이터의 비율 분포에 주목하고, 절대적인 수치에 의존하여 성능 평가를 하면 안된다. <span style="color: blue">Paying attention to the distribution of the training and test dataset </span></p>

<h3 id="성능-지표-classification-report">성능 지표 (Classification Report)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                precision    recall  f1-score   support

            0       1.00      0.99      0.99       881
            1       0.96      0.99      0.98       265

    avg / total       0.99      0.99      0.99      1146
</code></pre></div></div>

<h1 id="part-2-yelp-reviews">PART 2: YELP Reviews</h1>
<p>‘엘프’는 기업체와 서비스에 대한 대중의 리뷰 포럼을 제공하는 앱으로 자연어 처리 기술을 사용해 엘프 리뷰를 분석해본다. <span style="color: blue">A public review forum for businesses and services, using natural language processing technology to analyze YELP reviews.</span></p>

<p>자연어 처리를 활용하여 리뷰에 있는 순수 텍스트에 기반해 고객 기분이 좋은지 나쁜지 감성 분석을 시행한 후, 모델이 자동적으로 해당 고객이 상품에 별점을 얼마나 부과할지 예측한다. <span style="color: blue">After sentiment analysis to raw test data using NLP, the model predicts appropriate star rate</span></p>

<h2 id="loading-the-dataset-1">Loading the dataset</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"yelp.csv"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180663433-611d058b-ec9e-4276-a517-9b7020c66700.png" alt="image" /></p>

<h2 id="data-visualization-1">Data Visualization</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df</span><span class="p">[</span><span class="s">'length'</span><span class="p">]</span> <span class="o">=</span> <span class="n">yelp_df</span><span class="p">[</span><span class="s">'text'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
<span class="n">yelp_df</span><span class="p">[</span><span class="s">'length'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">)</span> 
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180663579-4a692ad7-7df5-4913-8a64-d4edd41607ec.png" alt="image" /></p>

<p>대략 400단어가 분포에서 가장 많은 것으로 관찰된다. <span style="color: blue">Approximately, 400 words appear the most in the distribution</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df</span><span class="p">.</span><span class="n">length</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    count    10000.000000
    mean       710.738700
    std        617.399827
    min          1.000000
    25%        294.000000
    50%        541.500000
    75%        930.000000
    max       4997.000000
    Name: length, dtype: float64
</code></pre></div></div>

<p>위 결과에서 가장 많은 단어 수는 4997개이고, 평균 단어 수는 710인 것으로 발견됐다. <span style="color: blue">The max number of words = 4997, avg. = 710</span></p>

<p>그렇다면, 각 별점 별 리뷰 개수 분포는 어떠할까? <span style="color: blue">What about the star distribution?</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="s">'stars'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">yelp_df</span><span class="p">)</span> <span class="c1"># count by column 'stars'
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180664615-c1904d4b-a7f2-49b5-b6c1-4c5001687b63.png" alt="image" /></p>

<p>분포도에서 나온 바와 같이 별점 4점이 가장 많은 빈도수를 차지한다. <span style="color: blue">4 stars appear the most</span></p>

<p>여기서, 우리는 각 별점 별로 단어 길이 개수 분포를 확인해보고자 한다. <span style="color: blue">What about the length of words by star rate</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">yelp_df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'stars'</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># 한 줄에 총 5개 grid를 별점 기준으로 나누기
</span><span class="n">g</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">,</span> <span class="s">'length'</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'r'</span><span class="p">)</span> <span class="c1"># 히스토그램 w/ x-axis = length
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180664713-5cda0980-4cb4-4f77-b58d-b11f059294d7.png" alt="image" /></p>

<p>분포도에서 확인해볼 수 있듯이, x축은 단어의 길이를 나타낸다. <span style="color: blue">x-axis = length of words</span></p>

<p>따라서, 길이가 짧은 리뷰의 빈도수가 각 별점마다 높게 나타난 것을 확인해볼 수 있다. <span style="color: blue">The short length of reviews appear the most by each star rate</span></p>

<p>이제, 별점 1과 5를 비교해보자. <span style="color: blue">What about star rate 1 vs. 5?</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df_1</span> <span class="o">=</span> <span class="n">yelp_df</span><span class="p">[</span><span class="n">yelp_df</span><span class="p">[</span><span class="s">'stars'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">yelp_df_5</span> <span class="o">=</span> <span class="n">yelp_df</span><span class="p">[</span><span class="n">yelp_df</span><span class="p">[</span><span class="s">'stars'</span><span class="p">]</span><span class="o">==</span><span class="mi">5</span><span class="p">]</span>
<span class="n">yelp_df_1_5</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">yelp_df_1</span> <span class="p">,</span> <span class="n">yelp_df_5</span><span class="p">])</span> <span class="c1"># 한 행렬로 합치기
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span> <span class="s">'1-Stars percentage ='</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">yelp_df_1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">)</span> <span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">"%"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    1-Stars percentage = 18.330885952031327 %
</code></pre></div></div>

<p>별점 1점은 별점 5점에 대비하여 18.3%의 빈도수를 차지한다. <span style="color: blue">star rate 1 appear 18.3% more than 5</span></p>

<p>따라서, 별점 5점은 81.67%를 차지할 것이다. <span style="color: blue">hence, star rate 5 takes 81.67%</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'stars'</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Count"</span><span class="p">)</span> 
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180664906-878df245-f501-4236-bde6-903fd5cb8cee.png" alt="image" /></p>

<h2 id="nlp-1">NLP</h2>

<h3 id="불용어구두점-제거-stopwordspunctuation">불용어/구두점 제거 (Stopwords/Punctuation)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">message_cleaning</span><span class="p">(</span><span class="n">message</span><span class="p">):</span>
    <span class="n">Test_punc_removed</span> <span class="o">=</span> <span class="p">[</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">message</span> <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">]</span>
    <span class="n">Test_punc_removed_join</span> <span class="o">=</span> <span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">Test_punc_removed</span><span class="p">)</span>
    <span class="n">Test_punc_removed_join_clean</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">Test_punc_removed_join</span><span class="p">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">Test_punc_removed_join_clean</span>
</code></pre></div></div>

<details>
<summary>Result(hide/show)</summary>
<div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df_clean</span> <span class="o">=</span> <span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'text'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="n">message_cleaning</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">yelp_df_clean</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># show the cleaned up version
</span></code></pre></div>    </div>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ['wife', 'took', 'birthday', 'breakfast', 'excellent', 'weather', 'perfect', 'made', 'sitting', 'outside', 'overlooking', 'grounds', 'absolute', 'pleasure', 'waitress', 'excellent', 'food', 'arrived', 'quickly', 'semibusy', 'Saturday', 'morning', 'looked', 'like', 'place', 'fills', 'pretty', 'quickly', 'earlier', 'get', 'better', 'favor', 'get', 'Bloody', 'Mary', 'phenomenal', 'simply', 'best', 'Ive', 'ever', 'Im', 'pretty', 'sure', 'use', 'ingredients', 'garden', 'blend', 'fresh', 'order', 'amazing', 'EVERYTHING', 'menu', 'looks', 'excellent', 'white', 'truffle', 'scrambled', 'eggs', 'vegetable', 'skillet', 'tasty', 'delicious', 'came', '2', 'pieces', 'griddled', 'bread', 'amazing', 'absolutely', 'made', 'meal', 'complete', 'best', 'toast', 'Ive', 'ever', 'Anyway', 'cant', 'wait', 'go', 'back']
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'text'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># show the original version
</span></code></pre></div>    </div>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.

    Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.

    While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best "toast" I've ever had.

    Anyway, I can't wait to go back!
</code></pre></div>    </div>

  </div>
</details>

<h3 id="count-vectorizer-1"><a href="#count-vectorizer">Count Vectorizer</a></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">message_cleaning</span><span class="p">)</span>
<span class="n">yelp_countvectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'text'</span><span class="p">])</span>

<span class="n">yelp_countvectorizer</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (4086, 26435)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">yelp_countvectorizer</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>  
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    ...
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]]
</code></pre></div></div>

<h2 id="creating-the-trainingtest-dataset-1">Creating the Training/Test dataset</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">yelp_countvectorizer</span><span class="p">,</span> <span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'stars'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="training-the-model-naive-beyas">Training the model (Naive Beyas)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>

<span class="n">NB_classifier</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">NB_classifier</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="evaluating-the-model">Evaluating the model</h2>
<h3 id="confusion-matrix">Confusion Matrix</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">y_predict_train</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_predict_train</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_predict_train</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180665314-052c9c4f-9ee8-4e45-83e8-40498b220715.png" alt="image" /></p>

<p>모델이 학습 데이터를 훈련한 결과를 보여주는 상기 혼동 행렬에서 오분류가 64개인 것으로 확인된다. <span style="color: blue">Training dataset –&gt; # errors = 64 in confusion matrix</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predicting the Test set results
</span><span class="n">y_predict_test</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180665355-5991613d-7965-4802-982c-6913ef276720.png" alt="image" /></p>

<p>반대로 모델이 테스트 데이터를 예측한 결과를 보여주는 상기 혼동 행렬에서 오분류가 67개인 것으로 확인된다. <span style="color: blue">Test dataset –&gt; # errors = 67 in confusion matrix</span></p>

<h3 id="성능-지표-classification-report-1">성능 지표 (Classification Report)</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                precision    recall  f1-score   support

            1       0.86      0.68      0.76       156
            5       0.93      0.97      0.95       662

    avg / total       0.92      0.92      0.91       818
</code></pre></div></div>

<h2 id="tf-idf-term-frequency-inverse-document-frequency">TF-IDF (term frequency-inverse document frequency)</h2>
<p>정보 검색과 텍스트 마이닝에서 이용하는 가중치로, 여러 문서로 이루어진 문서군이 있을 때 어떤 단어가 특정 문서 내에서 얼마나 중요한 것인지를 나타내는 통계적 수치이다. <span style="color: blue">A statistical measure that evaluates how relevant a word is to a document in a collection of documents.</span></p>

<p>가령, 부동산 관련하여 ‘계약’이라는 단어가 지극히 중요할 것이다. <span style="color: blue">For example, ‘contract’ is important in terms of ‘real estates’</span></p>

<p>For more information, click <a href="https://hchoi256.github.io/nlp/nlp-basic-word-embedding/">here</a> or <a href="#code">code</a>.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#machine-learning" class="page__taxonomy-item p-category" rel="tag">machine learning</a><span class="sep">, </span>
    
      <a href="/tags/#python" class="page__taxonomy-item p-category" rel="tag">python</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#ml" class="page__taxonomy-item p-category" rel="tag">ML</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time class="dt-published" datetime="2022-07-24T00:00:00+09:00">2022-07-24</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">공유하기</h4>
  

  <a href="https://twitter.com/intent/tweet?text=ML+Project+5%3A+Natural+Language+Processing%20http%3A%2F%2Flocalhost%3A4000%2Fml%2Fml-projects-5%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fml%2Fml-projects-5%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fml%2Fml-projects-5%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ml/ml-projects-4/" class="pagination--pager" title="ML Project 4: LeNet - Traffic Signs Classification
">이전</a>
    
    
      <a href="/ml/ml-projects-6/" class="pagination--pager" title="ML Project 6: 사용자 기반 협업 필터링 (Collaborative Filtering) - 영화 추천 시스템 (Movie Recommender Systems)
">다음</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">참고</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/teeko.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml/ml-teeko-minimax/" rel="permalink">ML: Minimax 알고리즘 - Teeko Game
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-08-14T00:00:00+09:00">2022-08-14</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          5 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Minimax 알고리즘을 활용해서 Teeko 게임을 구현한다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/pca-image-compression.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml/ml-pca/" rel="permalink">ML: PCA - Image Compression(이미지 압축)
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-08-14T00:00:00+09:00">2022-08-14</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          2 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">PCA를 이용해서 이미지 압축을 진행해보자.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/hac.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ml/ml-hca/" rel="permalink">ML: Hierarchical Agglomerate Clustering(HAC) - 포켓몬 군집화
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-08-14T00:00:00+09:00">2022-08-14</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          4 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Hierarchical Agglomerate Clustering(HAC) 이용해서 서로 다른 특성을 공유하는 Pokemon들을 군집으로 묶어보자.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/lenet.JPG" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/dl/dl-miniplace-classification/" rel="permalink">DL: LeNet 신경망 - MiniPlaces 이미지 분류
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-08-14T00:00:00+09:00">2022-08-14</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          2 분 소요
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">LeNet 신경망을 활용해서 MiniPlaces 데이터셋 이미지 분류 작업을 수행한다.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    

    
      
        
          <li><a href="mailto:hchoi256@wisc.edu" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/hojun-choi-2b10b11a0/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://github.com/hchoi256" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="/assets/CV.pdf" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-link" aria-hidden="true"></i> CV</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 Hojun Eric Choi. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/ml/ml-projects-5/";  /* Replace PAGE_URL with your page's canonical URL variable */
      this.page.identifier = "/ml/ml-projects-5"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */
    };
    (function() { /* DON'T EDIT BELOW THIS LINE */
      var d = document, s = d.createElement('script');
      s.src = 'https://jjunes.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  





  </body>
</html>
