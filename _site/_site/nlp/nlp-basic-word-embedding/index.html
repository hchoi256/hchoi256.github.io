<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <!--í°íŠ¸ : "Nanum Gothic Coding", "Coming Soon"-->
    <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Coming+Soon&family=Nanum+Gothic+Coding&display=swap">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Coming+Soon&family=Nanum+Gothic+Coding&display=swap">
    
    <!--í°íŠ¸ : "Iropke Batang"-->
    <link rel="preload" as="style" href="https://cdn.jsdelivr.net/font-iropke-batang/1.2/font-iropke-batang.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/font-iropke-batang/1.2/font-iropke-batang.css">

    <!--í°íŠ¸ : "Cafe24Oneprettynight"-->
    <link rel="preload" as="style" href="/assets/css/main.css">

    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>NLP - Part 2: Word Embedding | ì •ë¦¬í•˜ì—¬ ë‚´ ê²ƒìœ¼ë¡œ, AI ğŸ“‚</title>
<meta name="description" content="ì–´ê°„ì¶”ì¶œ(Stemmer) vs. í‘œì œì–´ì¶”ì¶œ(Lemmatizer) Stemmer ë‹¨ì–´ì—ì„œ ì¼ë°˜ì ì¸ í˜•íƒœ ë° êµ´ì ˆ ì–´ë¯¸ë¥¼ ì œê±°í•˜ëŠ” í”„ë¡œì„¸ìŠ¤. A process for removing the commoner morphological and inflexional endings from words.">


  <meta name="author" content="ì­ŒìŠ¤ğŸ„">
  
  <meta property="article:author" content="ì­ŒìŠ¤ğŸ„">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="ì •ë¦¬í•˜ì—¬ ë‚´ ê²ƒìœ¼ë¡œ, AI ğŸ“‚">
<meta property="og:title" content="NLP - Part 2: Word Embedding">
<meta property="og:url" content="http://localhost:4000/nlp/nlp-basic-word-embedding/">


  <meta property="og:description" content="ì–´ê°„ì¶”ì¶œ(Stemmer) vs. í‘œì œì–´ì¶”ì¶œ(Lemmatizer) Stemmer ë‹¨ì–´ì—ì„œ ì¼ë°˜ì ì¸ í˜•íƒœ ë° êµ´ì ˆ ì–´ë¯¸ë¥¼ ì œê±°í•˜ëŠ” í”„ë¡œì„¸ìŠ¤. A process for removing the commoner morphological and inflexional endings from words.">



  <meta property="og:image" content="http://localhost:4000/assets/images/posts/nlp-thumbnail.jpg">





  <meta property="article:published_time" content="2022-07-20T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/nlp/nlp-basic-word-embedding/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "ì­ŒìŠ¤ğŸ„",
      "url": "http://localhost:4000/"
    
  }
</script>






  <meta name="naver-site-verification" content="57d020c8f9b26bf56ed7846608b8d873481e9b84">


<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="ì •ë¦¬í•˜ì—¬ ë‚´ ê²ƒìœ¼ë¡œ, AI ğŸ“‚ Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/logo.ico/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/logo.ico/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/logo.ico/favicon-16x16.png">
<link rel="mask-icon" href="/assets/logo.ico/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

    <!-- ìŠ¤í¬ë¡¤ë°” ì»¤ìŠ¤í„°ë§ˆì´ì§• -->
    <style> 
      ::-webkit-scrollbar{width: 16px;}
      ::-webkit-scrollbar-track {background-color:#4b4f52; border-radius: 16px;}
      ::-webkit-scrollbar-thumb {background-color:#5e6265; border-radius: 16px;}
      ::-webkit-scrollbar-thumb:hover {background: #ffd24c;}
      ::-webkit-scrollbar-button:start:decrement,::-webkit-scrollbar-button:end:increment 
      {
          width:12px;height:12px;background:transparent;}
      }  

      
    </style>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          ì •ë¦¬í•˜ì—¬ ë‚´ ê²ƒìœ¼ë¡œ, AI ğŸ“‚
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li><li class="masthead__menu-item">
              <a href="/search/">Search</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">í† ê¸€ ë©”ë‰´</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      




  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/" itemprop="item"><span itemprop="name">Home</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#nlp" itemprop="item"><span itemprop="name">Nlp</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">NLP - Part 2: Word Embedding</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/echoi.jpg" alt="ì­ŒìŠ¤ğŸ„" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">ì­ŒìŠ¤ğŸ„</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>I am a senior-year B.S. student in Computer Science and Data Science at the University of Wisconsin, Madison.</p>

<p>My research interests are <strong>hyper-scale AI</strong>, <strong>ML</strong>, <strong>deep NLP</strong>, and <strong>XAI in computer vision</strong>.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">íŒ”ë¡œìš°</button>
    <ul class="author__urls social-icons">
      

      
        
          
            <li><a href="mailto:hchoi256@wisc.edu" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://github.com/hchoi256" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="/assets/í¬íŠ¸í´ë¦¬ì˜¤.pdf" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Portfolio</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">í† ê¸€ ë©”ë‰´</label>
  <ul class="nav__items">
    
  </ul>
</nav>

    
  

  
    <!--ì „ì²´ ê¸€ ìˆ˜ë¥¼ ì„¸ê¸° ìœ„í•œ ì—°ì‚°. sum ë³€ìˆ˜ì— ì „ì²´ ê¸€ ìˆ˜ ì €ì¥-->



<nav class="nav__list">
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">í† ê¸€ ë©”ë‰´</label>
  <ul class="nav__items" id="category_tag_menu">
      <!--ì „ì²´ ê¸€ ìˆ˜-->
      <li>
            ğŸ“‚ <span style="font-family:'Cafe24Oneprettynight';">ì „ì²´ ê¸€ ìˆ˜</style> <span style="font-family:'Coming Soon';">40</style> <span style="font-family:'Cafe24Oneprettynight';">ê°œ</style> 
      </li>
      <li>
        <!--span íƒœê·¸ë¡œ ì¹´í…Œê³ ë¦¬ë“¤ì„ í¬ê²Œ ë¶„ë¥˜ ex) C/C++/C#-->
        <span class="nav__sub-title">Important</span>
        <!--ul íƒœê·¸ë¡œ ê°™ì€ ì¹´í…Œê³ ë¦¬ë“¤ ëª¨ì•„ë‘” í˜ì´ì§€ë“¤ ë‚˜ì—´-->
        <ul>
            <!--Cpp ì¹´í…Œê³ ë¦¬ ê¸€ë“¤ì„ ëª¨ì•„ë‘” í˜ì´ì§€ì¸ /categories/cpp ì£¼ì†Œì˜ ê¸€ë¡œ ë§í¬ ì—°ê²°-->
            <!--category[1].size ë¡œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°€ì§„ ê¸€ì˜ ê°œìˆ˜ í‘œì‹œ--> 
            
                
            
                
            
                
            
                
            
                
                    <li><a href="/categories/Star" class="">ê³µì§€ì‚¬í•­ (1)</a></li>
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        </ul>
        <ul>
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
                    <li><a href="/categories/Study" class="">AI ê¸°ë³¸ì§€ì‹ (1)</a></li>
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        </ul>
        <ul>
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
                    <li><a href="/categories/Python" class="">Python (2)</a></li>
                
            
                
            
                
            
                
            
                
            
                
            
        </ul>
        <ul>
            
                
                    <li><a href="/categories/Basic" class="">ê¸°íƒ€ (1)</a></li>
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
                
            
        </ul>
        <span class="nav__sub-title">ML/DL</span>
            <!--ul íƒœê·¸ë¡œ ê°™ì€ ì¹´í…Œê³ ë¦¬ë“¤ ëª¨ì•„ë‘” í˜ì´ì§€ë“¤ ë‚˜ì—´-->
            <ul>
                <!--Cpp ì¹´í…Œê³ ë¦¬ ê¸€ë“¤ì„ ëª¨ì•„ë‘” í˜ì´ì§€ì¸ /categories/cpp ì£¼ì†Œì˜ ê¸€ë¡œ ë§í¬ ì—°ê²°-->
                <!--category[1].size ë¡œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°€ì§„ ê¸€ì˜ ê°œìˆ˜ í‘œì‹œ--> 
                
                    
                
                    
                
                    
                        <li><a href="/categories/SL" class="">ì§€ë„í•™ìŠµ (14)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/categories/USL" class="">ë¹„ì§€ë„í•™ìŠµ (2)</a></li>
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/categories/RL" class="">ê°•í™”í•™ìŠµ (1)</a></li>
                    
                
            </ul>
        <span class="nav__sub-title">NLP</span>
            <!--ul íƒœê·¸ë¡œ ê°™ì€ ì¹´í…Œê³ ë¦¬ë“¤ ëª¨ì•„ë‘” í˜ì´ì§€ë“¤ ë‚˜ì—´-->
            <ul>
                <!--Cpp ì¹´í…Œê³ ë¦¬ ê¸€ë“¤ì„ ëª¨ì•„ë‘” í˜ì´ì§€ì¸ /categories/cpp ì£¼ì†Œì˜ ê¸€ë¡œ ë§í¬ ì—°ê²°-->
                <!--category[1].size ë¡œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°€ì§„ ê¸€ì˜ ê°œìˆ˜ í‘œì‹œ--> 
                
                    
                
                    
                        <li><a href="/categories/NLP" class="">NLP (8)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/categories/BERT" class="">BERT (3)</a></li>
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/categories/GPT" class="">GPT (1)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        <span class="nav__sub-title">AI Research Papers</span>
            <!--ul íƒœê·¸ë¡œ ê°™ì€ ì¹´í…Œê³ ë¦¬ë“¤ ëª¨ì•„ë‘” í˜ì´ì§€ë“¤ ë‚˜ì—´-->
            <ul>
                <!--Cpp ì¹´í…Œê³ ë¦¬ ê¸€ë“¤ì„ ëª¨ì•„ë‘” í˜ì´ì§€ì¸ /categories/cpp ì£¼ì†Œì˜ ê¸€ë¡œ ë§í¬ ì—°ê²°-->
                <!--category[1].size ë¡œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°€ì§„ ê¸€ì˜ ê°œìˆ˜ í‘œì‹œ--> 
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/categories/AIPaperCV" class="">CV (1)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                <!--Cpp ì¹´í…Œê³ ë¦¬ ê¸€ë“¤ì„ ëª¨ì•„ë‘” í˜ì´ì§€ì¸ /categories/cpp ì£¼ì†Œì˜ ê¸€ë¡œ ë§í¬ ì—°ê²°-->
                <!--category[1].size ë¡œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¥¼ ê°€ì§„ ê¸€ì˜ ê°œìˆ˜ í‘œì‹œ--> 
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/categories/AIPaperNLP" class="">NLP (1)</a></li>
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/categories/AIPaperOthers" class="">ê¸°íƒ€ (1)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>        
      </li>
  </ul>
</nav>

  

  </div>


  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="NLP - Part 2: Word Embedding">
    <meta itemprop="description" content="ì–´ê°„ì¶”ì¶œ(Stemmer) vs. í‘œì œì–´ì¶”ì¶œ(Lemmatizer)Stemmerë‹¨ì–´ì—ì„œ ì¼ë°˜ì ì¸ í˜•íƒœ ë° êµ´ì ˆ ì–´ë¯¸ë¥¼ ì œê±°í•˜ëŠ” í”„ë¡œì„¸ìŠ¤. A process for removing the commoner morphological and inflexional endings from words.">
    <meta itemprop="datePublished" content="2022-07-20T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/nlp/nlp-basic-word-embedding/" class="u-url" itemprop="url">NLP - Part 2: Word Embedding
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          22 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> GITHUB BLOG JJUNS</h4></header>
              <ul class="toc__menu"><li><a href="#ì–´ê°„ì¶”ì¶œstemmer-vs-í‘œì œì–´ì¶”ì¶œlemmatizer">ì–´ê°„ì¶”ì¶œ(Stemmer) vs. í‘œì œì–´ì¶”ì¶œ(Lemmatizer)</a><ul><li><a href="#stemmer">Stemmer</a></li><li><a href="#lemmatizer">Lemmatizer</a></li></ul></li><li><a href="#chunking">Chunking</a></li><li><a href="#bag-of-words">Bag of Words</a></li><li><a href="#vectorization">Vectorization</a><ul><li><a href="#why-we-need-vectorization">Why We Need Vectorization?</a></li><li><a href="#1-countvectorizer">1. CountVectorizer</a><ul><li><a href="#exercise">Exercise</a></li></ul></li><li><a href="#2-tf-idf">2. TF-IDF</a><ul><li><a href="#cosine-similarity">Cosine Similarity</a></li></ul></li><li><a href="#3-hashing-vectorizer">3. Hashing Vectorizer</a></li><li><a href="#4-featurehasher">4. FeatureHasher</a></li><li><a href="#5-dict-vectorizer">5. Dict Vectorizer</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <h1 id="ì–´ê°„ì¶”ì¶œstemmer-vs-í‘œì œì–´ì¶”ì¶œlemmatizer">ì–´ê°„ì¶”ì¶œ(Stemmer) vs. í‘œì œì–´ì¶”ì¶œ(Lemmatizer)</h1>
<h2 id="stemmer">Stemmer</h2>
<p>ë‹¨ì–´ì—ì„œ ì¼ë°˜ì ì¸ í˜•íƒœ ë° êµ´ì ˆ ì–´ë¯¸ë¥¼ ì œê±°í•˜ëŠ” í”„ë¡œì„¸ìŠ¤. <span style="color: blue">A process for removing the commoner morphological and inflexional endings from words.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="kn">import</span> <span class="n">PorterStemmer</span> <span class="c1"># least strict
</span><span class="kn">from</span> <span class="nn">nltk.stem.snowball</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span> <span class="c1"># average (best)
</span><span class="kn">from</span> <span class="nn">nltk.stem.lancaster</span> <span class="kn">import</span> <span class="n">LancasterStemmer</span> <span class="c1"># most strict 
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input_words</span> <span class="o">=</span> <span class="p">[</span><span class="s">'writing'</span><span class="p">,</span> <span class="s">'calves'</span><span class="p">,</span> <span class="s">'be'</span><span class="p">,</span> <span class="s">'branded'</span><span class="p">,</span> <span class="s">'house'</span><span class="p">,</span> <span class="s">'randomize'</span><span class="p">,</span> <span class="s">'possibly'</span><span class="p">,</span> <span class="s">'extraction'</span><span class="p">,</span> <span class="s">'hospital'</span><span class="p">,</span> <span class="s">'kept'</span><span class="p">,</span> <span class="s">'scratchy'</span><span class="p">,</span> <span class="s">'code'</span><span class="p">]</span> <span class="c1"># sample
</span>
<span class="n">porter</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
<span class="n">snowball</span> <span class="o">=</span> <span class="n">SnowballStemmer</span><span class="p">(</span><span class="s">"english"</span><span class="p">)</span>
<span class="n">lancaster</span> <span class="o">=</span> <span class="n">LancasterStemmer</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stemmers_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"PORTER"</span><span class="p">,</span> <span class="s">"SNOWBALL"</span><span class="p">,</span> <span class="s">"LANCASTER"</span><span class="p">]</span>
<span class="n">formatted_text</span> <span class="o">=</span> <span class="s">"{:&gt;16}"</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stemmers_names</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">formatted_text</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"INPUT WORD"</span><span class="p">,</span> <span class="o">*</span><span class="n">stemmers_names</span><span class="p">),</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"="</span><span class="o">*</span><span class="mi">68</span><span class="p">)</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">input_words</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">,</span> <span class="n">porter</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">),</span> <span class="n">snowball</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">),</span> <span class="n">lancaster</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">formatted_text</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="o">*</span><span class="n">output</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      INPUT WORD          PORTER        SNOWBALL       LANCASTER 
====================================================================
        writing           write           write            writ
          calves            calv            calv            calv
              be              be              be              be
        branded           brand           brand           brand
          house            hous            hous            hous
      randomize          random          random          random
        possibly         possibl         possibl            poss
      extraction         extract         extract         extract
        hospital          hospit          hospit          hospit
            kept            kept            kept            kept
        scratchy        scratchi        scratchi        scratchy
            code            code            code             cod
</code></pre></div></div>

<h2 id="lemmatizer">Lemmatizer</h2>
<p>â€˜ë‹¨ì–´ì˜ ì›í˜•â€™ì„ ì°¾ê³ ì í•˜ëŠ” ë˜ ë‹¤ë¥¸ í˜•íƒœ, í‘œì œì–´ëŠ” ë‹¨ì–´ì˜ ë‹¤ì–‘í•œ êµ´ì ˆ í˜•íƒœë¥¼ ê·¸ë£¹í™”í•˜ì—¬ ë‹¨ì¼ í•­ëª©ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê³¼ì •ì´ë‹¤. <span style="color: blue">Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
<span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"wordnet"</span><span class="p">)</span>
<span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"omw-1.4"</span><span class="p">)</span>

<span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lemmatizer_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"NOUN LEMMATIZER"</span><span class="p">,</span> <span class="s">"VERB LEMMATIZER"</span><span class="p">]</span>
<span class="n">formatted_text</span> <span class="o">=</span> <span class="s">"{:&gt;24}"</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lemmatizer_names</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">formatted_text</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"INPUT WORD"</span><span class="p">,</span> <span class="o">*</span><span class="n">lemmatizer_names</span><span class="p">),</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="s">"="</span><span class="o">*</span><span class="mi">75</span><span class="p">)</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">input_words</span><span class="p">:</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">,</span> <span class="n">lemmatizer</span><span class="p">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="s">"n"</span><span class="p">),</span> <span class="n">lemmatizer</span><span class="p">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="s">"v"</span><span class="p">)]</span>
    <span class="k">print</span><span class="p">(</span><span class="n">formatted_text</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="o">*</span><span class="n">output</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              INPUT WORD         NOUN LEMMATIZER         VERB LEMMATIZER 
===========================================================================
                writing                 writing                   write
                  calves                    calf                   calve
                      be                      be                      be
                branded                 branded                   brand
                  house                   house                   house
              randomize               randomize               randomize
                possibly                possibly                possibly
              extraction              extraction              extraction
                hospital                hospital                hospital
                    kept                    kept                    keep
                scratchy                scratchy                scratchy
                    code                    code                    code
</code></pre></div></div>

<h1 id="chunking">Chunking</h1>
<p>í…ìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¶”ê°€ ë¶„ì„ì„ ìœ„í•´ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì•¼ í•  í•„ìš”ê°€ ìˆë‹¤. <span style="color: blue">Text data usually needs to be broken into pieces for further analysis.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">brown</span>
<span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"brown"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">chunker</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">input_words</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">cur_chunk</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">input_words</span><span class="p">:</span>
        <span class="n">cur_chunk</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="n">N</span><span class="p">:</span>
            <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">cur_chunk</span><span class="p">))</span>
            <span class="c1"># print(cur_chunk)
</span>            <span class="n">count</span><span class="p">,</span> <span class="n">cur_chunk</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="p">[]</span>
        <span class="c1"># print(output)
</span>
    <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">cur_chunk</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">output</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input_data</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">brown</span><span class="p">.</span><span class="n">words</span><span class="p">()[:</span><span class="mi">14000</span><span class="p">])</span>
<span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">700</span>
<span class="n">chunks</span> <span class="o">=</span> <span class="n">chunker</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
</code></pre></div></div>

<p>ìƒê¸° ì½”ë“œëŠ” brown ë¼ì´ë¸ŒëŸ¬ë¦¬ ë°ì´í„°ì˜ 14000 ë‹¨ì–´ë¥¼ ë¶ˆëŸ¬ì™€ 700ê°œì˜ ë‹¨ì–´ ë‹¨ìœ„ë¡œ chunkë¥¼ ìƒì„±í•œë‹¤. <span style="color: blue">The above code fetches 14000 words of brown library data and creates chunks in units of 700 words.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Number of text chunks ="</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">),</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">chunks</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Chunk"</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="s">"==&gt;"</span> <span class="p">,</span><span class="n">chunk</span><span class="p">[:</span><span class="mi">50</span><span class="p">])</span> <span class="c1"># show 50 words out of 700
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of text chunks = 21 

Chunk 1 ==&gt; The Fulton County Grand Jury said Friday an invest
Chunk 2 ==&gt; '' . ( 2 ) Fulton legislators `` work with city of
Chunk 3 ==&gt; . Construction bonds Meanwhile , it was learned th
Chunk 4 ==&gt; , anonymous midnight phone calls and veiled threat
Chunk 5 ==&gt; Harris , Bexar , Tarrant and El Paso would be $451
Chunk 6 ==&gt; set it for public hearing on Feb. 22 . The proposa
Chunk 7 ==&gt; College . He has served as a border patrolman and 
Chunk 8 ==&gt; of his staff were doing on the address involved co
Chunk 9 ==&gt; plan alone would boost the base to $5,000 a year a
Chunk 10 ==&gt; nursing homes In the area of `` community health s
Chunk 11 ==&gt; of its Angola policy prove harsh , there has been 
Chunk 12 ==&gt; system which will prevent Laos from being used as 
Chunk 13 ==&gt; reform in recipient nations . In Laos , the admini
Chunk 14 ==&gt; . He is not interested in being named a full-time 
Chunk 15 ==&gt; said , `` to obtain the views of the general publi
Chunk 16 ==&gt; '' . Mr. Reama , far from really being retired , i
Chunk 17 ==&gt; making enforcement of minor offenses more effectiv
Chunk 18 ==&gt; to tell the people where he stands on the tax issu
Chunk 19 ==&gt; '' . Trenton -- William J. Seidel , state fire war
Chunk 20 ==&gt; not comment on tax reforms or other issues in whic
Chunk 21 ==&gt; 
</code></pre></div></div>

<p>700(# words per chunk) * 20(# chunks) = 14000 (total words)</p>

<h1 id="bag-of-words">Bag of Words</h1>
<p>Bag of Words ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ í…ìŠ¤íŠ¸ ë¶„ì„ì„ í•˜ëŠ” ì£¼ìš” ëª©ì  ì¤‘ì— í•˜ë‚˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ê¸°ê³„í•™ìŠµì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ë‹¤. <span style="color: blue">One of the main purposes of text analysis using the Bag of Words model is to convert the text into a numeric form so that it can be used in machine learning.</span></p>

<p>ìˆ˜ë°±ë§Œ ë‹¨ì–´ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ë ¤ê³  í•œë‹¤. <span style="color: blue">You want to analyze a text document containing millions of words.</span></p>

<p>ê·¸ëŸ¬ê¸° ìœ„í•´ì„ , í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ìˆ«ì í‘œí˜„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•œë‹¤. <span style="color: blue">To do that, we need to extract the text and convert it to a numeric representation.</span></p>

<p>ê¸°ê³„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì˜ë¯¸ ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡ ì‘ì—…í•  ìˆ«ì ë°ì´í„°ê°€ í•„ìš”í•˜ë‹¤. <span style="color: blue">Machine learning algorithms need numeric data to work with so that they can analyze the data and extract meaningful information.</span></p>

<p>Bag of Words ëª¨ë¸ì€ ë¬¸ì„œì˜ ëª¨ë“  ë‹¨ì–´ì—ì„œ ì–´íœ˜ë¥¼ ì¶”ì¶œí•˜ê³  ë¬¸ì„œ-ìš©ì–´ í–‰ë ¬ (matrix)ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ êµ¬ì¶•í•œë‹¤. <span style="color: blue">The Bag of Words model extracts vocabulary from every word in a document and builds the model using a document-term matrix.</span></p>
<ul>
  <li>ì´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ëª¨ë“  ë¬¸ì„œë¥¼ ë‹¨ì–´ ëª¨ìŒìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. <span style="color: blue">This model allows any document to be represented as a collection of words.</span></li>
  <li>ë‹¨ì–´ ê°¯ìˆ˜, ë¬¸ë²•ì  ì„¸ë¶€ ì‚¬í•­, ë‹¨ì–´ ìˆœì„œë¥¼ ë¬´ì‹œí•œë‹¤. <span style="color: blue">Ignoring word count, grammatical details, and word order.</span></li>
</ul>

<p>ë¬¸ì„œ-ìš©ì–´ í–‰ë ¬ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë¬¸ì„œì—ì„œ ë°œìƒí•˜ëŠ” ë‹¤ì–‘í•œ ë‹¨ì–´ì˜ ìˆ˜ë¥¼ ì œê³µí•˜ëŠ” í…Œì´ë¸”ì´ë‹¤. <span style="color: blue">The document-term matrix is â€‹â€‹basically a table that gives the number of different words that occur in a document.</span></p>

<p>í…ìŠ¤íŠ¸ ë¬¸ì„œëŠ” ë‹¤ì–‘í•œ ë‹¨ì–´ì˜ ê°€ì¤‘ì¹˜ ì¡°í•­ìœ¼ë¡œ í‘œí˜„ë˜ê³ , ì„ê³„ê°’ì„ ì„¤ì •í•˜ê³  ë” ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ë¥¼ ì„ íƒí•  ìˆ˜ ìˆë‹¤. <span style="color: blue">Text documents are represented by weighted clauses of various words; more meaningful with thresholds words can be selected.</span></p>

<p>feature vectorë¡œ ì‚¬ìš©ë  ë¬¸ì„œì˜ ëª¨ë“  ë‹¨ì–´ë“¤ì˜ íˆìŠ¤í† ê·¸ë¨ì„ ë§Œë“¤ê³ , ì´ feature vectorëŠ” í…ìŠ¤íŠ¸ ë¶„ë¥˜ì— ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. <span style="color: blue">Creating a histogram of all words in the document to be used as a feature vector, and this feature vector can be used for text classification.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input_data</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">brown</span><span class="p">.</span><span class="n">words</span><span class="p">()[:</span><span class="mi">5500</span><span class="p">])</span>
<span class="n">chunk_size</span> <span class="o">=</span> <span class="mi">800</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">chunker</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">chunk_size</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">count</span><span class="p">,</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s">"index"</span><span class="p">:</span> <span class="n">count</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="n">chunk</span><span class="p">}</span>
    <span class="n">chunks</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>7
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">count_vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">document_term_matrix</span> <span class="o">=</span> <span class="n">count_vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">([</span><span class="n">chunk</span><span class="p">[</span><span class="s">"text"</span><span class="p">]</span> <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">])</span>
<span class="n">vocabulary</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">count_vectorizer</span><span class="p">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['000' '10' '100' ... 'york' 'you' 'your']
</code></pre></div></div>

<blockquote>
  <p><a href="#1-countvectorizer">CountVectorizer</a></p>
</blockquote>

<h1 id="vectorization">Vectorization</h1>

<h2 id="why-we-need-vectorization">Why We Need Vectorization?</h2>
<p>Machine (ê¸°ê³„)ëŠ” ë¬¸ìì™€ ë‹¨ì–´ë¥¼ ì´í•´í•  ìˆ˜ ì—†ë‹¤. <span style="color: blue">Machines cannot understand sentences or words. </span></p>

<p>0ê³¼ 1ë¡œ ì´ë£¨ì–´ì§„ ì´ì§„ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ê¸°ê³„ëŠ” ì´í•´í•  ìˆ˜ ìˆë‹¤. <span style="color: blue">But they can understand binary data (i.e., 0101010)  </span></p>

<p><strong>Computer Vision</strong>ì˜ ê°€ì¥ ê¸°ë³¸ì€ ì´ë¯¸ì§€ëŠ” í”½ì…€ (pixel)ë¡œ ì´ë£¨ì–´ì ¸ ìˆê³ , í”½ì…€ì— ëŒ€í•œ ì •ë³´ëŠ” x, yì™€ ê°™ì€ í”½ì…€ì˜ ìœ„ì¹˜ ê·¸ë¦¬ê³  í•´ë‹¹ í”½ì…€ì˜ ìƒ‰ìƒ ì •ë³´ (ë³´í†µ RGB)ë¥¼ ê°€ì§€ê³  ìˆë‹¤. ì´ëŸ° ì •ë³´ë“¤ì€ ìˆ«ìë¡œ ì‰½ê²Œ ë§Œë“¤ ìˆ˜ê°€ ìˆë‹¤! <span style="color: blue"><strong>Computer Vision</strong> is a collection of pixels requiring information about the location of x, y, and RGB. We can easily produce such information with numbers.</span></p>

<p><strong>NLP</strong>ì˜ í…ìŠ¤íŠ¸ ë°ì´í„° ì—­ì‹œ ê¸°ê³„ê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ìˆ«ìë¡œ í‘œí˜„í•´ì•¼ í•œë‹¤. <span style="color: blue">In NLP, text data must also be numbers.</span></p>

<p><strong>CountVectorizer</strong> í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì ë°ì´í„°ë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ, í…ìŠ¤íŠ¸ë¥¼ ìˆ˜ì¹˜ ë°ì´í„°ë¡œ ë³€í™”í•˜ëŠ”ë° ì‚¬ìš©í•˜ëŠ” method! sklearnì„ í†µí•´ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤. <span style="color: blue"><strong>CountVectorizer</strong> is the method to convert text to numbers, which can be achieved with <em>sklearn</em>.</span></p>

<h2 id="1-countvectorizer">1. CountVectorizer</h2>
<p>í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ â€˜íšŸìˆ˜â€™ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì´ë‹¤. <span style="color: blue">Extracting features by â€˜numberâ€™ from text data.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">text1</span> <span class="o">=</span><span class="s">'''Tracy loves writing about data science.'''</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s">'''Tracy loves writing for medium publications.'''</span>
<span class="n">text3</span> <span class="o">=</span> <span class="s">'''Tracy loves studying Python programming.'''</span>
<span class="n">text4</span> <span class="o">=</span> <span class="s">'''Tracy loves entering Kaggle competitions.'''</span>
<span class="n">text5</span> <span class="o">=</span> <span class="s">'''Tracy loves making YouTube videos.'''</span>
<span class="n">text6</span> <span class="o">=</span> <span class="s">'''Tracy loves getting new subscribers.'''</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">text3</span><span class="p">,</span> <span class="n">text4</span><span class="p">,</span> <span class="n">text5</span><span class="p">,</span> <span class="n">text6</span><span class="p">]</span>
<span class="n">count_vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>

<span class="n">word_count_vec</span> <span class="o">=</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">word_count_vec</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(6, 21)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">count_vec</span><span class="p">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['about' 'competitions' 'data' 'entering' 'for' 'getting' 'kaggle' 'loves'
 'making' 'medium' 'new' 'programming' 'publications' 'python' 'science'
 'studying' 'subscribers' 'tracy' 'videos' 'writing' 'youtube']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Vocabulary: "</span><span class="p">,</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">vocabulary_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Vocabulary:  {'tracy': 17, 'loves': 7, 'writing': 19, 'about': 0, 'data': 2, 'science': 14, 'for': 4, 'medium': 9, 'publications': 12, 'studying': 15, 'python': 13, 'programming': 11, 'entering': 3, 'kaggle': 6, 'competitions': 1, 'making': 8, 'youtube': 20, 'videos': 18, 'getting': 5, 'new': 10, 'subscribers': 16}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Encoded Document is: "</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">word_count_vec</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Encoded Document is: 
[[1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0]
 [0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0]
 [0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0]
 [0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0]
 [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1]
 [0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">matrix</span> <span class="o">=</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">"display.max_columns"</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="c1"># show table on one page
</span><span class="n">counts</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">matrix</span><span class="p">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s">"doc1"</span><span class="p">,</span> <span class="s">"doc2"</span><span class="p">,</span> <span class="s">"doc3"</span><span class="p">,</span> <span class="s">"doc4"</span><span class="p">,</span> <span class="s">"doc5"</span><span class="p">,</span> <span class="s">"doc6"</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="n">counts</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="s">"Total"</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">counts</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>about</th>
      <th>competitions</th>
      <th>data</th>
      <th>entering</th>
      <th>for</th>
      <th>getting</th>
      <th>kaggle</th>
      <th>loves</th>
      <th>making</th>
      <th>medium</th>
      <th>new</th>
      <th>programming</th>
      <th>publications</th>
      <th>python</th>
      <th>science</th>
      <th>studying</th>
      <th>subscribers</th>
      <th>tracy</th>
      <th>videos</th>
      <th>writing</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>doc1</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc4</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc5</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>doc6</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Total</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="exercise">Exercise</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">"Electronics_data.xlsx"</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>sentiment</th>
      <th>title</th>
      <th>Reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>2</td>
      <td>Great CD</td>
      <td>My lovely Pat has one of the GREAT voices of h...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>One of the best game music soundtracks - for a...</td>
      <td>Despite the fact that I have only played a sma...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>Batteries died within a year ...</td>
      <td>I bought this charger in Jul 2003 and it worke...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>works fine, but Maha Energy is better</td>
      <td>Check out Maha Energy's website. Their Powerex...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>2</td>
      <td>Great for the non-audiophile</td>
      <td>Reviewed quite a bit of the combo players and ...</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(50000, 4)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">[</span><span class="s">"Full_text"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"title"</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"Reviews"</span><span class="p">],</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">" "</span><span class="p">)</span> <span class="c1"># titleê³¼ Reviews í•©ì¹˜ê¸°
</span><span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>sentiment</th>
      <th>title</th>
      <th>Reviews</th>
      <th>Full_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>2</td>
      <td>Great CD</td>
      <td>My lovely Pat has one of the GREAT voices of h...</td>
      <td>Great CD My lovely Pat has one of the GREAT vo...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>One of the best game music soundtracks - for a...</td>
      <td>Despite the fact that I have only played a sma...</td>
      <td>One of the best game music soundtracks - for a...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>Batteries died within a year ...</td>
      <td>I bought this charger in Jul 2003 and it worke...</td>
      <td>Batteries died within a year ... I bought this...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>works fine, but Maha Energy is better</td>
      <td>Check out Maha Energy's website. Their Powerex...</td>
      <td>works fine, but Maha Energy is better Check ou...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>2</td>
      <td>Great for the non-audiophile</td>
      <td>Reviewed quite a bit of the combo players and ...</td>
      <td>Great for the non-audiophile Reviewed quite a ...</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corpus</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Full_text'</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span> <span class="c1"># Fulltext ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ corpusì— ì €ì¥
</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>500
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="n">stop_words</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">corpus</span><span class="p">.</span><span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">porter</span><span class="p">.</span><span class="n">PorterStemmer</span><span class="p">()</span> <span class="c1"># ì–´ê°„ ì¶”ì¶œ (i.e., dies/dead/died --&gt; die)
</span>
<span class="k">def</span> <span class="nf">normalize_document</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># normalization
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">'[^a-zA-Z\s]'</span><span class="p">,</span> <span class="s">""</span><span class="p">,</span> <span class="n">doc</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">I</span><span class="o">|</span><span class="n">re</span><span class="p">.</span><span class="n">A</span><span class="p">)</span> <span class="c1"># êµ¬ë‘ì  ë° íŠ¹ìˆ˜ë¬¸ì ì œê±° remove punctuation and speical characteristics
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span>   <span class="c1"># ì†Œë¬¸ìí™” lowercase
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>   <span class="c1"># ë¬¸ìì—´ì˜ ì• ë’¤ì— ìˆì„ ë¹ˆ ì¹¸ ì œê±° strip string
</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="c1"># tokenization
</span>
    <span class="n">filtered_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span> <span class="c1"># remove stopwords
</span>
    <span class="c1"># doc = " ".join(filtered_tokens)
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">([</span> <span class="n">ps</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">filtered_tokens</span> <span class="p">])</span>

    <span class="k">return</span> <span class="n">doc</span>  
</code></pre></div></div>

<blockquote>
  <table>
    <tbody>
      <tr>
        <td>re.I</td>
        <td>re.A: re.subì˜ flags (<a href="https://docs.python.org/ko/3/library/re.html">click</a>)</td>
      </tr>
    </tbody>
  </table>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">normalize_corpus</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">normalize_document</span><span class="p">)</span> <span class="c1"># vectorize the text
</span><span class="n">norm_corpus</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="c1"># noremarize the corpus
</span><span class="n">norm_corpus</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['great cd love pat one great voic gener listen cd year still love im good mood make feel better bad mood evapor like sugar rain cd ooz life vocal jusat stuun lyric kill one life hidden gem desert isl cd book never made big beyond everytim play matter black white young old male femal everybodi say one thing sing',
       'one best game music soundtrack game didnt realli play despit fact play small portion game music heard plu connect chrono trigger great well led purchas soundtrack remain one favorit album incred mix fun epic emot song sad beauti track especi like there mani kind song video game soundtrack must admit one song lifea distant promis brought tear eye mani occasionsmi one complaint soundtrack use guitar fret effect mani song find distract even werent includ would still consid collect worth',
       'batteri die within year bought charger jul work ok design nice conveni howev year batteri would hold charg might well get alkalin dispos look elsewher charger come batteri better stay power',
      ...])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span> <span class="c1"># perform vectorization
</span><span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv_matrix</span><span class="p">.</span><span class="n">toarray</span><span class="p">()</span> <span class="c1"># pd.DataFrame ì¸ìë¡œ ë„£ê¸°ìœ„í•´ ë°°ì—´í™” to be used for pd.DataFrame
</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vocabulary</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4754
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">one_hot</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span> <span class="n">vocabulary</span><span class="p">)</span>
<span class="n">one_hot</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(500, 4754)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">one_hot</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aa</th>
      <th>abbrevi</th>
      <th>abduct</th>
      <th>abil</th>
      <th>abl</th>
      <th>aboard</th>
      <th>abor</th>
      <th>abound</th>
      <th>abridg</th>
      <th>abroad</th>
      <th>...</th>
      <th>yr</th>
      <th>yum</th>
      <th>yuppi</th>
      <th>zebra</th>
      <th>zep</th>
      <th>zero</th>
      <th>zhivago</th>
      <th>zillion</th>
      <th>zr</th>
      <th>zydeco</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>495</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>496</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>497</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>498</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>499</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>500 rows Ã— 4754 columns</p>
</div>

<h2 id="2-tf-idf">2. TF-IDF</h2>
<p>ì •ë³´ ê²€ìƒ‰ê³¼ í…ìŠ¤íŠ¸ ë§ˆì´ë‹ì—ì„œ ì´ìš©í•˜ëŠ” ê°€ì¤‘ì¹˜ë¡œ, ì—¬ëŸ¬ ë¬¸ì„œë¡œ ì´ë£¨ì–´ì§„ ë¬¸ì„œêµ°ì´ ìˆì„ ë•Œ ì–´ë–¤ ë‹¨ì–´ê°€ íŠ¹ì • ë¬¸ì„œ ë‚´ì—ì„œ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œ ê²ƒì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í†µê³„ì  ìˆ˜ì¹˜ì´ë‹¤. <span style="color: blue">a statistical measure that evaluates how relevant a word is to a document in a collection of documents</span></p>

<p><em>TF</em>: íŠ¹ì • ë‹¨ì–´ê°€ í•˜ë‚˜ì˜ ë°ì´í„° ì•ˆì—ì„œ ë“±ì¥í•˜ëŠ” íšŸìˆ˜ <span style="color: blue">how many times certain word appears in one data</span></p>

<p><em>DF</em>: ë¬¸ì œ ë¹ˆë„ ê°’ìœ¼ë¡œ, íŠ¹ì • ë‹¨ì–´ê°€ ì—¬ëŸ¬ ë°ì´í„°ì— ìì£¼ ë“±ì¥í•˜ëŠ”ì§€ ì•Œë ¤ì£¼ëŠ” ì§€í‘œ <span style="color: blue">how many times certain word appears in other data</span></p>

<p><em>IDF(Inverse)</em>: DFì˜ ì—­ìˆ˜ë¥¼ ì·¨í•´ì„œ êµ¬í•˜ë©°, íŠ¹ì • ë‹¨ì–´ê°€ ë‹¤ë¥¸ ë°ì´í„°ì— ë“±ì¥í•˜ì§€ ì•Šì„ ê²½ìš° ê°’ì´ ì»¤ì§„ë‹¤ <span style="color: blue">As a word doesnâ€™t appear in other data, IDF increases</span></p>

<p>TF-IDFë€ ì´ ë‘ ê°’ì„ ê³±í•´ì„œ ì‚¬ìš©í•˜ë¯€ë¡œ ì–´ë–¤ ë‹¨ì–´ê°€ í•´ë‹¹ ë¬¸ì„œì— ìì£¼ ë“±ì¥í•˜ì§€ë§Œ ë‹¤ë¥¸ ë¬¸ì„œì—ëŠ” ë§ì´ ì—†ëŠ” ë‹¨ì–´ì¼ìˆ˜ë¡ ë†’ì€ ê°’ì„ ê°€ì§„ë‹¤. <span style="color: blue">TF-IDF is computed by the multiplication of TF and IDF.</span></p>

<p>ë”°ë¼ì„œ, ì¡°ì‚¬ë‚˜ ì§€ì‹œëŒ€ëª…ì‚¬ì²˜ëŸ¼ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ëŠ” TF ê°’ì€ í¬ì§€ë§Œ IDF ê°’ì€ ì‘ì•„ì§€ë¯€ë¡œ CountVectorizerê°€ ê°€ì§„ ë¬¸ì œì ì´ í•´ê²° ê°€ëŠ¥í•˜ë‹¤.<span style="color: blue"> Thus, TF-IDF overcomes the limits of CountVectorizer.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text1</span> <span class="o">=</span><span class="s">'''Tracy loves writing about data science.'''</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s">'''Tracy loves writing for medium publications.'''</span>
<span class="n">text3</span> <span class="o">=</span> <span class="s">'''Tracy loves studying Python programming.'''</span>
<span class="n">text4</span> <span class="o">=</span> <span class="s">'''Tracy loves entering Kaggle competitions.'''</span>
<span class="n">text5</span> <span class="o">=</span> <span class="s">'''Tracy loves making YouTube videos.'''</span>
<span class="n">text6</span> <span class="o">=</span> <span class="s">'''Tracy loves getting new subscribers.'''</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">text3</span><span class="p">,</span> <span class="n">text4</span><span class="p">,</span> <span class="n">text5</span><span class="p">,</span> <span class="n">text6</span><span class="p">]</span>
<span class="n">corpus</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['Tracy loves writing about data science.',
 'Tracy loves writing for medium publications.',
 'Tracy loves studying Python programming.',
 'Tracy loves entering Kaggle competitions.',
 'Tracy loves making YouTube videos.',
 'Tracy loves getting new subscribers.']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span> <span class="c1"># CountVectorizer
</span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span> <span class="c1"># TfidfTransformer
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">count_vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">matrix</span> <span class="o">=</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">tf_transformer</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span> <span class="c1"># train TF-IDF
</span><span class="n">word_count_vec_tf</span> <span class="o">=</span> <span class="n">tf_transformer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span> <span class="c1"># apply TF-IDF
</span><span class="n">word_count_vec_tf</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(6, 21)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df0</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">word_count_vec_tf</span><span class="p">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s">'doc1'</span><span class="p">,</span><span class="s">'doc2'</span><span class="p">,</span> <span class="s">'doc3'</span><span class="p">,</span> <span class="s">'doc4'</span><span class="p">,</span> <span class="s">'doc5'</span><span class="p">,</span> <span class="s">'doc6'</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="n">count_vec</span><span class="p">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
<span class="n">df0</span>
</code></pre></div></div>

<div>
  <style scoped="">
      .dataframe tbody tr th:only-of-type {
          vertical-align: middle;
      }

      .dataframe tbody tr th {
          vertical-align: top;
      }

      .dataframe thead th {
          text-align: right;
      }
  </style>
  <table border="1" class="dataframe">
    <thead>
      <tr style="text-align: right;">
        <th></th>
        <th>about</th>
        <th>competitions</th>
        <th>data</th>
        <th>entering</th>
        <th>for</th>
        <th>getting</th>
        <th>kaggle</th>
        <th>loves</th>
        <th>making</th>
        <th>medium</th>
        <th>...</th>
        <th>programming</th>
        <th>publications</th>
        <th>python</th>
        <th>science</th>
        <th>studying</th>
        <th>subscribers</th>
        <th>tracy</th>
        <th>videos</th>
        <th>writing</th>
        <th>youtube</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <th>doc1</th>
        <td>0.495894</td>
        <td>0.000000</td>
        <td>0.495894</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.220127</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>...</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.495894</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.220127</td>
        <td>0.000000</td>
        <td>0.40664</td>
        <td>0.000000</td>
      </tr>
      <tr>
        <th>doc2</th>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.495894</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.220127</td>
        <td>0.000000</td>
        <td>0.495894</td>
        <td>...</td>
        <td>0.000000</td>
        <td>0.495894</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.220127</td>
        <td>0.000000</td>
        <td>0.40664</td>
        <td>0.000000</td>
      </tr>
      <tr>
        <th>doc3</th>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.240948</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>...</td>
        <td>0.542798</td>
        <td>0.000000</td>
        <td>0.542798</td>
        <td>0.000000</td>
        <td>0.542798</td>
        <td>0.000000</td>
        <td>0.240948</td>
        <td>0.000000</td>
        <td>0.00000</td>
        <td>0.000000</td>
      </tr>
      <tr>
        <th>doc4</th>
        <td>0.000000</td>
        <td>0.542798</td>
        <td>0.000000</td>
        <td>0.542798</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.542798</td>
        <td>0.240948</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>...</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.240948</td>
        <td>0.000000</td>
        <td>0.00000</td>
        <td>0.000000</td>
      </tr>
      <tr>
        <th>doc5</th>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.240948</td>
        <td>0.542798</td>
        <td>0.000000</td>
        <td>...</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.240948</td>
        <td>0.542798</td>
        <td>0.00000</td>
        <td>0.542798</td>
      </tr>
      <tr>
        <th>doc6</th>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.542798</td>
        <td>0.000000</td>
        <td>0.240948</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>...</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.000000</td>
        <td>0.542798</td>
        <td>0.240948</td>
        <td>0.000000</td>
        <td>0.00000</td>
        <td>0.000000</td>
      </tr>
    </tbody>
  </table>
  <p>6 rows Ã— 21 columns</p>
</div>

<p>â€˜doc1â€™ì—ì„œ ìˆ«ì 0ì„ ê°€ì§€ëŠ” ì—´ì— í•´ë‹¹ë˜ëŠ” ë‹¨ì–´ë“¤ì€ â€˜doc1â€™ ë¬¸ì¥ì— í¬í•¨ë˜ì§€ ì•Šì€ ë‹¨ì–´ë“¤ì´ë‹¤.<span style="color: blue">The words corresponding to the column with the number 0 in â€˜doc1â€™ are words not included in the sentence â€˜doc1â€™.</span></p>

<p>TF-IDF ìˆ˜ì¹˜ëŠ” í´ìˆ˜ë¡ ë‹¤ë¥¸ ë¬¸ì„œì—ì„œ ì–¸ê¸‰ë˜ì§€ ì•Šìœ¼ë©´ì„œ í•´ë‹¹ ë¬¸ì„œì—ì„œ ì—¬ëŸ¬ ë²ˆ ì‚¬ìš©ë˜ì—ˆë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.<span style="color: blue">&lt;A higher TF-IDF number means that it has been used multiple times in that document without being mentioned in other documents./span&gt;</span></p>

<p>ë”°ë¼ì„œ, â€˜aboutâ€™ì˜ 0.495894ê°€ â€˜lovesâ€™ì˜ 0.220127 ë³´ë‹¤ í° ê²ƒì€ â€˜aboutâ€™ì´ ë‹¤ë¥¸ ë¬¸ì„œì—ì„œëŠ” ëœ ì‚¬ìš©ëìœ¼ë©´ì„œ í•´ë‹¹ ë¬¸ì„œì—ì„œë§Œ ë§ì´ ì‚¬ìš©ë˜ì—ˆê¸° ë•Œë¬¸ìœ¼ë¡œ í•´ì„í•  ìˆ˜ ìˆë‹¤.<span style="color: blue">Therefore, the reason that 0.495894 of â€˜aboutâ€™ is greater than 0.220127 of â€˜lovesâ€™ can be interpreted because â€˜aboutâ€™ is used less in other documents and is used a lot only in that document.</span></p>

<h3 id="cosine-similarity">Cosine Similarity</h3>
<p>TF-IDF ë²¡í„°ë¡œ í‘œí˜„ëœ ê²°ê³¼ë“¤ ë¼ë¦¬ì˜ ì½”ì‚¬ì¸ ì—°ê´€ì„±ì„ ë¹„êµí•œë‹¤.<span style="color: blue">Compare the cosine association between the results expressed as TF-IDF vectors.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cosine_similarity</span><span class="p">(</span><span class="n">df0</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">4</span><span class="p">],</span> <span class="n">df0</span><span class="p">)</span> <span class="c1"># ë¬¸ì„œ 4ì™€ ë‚˜ë¨¸ì§€ ë¬¸ì„œë“¤ê³¼ì˜ ì½”ì‚¬ì¸ ì—°ê´€ì„±ì„ ë¹„êµ consine similarity between docu 4 and others
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0.10607812, 0.10607812, 0.1161115 , 1.        , 0.1161115 ,
        0.1161115 ]])
</code></pre></div></div>

<p>ìƒê¸° ê²°ê³¼ëŠ” ë¬¸ì„œ4ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ 3 ìë¦¬ì— ìœ„ì¹˜í•œ 1ì´ ìê¸° ìì‹ ê³¼ì˜ ìœ ì‚¬ë„ê°€ 1ë¡œ ì™„ë²½í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤.<span style="color: blue">The above result means that the 1 located at the 3rd position of the index corresponding to the document 4 has a perfect similarity of 1 to itself.</span></p>

<p>ë¬¸ì„œ1ê³¼ 4ì˜ ì—°ê´€ì„±ì€ 0.1061ì¸ ê²ƒìœ¼ë¡œ ê´€ì°°ëœë‹¤.<span style="color: blue"></span></p>

<h2 id="3-hashing-vectorizer">3. Hashing Vectorizer</h2>
<p>ë¬¸ì¥ë“¤ì„ tokenì˜ ë¹ˆë„ìˆ˜(= íšŸìˆ˜)ë¡œ í–‰ë ¬ì„ ë§Œë“œëŠ” ë°©ë²•ìœ¼ë¡œ, CountVectorizerì™€ ë™ì¼í•œ ë°©ì‹ì´ë‹¤.<span style="color: blue">This is a method of creating a matrix with the frequency (= number of times) of the tokens, in the same way as CountVectorizer.</span></p>

<p>í•˜ì§€ë§Œ, â€˜CountVectorizerâ€™ê³¼ ë‹¤ë¥´ê²Œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•  ë•Œ â€˜í•´ì‹œâ€™ë¥¼ ì´ìš©í•˜ì—¬ â€˜ì‹¤í–‰ì‹œê°„ì„ ì¤„ì¸ë‹¤â€™.<span style="color: blue">However, unlike â€˜CountVectorizerâ€™, when processing text, â€˜hashâ€™ is used to â€˜reduce execution timeâ€™.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">HashingVectorizer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vectorizer</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># 'n_features': í”¼ì³ ê°œìˆ˜ # features (default = 30,000) 
</span></code></pre></div></div>

<p>í•´ì‰¬ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í† í° ì´ë¦„ë“¤ì„ ë§µí•‘ëœ 32ê°œì˜ í”¼ì²˜ë¥¼ ì œì–´í•œë‹¤. <span style="color: blue">take control of token names that have been mapped into 32 features using hash function</span></p>
<ul>
  <li>í•´ì‰¬ í•¨ìˆ˜ë¥¼ í†µí•˜ì—¬ 32ê°œì˜ í”¼ì²˜ ì¤‘ ì•Œë§ì€ í”¼ì²˜ì˜ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜¨ë‹¤.<span style="color: blue"> hash function helps find the index of appropriate feature</span></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">X</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(6, 32)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s">'doc1'</span><span class="p">,</span><span class="s">'doc2'</span><span class="p">,</span> <span class="s">'doc3'</span><span class="p">,</span> <span class="s">'doc4'</span><span class="p">,</span> <span class="s">'doc5'</span><span class="p">,</span> <span class="s">'doc6'</span><span class="p">])</span>
<span class="n">matrix</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>22</th>
      <th>23</th>
      <th>24</th>
      <th>25</th>
      <th>26</th>
      <th>27</th>
      <th>28</th>
      <th>29</th>
      <th>30</th>
      <th>31</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>doc1</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.500000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.500000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.500000</td>
    </tr>
    <tr>
      <th>doc2</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.408248</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.408248</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.408248</td>
    </tr>
    <tr>
      <th>doc3</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.447214</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.447214</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>doc4</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.447214</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.447214</td>
      <td>0.447214</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>doc5</th>
      <td>0.0</td>
      <td>-0.447214</td>
      <td>0.0</td>
      <td>0.447214</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.447214</td>
      <td>0.000000</td>
      <td>0.447214</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>doc6</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.377964</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.755929</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.377964</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-0.377964</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>6 rows Ã— 32 columns</p>
</div>

<h2 id="4-featurehasher">4. FeatureHasher</h2>
<p>Feature Hashingì´ë¼ëŠ” ë°©ë²•ì„ ì´ìš©í•˜ì—¬ â€˜ì•½ê°„ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ê³ â€™ ë¹ ë¥´ê²Œ ë²¡í„°í™” í•˜ëŠ” ë°©ë²•ì´ë‹¤.<span style="color: blue">This is a fast vectorization method using a method called Feature Hashing â€˜using a little memoryâ€™.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="kn">import</span> <span class="n">FeatureHasher</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hasher</span> <span class="o">=</span> <span class="n">FeatureHasher</span><span class="p">(</span><span class="n">n_features</span> <span class="o">=</span> <span class="mi">21</span><span class="p">,</span> <span class="n">alternate_sign</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">input_type</span><span class="o">=</span><span class="s">"string"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vectors</span> <span class="o">=</span> <span class="n">hasher</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">vectors</span><span class="p">.</span><span class="n">toarray</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[0., 0., 4., 0., 3., 0., 0., 1., 0., 0., 1., 5., 3., 1., 6., 4.,
        6., 1., 3., 0., 1.],
       [0., 2., 3., 0., 4., 0., 0., 1., 0., 0., 1., 4., 3., 1., 6., 4.,
        7., 1., 5., 0., 2.],
       [0., 2., 5., 0., 4., 0., 0., 1., 1., 0., 3., 3., 3., 0., 5., 5.,
        5., 0., 2., 0., 1.],
       [0., 1., 5., 0., 4., 0., 0., 1., 0., 0., 1., 4., 4., 0., 5., 5.,
        7., 0., 3., 0., 1.],
       [0., 1., 2., 0., 4., 0., 0., 2., 0., 0., 1., 3., 0., 0., 5., 4.,
        6., 1., 2., 0., 3.],
       [0., 0., 4., 0., 1., 0., 0., 1., 0., 0., 1., 2., 2., 1., 5., 6.,
        8., 2., 2., 0., 1.]])
</code></pre></div></div>

<h2 id="5-dict-vectorizer">5. Dict Vectorizer</h2>
<p>CountVectorizerê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë™ì‘í•˜ì§€ë§Œ, <strong>ë”•ì…”ë„ˆë¦¬</strong> ë°ì´í„°ë¥¼ ì¸í’‹ìœ¼ë¡œ ë°›ëŠ”ë‹¤ëŠ” ì ì—ì„œ ì°¨ì´ê°€ ìˆë‹¤. <span style="color: blue">Dic Vectorizer shares the same way to operate but receives dictionary input data.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction</span> <span class="kn">import</span> <span class="n">DictVectorizer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># sample dict data
</span><span class="nb">dict</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Tracy'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Little Rock'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span><span class="s">'female'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">60</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Mike'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Reading'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span><span class="s">'male'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">54</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Martina'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Berlin'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span><span class="s">'female'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span><span class="mi">62</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Gerry'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span><span class="s">'Heerlen'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span><span class="s">'female'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">80</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Paz'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Manila'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span><span class="s">'female'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">61</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Doug'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Aberdeen'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span><span class="s">'male'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">55</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Jeff'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Cardiff'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span><span class="s">'male'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">57</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Cindy'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span><span class="s">'Little Rock'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span> <span class="s">'female'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span><span class="mi">60</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Keith'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Reading'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span> <span class="s">'male'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span><span class="mi">57</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Adrian'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Tercera'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span> <span class="s">'male'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">38</span><span class="p">},</span>
    <span class="p">{</span><span class="s">'name'</span><span class="p">:</span> <span class="s">'Katherine'</span><span class="p">,</span> <span class="s">'from'</span><span class="p">:</span> <span class="s">'Fayeteville'</span><span class="p">,</span> <span class="s">'sex'</span><span class="p">:</span> <span class="s">'female'</span><span class="p">,</span> <span class="s">'age'</span><span class="p">:</span> <span class="mi">38</span><span class="p">}</span>
<span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vec</span> <span class="o">=</span> <span class="n">DictVectorizer</span><span class="p">()</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="n">vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
<span class="n">vectors</span><span class="p">.</span><span class="n">toarray</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([[60.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.],
      [54.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.],
      [62.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.],
      [80.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],
      [61.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.],
      [55.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],
      [57.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],
      [60.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],
      [57.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,
        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.],
      [38.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,
        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],
      [38.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,
        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vec</span><span class="p">.</span><span class="n">get_feature_names_out</span><span class="p">(),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vec</span><span class="p">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(array(['age', 'from=Aberdeen', 'from=Berlin', 'from=Cardiff',
        'from=Fayeteville', 'from=Heerlen', 'from=Little Rock',
        'from=Manila', 'from=Reading', 'from=Tercera', 'name=Adrian',
        'name=Cindy', 'name=Doug', 'name=Gerry', 'name=Jeff',
        'name=Katherine', 'name=Keith', 'name=Martina', 'name=Mike',
        'name=Paz', 'name=Tracy', 'sex=female', 'sex=male'], dtype=object),
23)
</code></pre></div></div>

<p>ìƒê¸° ê³¼ì •ì—ì„œ Dict Vectorizerë¥¼ í†µí•˜ì—¬ ë”•ì…”ë„ˆë¦¬ ë°ì´í„°ë¥¼ ìˆ˜ì¹˜ì— ê¸°ë°˜í•˜ì—¬ ë²¡í„°í™”í–ˆë‹¤. <span style="color: blue">The result shows how vectorization has been done using Dict Vectorizer.</span></p>

<p>ì´í›„, TF-IDFë¥¼ ì‚¬ìš©í•˜ì—¬ íšŸìˆ˜ ê¸°ë°˜ ë²¡í„°í™”ëœ í–‰ë ¬ì„ ë³€í™˜í•˜ì—¬ ë³´ë‹¤ ìœ ì˜ë¯¸í•œ ë‹¨ì–´ë¥¼ ë„ì¶œí•´ë³´ì.<span style="color: blue"> Now, letâ€™s use TF-IDF to find informative words from the output. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf_transformer</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">().</span><span class="n">fit</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
<span class="n">word_count_vec_tf</span> <span class="o">=</span> <span class="n">tf_transformer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
<span class="n">word_count_vec_tf</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<p>(11, 23)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df0</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">word_count_vec_tf</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>
<span class="n">df0</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>...</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>19</th>
      <th>20</th>
      <th>21</th>
      <th>22</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.997805</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.039684</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.046427</td>
      <td>0.025594</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.997207</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.044067</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.051555</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.031267</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.997673</td>
      <td>0.000000</td>
      <td>0.044924</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.044924</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.024765</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.998600</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.034848</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.034848</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.019211</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.997596</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.045657</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.045657</td>
      <td>0.000000</td>
      <td>0.025169</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.996964</td>
      <td>0.050605</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.030691</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.997172</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.04884</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.04884</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.029620</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.997805</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.039684</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.025594</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.997493</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.041760</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.048855</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.029630</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.993671</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.073002</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.044274</td>
    </tr>
    <tr>
      <th>10</th>
      <td>0.993840</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.073015</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.00000</td>
      <td>0.073015</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.040250</td>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>11 rows Ã— 23 columns</p>
</div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> íƒœê·¸: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#nlp" class="page__taxonomy-item p-category" rel="tag">NLP</a><span class="sep">, </span>
    
      <a href="/tags/#word-embedding" class="page__taxonomy-item p-category" rel="tag">Word Embedding</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> ì¹´í…Œê³ ë¦¬: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#nlp" class="page__taxonomy-item p-category" rel="tag">NLP</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> ì—…ë°ì´íŠ¸:</strong> <time class="dt-published" datetime="2022-07-20T00:00:00+09:00">2022-07-20</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">ê³µìœ í•˜ê¸°</h4>
  

  <a href="https://twitter.com/intent/tweet?text=NLP+-+Part+2%3A+Word+Embedding%20http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fnlp-basic-word-embedding%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="ê³µìœ í•˜ê¸° Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fnlp-basic-word-embedding%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="ê³µìœ í•˜ê¸° Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fnlp-basic-word-embedding%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="ê³µìœ í•˜ê¸° LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/nlp/nlp-basic-tokenizer/" class="pagination--pager" title="NLP - Part 1: Text Mining and Tokenization
">ì´ì „</a>
    
    
      <a href="/nlp/nlp-voice-recognition/" class="pagination--pager" title="NLP - Part 3: Voice Recognition
">ë‹¤ìŒ</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">ì°¸ê³ </h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/nlp-thumbnail.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/nlp-NER/" rel="permalink">NLP - Part 7: Name Entity Recognition (NER) ì•±
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          ìµœëŒ€ 1 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">ì‚¬ì „ ì„¤ì •
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/teeko.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/others/ml-teeko-minimax/" rel="permalink">Minimax ì•Œê³ ë¦¬ì¦˜ - Teeko Game
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          12 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Minimax ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•´ì„œ Teeko ê²Œì„ì„ êµ¬í˜„í•œë‹¤.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/q-learning.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/rl/ml-reinforcement-learning-q-learning/" rel="permalink">Reinforcement Learning - Q-Learning ì•Œê³ ë¦¬ì¦˜
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          ìµœëŒ€ 1 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Q-Learning ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ì˜ˆì œì´ë‹¤.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/pca-image-compression.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/usl/ml-pca/" rel="permalink">PCA - Image Compression(ì´ë¯¸ì§€ ì••ì¶•)
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">PCAë¥¼ ì´ìš©í•´ì„œ ì´ë¯¸ì§€ ì••ì¶•ì„ ì§„í–‰í•´ë³´ì.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/hac.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/usl/ml-hca/" rel="permalink">Hierarchical Agglomerate Clustering(HAC) - í¬ì¼“ëª¬ êµ°ì§‘í™”
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Hierarchical Agglomerate Clustering(HAC) ì´ìš©í•´ì„œ ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê³µìœ í•˜ëŠ” Pokemonë“¤ì„ êµ°ì§‘ìœ¼ë¡œ ë¬¶ì–´ë³´ì.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/8-tile-puzzle.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/others/ml-8-tile-puzzle-a-search/" rel="permalink">A* Search - 8-tile Puzzle Game
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          ìµœëŒ€ 1 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">A-star ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•´ì„œ 8-tile Puzzle ê²Œì„ì„ êµ¬í˜„í•œë‹¤.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/lenet.JPG" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/sl/dl-miniplace-classification/" rel="permalink">LeNet ì‹ ê²½ë§ - MiniPlaces ì´ë¯¸ì§€ ë¶„ë¥˜
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">LeNet ì‹ ê²½ë§ì„ í™œìš©í•´ì„œ MiniPlaces ë°ì´í„°ì…‹ ì´ë¯¸ì§€ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/streamlit-thumbnail.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/python-web-server-exercise/" rel="permalink">Python: PART 2 - Web Application without Server
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

ê°•ì•„ì§€ í’ˆì¢… ë¶„ë¥˜ AI ì›¹í˜ì´ì§€
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/ai-thumbnail.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/aipapernlp/ai-paper-ko-legal-nlp/" rel="permalink">[ë…¼ë¬¸ ë¶„ì„] A Multi-Task Benchmark for Korean Legal Language Understanding and Judgement Prediction (arXiv 2022)
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/bert-thumbnail.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/bert/bert-3/" rel="permalink">Part 3: BERT Language Model
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 ë¶„ ì†Œìš”
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">BERT
Bi-directional transformerë¡œ ì´ë£¨ì–´ì§„ ì–¸ì–´ëª¨ë¸ë¡œ, BERT ì–¸ì–´ëª¨ë¸ ìœ„ì— 1ê°œì˜ classification layerë§Œ ë¶€ì°©í•˜ì—¬ ë‹¤ì–‘í•œ NLP taskë¥¼ ìˆ˜í–‰í•œë‹¤.
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>íŒ”ë¡œìš°:</strong></li>
    

    
      
        
          <li><a href="mailto:hchoi256@wisc.edu" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
        
      
        
          <li><a href="https://github.com/hchoi256" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="/assets/í¬íŠ¸í´ë¦¬ì˜¤.pdf" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-link" aria-hidden="true"></i> Portfolio</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> í”¼ë“œ</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 ì­ŒìŠ¤ğŸ„. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>
    
  <script src="/assets/js/main.min.js"></script>







    

  





  </body>
</html>
