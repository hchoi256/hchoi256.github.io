<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-07-22T20:38:23+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">정리하여 내 것으로, AI</title><subtitle>Leveraging the state-of-the-art technology in AI</subtitle><author><name>Hojun Eric Choi</name><email>hchoi256@wisc.edu</email></author><entry><title type="html">ML Project 1: ANN - Car Sales Prediction</title><link href="http://localhost:4000/machine/learning/ml-projects/" rel="alternate" type="text/html" title="ML Project 1: ANN - Car Sales Prediction" /><published>2022-07-22T00:00:00+09:00</published><updated>2022-07-22T00:00:00+09:00</updated><id>http://localhost:4000/machine/learning/ml-projects</id><content type="html" xml:base="http://localhost:4000/machine/learning/ml-projects/"><![CDATA[<h1 id="car-sales-prediction">Car Sales Prediction</h1>

<h2 id="learning-goals">Learning Goals</h2>
<p>Artificial Neural Network (ANN)을 이용한 회귀 작업 처리를 이해한다.</p>

<p>순방향/역전파를 동반하는 가중치 학습의 과정에 대해 보다 나은 이해를 도모한다.</p>

<h2 id="description">Description</h2>
<p>여러분이 자동차 딜러 혹은 차량 판매원이라 가정하고, 상기 고객들의 특정 데이터(나이, 연봉, etc.)를 참고하여 고객들이 차량 구매에 사용할 금액을 예측하여 특정 집단에 대한 타깃 마케팅을 이루고자 한다.</p>

<h3 id="dataset">Dataset</h3>
<table border="0" cellpadding="0" cellspacing="0" id="sheet0" class="sheet0 gridlines">
    <col class="col0" />
    <col class="col1" />
    <col class="col2" />
    <col class="col3" />
    <col class="col4" />
    <col class="col5" />
    <col class="col6" />
    <col class="col7" />
    <col class="col8" />
    <tbody>
        <tr class="row0">
        <td class="column0 style0 s">Customer Name</td>
        <td class="column1 style0 s">Customer e-mail</td>
        <td class="column2 style0 s">Country</td>
        <td class="column3 style0 s">Gender</td>
        <td class="column4 style0 s">Age</td>
        <td class="column5 style0 s">Annual Salary</td>
        <td class="column6 style0 s">Credit Card Debt</td>
        <td class="column7 style0 s">Net Worth</td>
        <td class="column8 style0 s">Car Purchase Amount</td>
        </tr>
        <tr class="row1">
        <td class="column0 style0 s">Martina Avila</td>
        <td class="column1 style0 s">cubilia.Curae.Phasellus@quisaccumsanconvallis.edu</td>
        <td class="column2 style0 s">Bulgaria</td>
        <td class="column3 style0 n">0</td>
        <td class="column4 style0 n">41.8517198</td>
        <td class="column5 style0 n">62812.09301</td>
        <td class="column6 style0 n">11609.38091</td>
        <td class="column7 style0 n">238961.2505</td>
        <td class="column8 style0 n">35321.45877</td>
        </tr>
        <tr class="row2">
        <td class="column0 style0 s">Harlan Barnes</td>
        <td class="column1 style0 s">eu.dolor@diam.co.uk</td>
        <td class="column2 style0 s">Belize</td>
        <td class="column3 style0 n">0</td>
        <td class="column4 style0 n">40.87062335</td>
        <td class="column5 style0 n">66646.89292</td>
        <td class="column6 style0 n">9572.957136</td>
        <td class="column7 style0 n">530973.9078</td>
        <td class="column8 style0 n">45115.52566</td>
        </tr>
        <tr class="row3">
        <td class="column0 style0 s">Naomi Rodriquez</td>
        <td class="column1 style0 s">vulputate.mauris.sagittis@ametconsectetueradipiscing.co.uk</td>
        <td class="column2 style0 s">Algeria</td>
        <td class="column3 style0 n">1</td>
        <td class="column4 style0 n">43.15289747</td>
        <td class="column5 style0 n">53798.55112</td>
        <td class="column6 style0 n">11160.35506</td>
        <td class="column7 style0 n">638467.1773</td>
        <td class="column8 style0 n">42925.70921</td>
        </tr>
        <tr class="row4">
        <td class="column0 style0 s">Jade Cunningham</td>
        <td class="column1 style0 s">malesuada@dignissim.com</td>
        <td class="column2 style0 s">Cook Islands</td>
        <td class="column3 style0 n">1</td>
        <td class="column4 style0 n">58.27136945</td>
        <td class="column5 style0 n">79370.03798</td>
        <td class="column6 style0 n">14426.16485</td>
        <td class="column7 style0 n">548599.0524</td>
        <td class="column8 style0 n">67422.36313</td>
        </tr>
        <tr class="row5">
        <td class="column0 style0 s">Cedric Leach</td>
        <td class="column1 style0 s">felis.ullamcorper.viverra@egetmollislectus.net</td>
        <td class="column2 style0 s">Brazil</td>
        <td class="column3 style0 n">1</td>
        <td class="column4 style0 n">57.31374945</td>
        <td class="column5 style0 n">59729.1513</td>
        <td class="column6 style0 n">5358.712177</td>
        <td class="column7 style0 n">560304.0671</td>
        <td class="column8 style0 n">55915.46248</td>
        </tr>
    </tbody>
</table>

<p><strong>독립변수</strong></p>
<ul>
  <li>Customer Name</li>
  <li>Customer e-mail</li>
  <li>Country</li>
  <li>Gender</li>
  <li>Age</li>
  <li>Annual Salary</li>
  <li>Credit Card Debt.</li>
  <li>Net Worth</li>
</ul>

<p><strong>종속변수</strong></p>
<ul>
  <li>Car Purchase Amount</li>
</ul>

<h2 id="import-dataset">Import Dataset</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1"># 데이터 프레임 조작
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># 수치 해석
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> <span class="c1"># 그래프 시각화
</span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span> <span class="c1"># 그래프 시각화
</span>
<span class="n">car_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'Car_Purchasing_Data.csv'</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'ISO-8859-1'</span><span class="p">)</span> <span class="c1"># 데이터셋이 '@'와 같은 특수문자를 포함하기 때문에 상기 인코딩 설정을 해줘야한다.
</span></code></pre></div></div>

<h2 id="data-visualization">Data Visualization</h2>

<h3 id="seaborn">Seaborn</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">car_df</span><span class="p">)</span> <span class="c1"># 씨본 덕분에 분석 작업을 여러 번 할 필요없이 여러 종류의 시각화를 보여준다
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180380848-d3772ba0-a21b-416b-8139-534c7a3aa721.JPG" alt="screensht" /></p>

<p>데이터 분포에서 맨 아래 위치한 행은 ‘Car Purchase Amount’이고, 각 열은 순서대로 Gender, Age, Annual Salary, Credit Car Debt, Net Worth, Car Purchase Amount이다.</p>

<p>따라서, 나이가 증가함에 따라 차량 구매 예상 금액이 증가하는 선형적 형태의 데이터 분포를 보여주고, 반대로 Credit Card Debt은 종속변수와 뚜렷한 상관관계를 나타내지 않는 것으로 관찰된다.</p>

<h2 id="data-preprocessing">Data Preprocessing</h2>
<h2 id="remove-unnecessary-variables">Remove Unnecessary Variables</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">car_df</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Customer Name'</span><span class="p">,</span> <span class="s">'Customer e-mail'</span><span class="p">,</span> <span class="s">'Country'</span><span class="p">,</span> <span class="s">'Car Purchase Amount'</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># 종속변수에 영향을 끼치지 않는 불필요한 입력피처를 제거한다.
</span><span class="n">y</span> <span class="o">=</span> <span class="n">car_df</span><span class="p">[</span><span class="s">'Car Purchase Amount'</span><span class="p">]</span> <span class="c1"># 종속변수
</span>
<span class="n">X</span> <span class="c1"># 정제된 훈련 데이터 관찰
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180381916-2051d577-51ec-4ff8-be80-0685754f456b.png" alt="image" /></p>

<h3 id="data-scaling">Data Scaling</h3>
<p>나이와 연봉과 같은 입력피처의 수치가 차이가 커서, 특정 피처에 과중화된 결과가 나올 수 있으므로 [0, 1] 값으로 정규화하는 스케일링(Scailing)을 적용해야 한다.</p>

<p>이번 프로젝트에서, 우리는 <strong>MinMaxScaler</strong>를 사용한다.</p>

<p>기존 StandardScaler와 MinMaxScaler의 차이점은 데이터가 <strong>정규분포를 따르는지 혹은 따라야 하는지</strong>에 달려있다.</p>

<p><a href="https://velog.io/@ljs7463/%ED%94%BC%EC%B2%98-%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81StandardScalerMinMaxScaler">참고</a></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

</code></pre></div></div>

<h2 id="model-training">Model Training</h2>

<p><strong>Dense</strong></p>
<ul>
  <li><em>첫번째 인자</em> : 출력 뉴런의 수를 설정합니다.</li>
  <li><em>input_dim</em> : 입력 뉴런의 수를 설정합니다.</li>
  <li><em>init</em> : 가중치 초기화 방법 설정합니다.
    <ul>
      <li>‘uniform’ : 균일 분포</li>
      <li>‘normal’ : 가우시안 분포</li>
    </ul>
  </li>
  <li><em>activation</em> : 활성화 함수 설정합니다.
    <ul>
      <li>‘linear’ : 디폴트 값, 입력뉴런과 가중치로 계산된 결과값이 그대로 출력으로 나옵니다.</li>
      <li>‘relu’ : rectifier 함수, 은익층에 주로 쓰입니다.</li>
      <li>‘sigmoid’ : 시그모이드 함수, 이진 분류 문제에서 출력층에 주로 쓰입니다.</li>
      <li>‘softmax’ : 소프트맥스 함수, 다중 클래스 분류 문제에서 출력층에 주로 쓰입니다.</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_scaled</span><span class="p">,</span> <span class="n">y_scaled</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.25</span><span class="p">)</span> <span class="c1"># Create training and test set
</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span> <span class="c1"># 신경망을 순차적 형태로 설계
</span><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span> <span class="c1"># 뉴런의 입출력을 연결해주는 완전 연결 신경망 생성
</span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span> <span class="c1"># 순차적 망이기 때문에 'input)dim'은 다시 쓰지 않아도 된다.
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span> <span class="c1"># output 값
</span><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180387209-a42f1385-dacc-45a3-a844-0ea2c3384262.png" alt="image" /></p>

<p><strong>입력값 개수</strong>: 5 (나이, etc.)</p>

<p><strong>뉴런 개수</strong>: 25</p>

<p><strong>bias</strong>: 은닉층 뉴런 개수에 맞게 할당된다 (i.e., 은닉층 뉴런 개수 25개 –&gt; bias 역시 25개가 존재한다).</p>

<p><strong>훈련 가능한 파라미터</strong>: 딥러닝 모델 학습의 역전파 과정에서 피라미터 업데이트의 대상이 되는 가중치와 bias를 말한다.</p>

<ol>
  <li>
    <p>초기 입력값에서 첫 번째 은닉층까지, <em>*훈련 가능한 피라미터</em> 개수 = 5(입력값 개수) * 25(첫 은닉층 뉴런개수) + 25(bias) = 150</p>
  </li>
  <li>
    <p>초기 입력값에서 두 번째 은닉층까지, <em>*훈련 가능한 피라미터</em> 개수 =  25(첫 은닉층 뉴런개수) * 25(두 번째 은닉층 뉴런개수) + 25(bias) = 650</p>
  </li>
  <li>
    <p>출력, <em>*훈련 가능한 피라미터</em> 개수 = 25(두 번째 은닉층 뉴런개수) * 1(출력값은 하나) + 1(bias) = 150</p>
  </li>
</ol>

<blockquote>
  <p>Toal params: 826</p>
  <blockquote>
    <p>입출력 값에 대한 최선의 상관관계 도출을 위해 훈련되거나 조정되는 피라미터 총 개수이다.</p>
  </blockquote>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">)</span> <span class="c1"># 모델 학습 방법 제시
</span>
</code></pre></div></div>
<p><img src="https://user-images.githubusercontent.com/39285147/180389686-0fd6c3e2-8ee8-4e0f-999c-7686f8f89d41.png" alt="image" /></p>

<blockquote>
  <p>Optimizer</p>
  <blockquote>
    <p>모델이 학습과정에서 어떻게 가중치 최적화를 이뤄내는지에 대한 방법을 제시한다.</p>

    <p><a href="https://github.com/hchoi256/lg-ai-auto-driving-radar-sensor/blob/main/supervised-learning/gradient-discent.md">adam이란?</a></p>
  </blockquote>
</blockquote>

<blockquote>
  <p>loss (손실함수)</p>
  <blockquote>
    <p>모델의 정확도를 판단하는데 사용되는 방법론이다.</p>

    <p>mean_squared_error (평균제곱오차)</p>
    <blockquote>
      <blockquote>

        <p>예측값과 실제값의 차이를 나타내는 정도로, 그 값이 작을수록 실제값과 유사하여 정확한 예측을 해냈다고 볼 수 있다.</p>
      </blockquote>
    </blockquote>
  </blockquote>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">epochs_hist</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>  <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180390662-b659a0d9-6f49-46cd-bb01-acd9cf2bd4b5.png" alt="image" /></p>

<p>모델이 학습하면서 epoch를 거듭함에 따라 loss(여기서는 평균제곱오차 방법을 사용)의 값이 줄어드는 것을 볼 수 있다.</p>

<ul>
  <li>epoch: 배치 사이즈만큼의 하나의 학습을 몇번 시행할지 결정한다. 그 크기가 모델 성능을 향상시키는 최대 임계치에 가까워 질수록 더 정확한 예측을 해낼 수 있다.</li>
  <li>batch_size: 한 번에 학습할 훈련 데이터 개수</li>
  <li>verbose: 디폴트 0. 1로 지정하면 Epoch의 상황과, loss의 값이 output에 보여준다.</li>
  <li><a href="https://github.com/hchoi256/ai-terms/blob/main/README.md">validation_split</a></li>
</ul>]]></content><author><name>Hojun Eric Choi</name><email>hchoi256@wisc.edu</email></author><category term="Machine" /><category term="Learning" /><category term="machine learning" /><category term="python" /><summary type="html"><![CDATA[Car Sales Prediction]]></summary></entry><entry><title type="html">NLP - Part 2: Word Embedding</title><link href="http://localhost:4000/nlp/nlp-basic-word-embedding/" rel="alternate" type="text/html" title="NLP - Part 2: Word Embedding" /><published>2022-07-20T00:00:00+09:00</published><updated>2022-07-20T00:00:00+09:00</updated><id>http://localhost:4000/nlp/nlp-basic-word-embedding</id><content type="html" xml:base="http://localhost:4000/nlp/nlp-basic-word-embedding/"><![CDATA[<h1 id="part-1-vectorization">PART 1: Vectorization</h1>

<h2 id="vectorization-필요성">Vectorization 필요성</h2>
<p>Machine (기계)는 문자와 단어를 이해할 수 없다.</p>

<p>0과 1로 이루어진 이진 형태의 데이터를 기계는 이해할 수 있다.</p>

<p><strong>Computer Vision</strong>의 가장 기본은 이미지는 픽셀 (pixel)로 이루어져 있고, 픽셀에 대한 정보는 x, y와 같은 픽셀의 위치 그리고 해당 픽셀의 색상 정보 (보통 RGB)를 가지고 있다. 이런 정보들은 숫자로 쉽게 만들 수가 있다!</p>

<p><strong>NLP</strong>의 텍스트 데이터 역시 기계가 이해할 수 있도록 숫자로 표현해야 한다.</p>

<p><em>CountVectorizer</em> 텍스트를 숫자 데이터로 변환하는 방법으로, 텍스트를 수치 데이터로 변화하는데 사용하는 method! sklearn을 통해 사용 가능하다.</p>

<h2 id="vectorization-구현">Vectorization 구현</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">text1</span> <span class="o">=</span><span class="s">'''Tracy loves writing about data science.'''</span>
<span class="n">text2</span> <span class="o">=</span> <span class="s">'''Tracy loves writing for medium publications.'''</span>
<span class="n">text3</span> <span class="o">=</span> <span class="s">'''Tracy loves studying Python programming.'''</span>
<span class="n">text4</span> <span class="o">=</span> <span class="s">'''Tracy loves entering Kaggle competitions.'''</span>
<span class="n">text5</span> <span class="o">=</span> <span class="s">'''Tracy loves making YouTube videos.'''</span>
<span class="n">text6</span> <span class="o">=</span> <span class="s">'''Tracy loves getting new subscribers.'''</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">text1</span><span class="p">,</span> <span class="n">text2</span><span class="p">,</span> <span class="n">text3</span><span class="p">,</span> <span class="n">text4</span><span class="p">,</span> <span class="n">text5</span><span class="p">,</span> <span class="n">text6</span><span class="p">]</span>
<span class="n">count_vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>

<span class="n">word_count_vec</span> <span class="o">=</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">word_count_vec</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(6, 21)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">count_vec</span><span class="p">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['about' 'competitions' 'data' 'entering' 'for' 'getting' 'kaggle' 'loves'
 'making' 'medium' 'new' 'programming' 'publications' 'python' 'science'
 'studying' 'subscribers' 'tracy' 'videos' 'writing' 'youtube']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Vocabulary: "</span><span class="p">,</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">vocabulary_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Vocabulary:  {'tracy': 17, 'loves': 7, 'writing': 19, 'about': 0, 'data': 2, 'science': 14, 'for': 4, 'medium': 9, 'publications': 12, 'studying': 15, 'python': 13, 'programming': 11, 'entering': 3, 'kaggle': 6, 'competitions': 1, 'making': 8, 'youtube': 20, 'videos': 18, 'getting': 5, 'new': 10, 'subscribers': 16}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Encoded Document is: "</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">word_count_vec</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Encoded Document is: 
[[1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0]
 [0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0]
 [0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0]
 [0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0]
 [0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1]
 [0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">matrix</span> <span class="o">=</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="n">set_option</span><span class="p">(</span><span class="s">"display.max_columns"</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span> <span class="c1"># 테이블 전체를 한 눈에 보여주기
</span><span class="n">counts</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">matrix</span><span class="p">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="s">"doc1"</span><span class="p">,</span> <span class="s">"doc2"</span><span class="p">,</span> <span class="s">"doc3"</span><span class="p">,</span> <span class="s">"doc4"</span><span class="p">,</span> <span class="s">"doc5"</span><span class="p">,</span> <span class="s">"doc6"</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">count_vec</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="n">counts</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="s">"Total"</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">counts</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">counts</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>about</th>
      <th>competitions</th>
      <th>data</th>
      <th>entering</th>
      <th>for</th>
      <th>getting</th>
      <th>kaggle</th>
      <th>loves</th>
      <th>making</th>
      <th>medium</th>
      <th>new</th>
      <th>programming</th>
      <th>publications</th>
      <th>python</th>
      <th>science</th>
      <th>studying</th>
      <th>subscribers</th>
      <th>tracy</th>
      <th>videos</th>
      <th>writing</th>
      <th>youtube</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>doc1</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc4</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>doc5</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>doc6</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>Total</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="vectorization-실습">Vectorization 실습</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">"Electronics_data.xlsx"</span><span class="p">)</span>
<span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>sentiment</th>
      <th>title</th>
      <th>Reviews</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>2</td>
      <td>Great CD</td>
      <td>My lovely Pat has one of the GREAT voices of h...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>One of the best game music soundtracks - for a...</td>
      <td>Despite the fact that I have only played a sma...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>Batteries died within a year ...</td>
      <td>I bought this charger in Jul 2003 and it worke...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>works fine, but Maha Energy is better</td>
      <td>Check out Maha Energy's website. Their Powerex...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>2</td>
      <td>Great for the non-audiophile</td>
      <td>Reviewed quite a bit of the combo players and ...</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(50000, 4)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span><span class="p">[</span><span class="s">"Full_text"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">"title"</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"Reviews"</span><span class="p">],</span> <span class="n">sep</span> <span class="o">=</span> <span class="s">" "</span><span class="p">)</span> <span class="c1"># title과 Reviews 합치기
</span><span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>sentiment</th>
      <th>title</th>
      <th>Reviews</th>
      <th>Full_text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>2</td>
      <td>Great CD</td>
      <td>My lovely Pat has one of the GREAT voices of h...</td>
      <td>Great CD My lovely Pat has one of the GREAT vo...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2</td>
      <td>One of the best game music soundtracks - for a...</td>
      <td>Despite the fact that I have only played a sma...</td>
      <td>One of the best game music soundtracks - for a...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>Batteries died within a year ...</td>
      <td>I bought this charger in Jul 2003 and it worke...</td>
      <td>Batteries died within a year ... I bought this...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>2</td>
      <td>works fine, but Maha Energy is better</td>
      <td>Check out Maha Energy's website. Their Powerex...</td>
      <td>works fine, but Maha Energy is better Check ou...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>2</td>
      <td>Great for the non-audiophile</td>
      <td>Reviewed quite a bit of the combo players and ...</td>
      <td>Great for the non-audiophile Reviewed quite a ...</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">corpus</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'Full_text'</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span> <span class="c1"># Fulltext 리스트 형태로 corpus에 저장
</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>500
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="n">stop_words</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">corpus</span><span class="p">.</span><span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">)</span>
<span class="n">ps</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">porter</span><span class="p">.</span><span class="n">PorterStemmer</span><span class="p">()</span> <span class="c1"># 어간 추출 (i.e., dies/dead/died --&gt; die)
</span>
<span class="k">def</span> <span class="nf">normalize_document</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
    <span class="c1"># 토큰화 하기전 문자열 normalization
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s">'[^a-zA-Z\s]'</span><span class="p">,</span> <span class="s">""</span><span class="p">,</span> <span class="n">doc</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">I</span><span class="o">|</span><span class="n">re</span><span class="p">.</span><span class="n">A</span><span class="p">)</span> <span class="c1"># 구두점 및 특수문자 제거
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span>   <span class="c1"># 소문자화
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>   <span class="c1"># 문자열의 앞 뒤에 있을 빈 칸 제거
</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="p">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="c1"># 토큰화
</span>
    <span class="n">filtered_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span> <span class="c1"># 불용어 제거
</span>
    <span class="c1"># doc = " ".join(filtered_tokens)
</span>    <span class="n">doc</span> <span class="o">=</span> <span class="s">" "</span><span class="p">.</span><span class="n">join</span><span class="p">([</span> <span class="n">ps</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">filtered_tokens</span> <span class="p">])</span>

    <span class="k">return</span> <span class="n">doc</span>  
</code></pre></div></div>

<blockquote>
  <table>
    <tbody>
      <tr>
        <td>re.I</td>
        <td>re.A: re.sub의 flags (<a href="https://docs.python.org/ko/3/library/re.html">click</a>)</td>
      </tr>
    </tbody>
  </table>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">normalize_corpus</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">normalize_document</span><span class="p">)</span> <span class="c1"># Vectorization 정규화 함수 트리거 저장
</span><span class="n">norm_corpus</span> <span class="o">=</span> <span class="n">normalize_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="c1"># 트리거에 정규화할 corpus 할당
</span><span class="n">norm_corpus</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['great cd love pat one great voic gener listen cd year still love im good mood make feel better bad mood evapor like sugar rain cd ooz life vocal jusat stuun lyric kill one life hidden gem desert isl cd book never made big beyond everytim play matter black white young old male femal everybodi say one thing sing',
       'one best game music soundtrack game didnt realli play despit fact play small portion game music heard plu connect chrono trigger great well led purchas soundtrack remain one favorit album incred mix fun epic emot song sad beauti track especi like there mani kind song video game soundtrack must admit one song lifea distant promis brought tear eye mani occasionsmi one complaint soundtrack use guitar fret effect mani song find distract even werent includ would still consid collect worth',
       'batteri die within year bought charger jul work ok design nice conveni howev year batteri would hold charg might well get alkalin dispos look elsewher charger come batteri better stay power',
      ...])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">norm_corpus</span><span class="p">)</span> <span class="c1"># Vectorization 진행
</span><span class="n">cv_matrix</span> <span class="o">=</span> <span class="n">cv_matrix</span><span class="p">.</span><span class="n">toarray</span><span class="p">()</span> <span class="c1"># pd.DataFrame 인자로 넣기위해 배열화
</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vocabulary</span> <span class="o">=</span> <span class="n">cv</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">vocabulary</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4754
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">one_hot</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_matrix</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span> <span class="n">vocabulary</span><span class="p">)</span>
<span class="n">one_hot</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(500, 4754)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">one_hot</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>aa</th>
      <th>abbrevi</th>
      <th>abduct</th>
      <th>abil</th>
      <th>abl</th>
      <th>aboard</th>
      <th>abor</th>
      <th>abound</th>
      <th>abridg</th>
      <th>abroad</th>
      <th>...</th>
      <th>yr</th>
      <th>yum</th>
      <th>yuppi</th>
      <th>zebra</th>
      <th>zep</th>
      <th>zero</th>
      <th>zhivago</th>
      <th>zillion</th>
      <th>zr</th>
      <th>zydeco</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>495</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>496</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>497</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>498</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>499</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>500 rows × 4754 columns</p>
</div>]]></content><author><name>Hojun Eric Choi</name><email>hchoi256@wisc.edu</email></author><category term="NLP" /><category term="NLP" /><category term="python" /><summary type="html"><![CDATA[PART 1: Vectorization]]></summary></entry><entry><title type="html">NLP - Part 1: Text Mining and Tokenization</title><link href="http://localhost:4000/nlp/nlp-basic-tokenizer/" rel="alternate" type="text/html" title="NLP - Part 1: Text Mining and Tokenization" /><published>2022-07-20T00:00:00+09:00</published><updated>2022-07-20T00:00:00+09:00</updated><id>http://localhost:4000/nlp/nlp-basic-tokenizer</id><content type="html" xml:base="http://localhost:4000/nlp/nlp-basic-tokenizer/"><![CDATA[<h1 id="part-1-text-mining">PART 1: Text Mining</h1>
<h2 id="1-1-텍스트-마이닝text-mining이란">1-1) 텍스트 마이닝(Text Mining)이란?</h2>
<p>비정형(= 구조화 되지 않은) 텍스트 빅 데이터에 대하여 효과적인 탐색 및 분석을 통해 유용한 정보, 패턴 및 실행 가능한 통찰력을 도출하는 과정이다.</p>

<h3 id="텍스트-마이닝의-필요성">텍스트 마이닝의 필요성</h3>

<p>일반적으로 텍스트 데이터는 구조화가 되어있지 않아서 비지도학습이 활용된다.</p>

<p>하지만, 실생활에는 엄청나게 많은 양의 텍스트 데이터가 순간마다 생성되고 있다 (<a href="https://github.com/hchoi256/ai-terms">차원의 저주</a>).</p>

<p>따라서, 텍스트 마이닝은 이러한 텍스트 데이터에서 business insight를 식별하여 목표 성취에 위험을 줄이는 것에 뜻이 있다.</p>

<blockquote>
  <p>정보에 입각한 결정을 내리고, 프로세스를 자동화하고, 감정 분석을 사용한 시장 조사 등을 수행하고자 한다.</p>
</blockquote>

<h3 id="텍스트-마이닝의-분야">텍스트 마이닝의 분야</h3>

<ul>
  <li><strong>정보 추출</strong> (Information Extraction)</li>
  <li><strong>문서 분류 및 클러스터링</strong> (Document classification and clustering)</li>
  <li><strong>정보 검색</strong> (Information retrieval)</li>
  <li><strong>자연어 처리</strong> (Natural Language Processing)</li>
</ul>

<blockquote>
  <p>NLP (Processing) -&gt; NLU (Understaing) -&gt; NLG (Generate)</p>
</blockquote>

<h3 id="nlp-텍스트-마이닝의-핵심">NLP: 텍스트 마이닝의 핵심</h3>

<p>컴퓨터를 사용하여 인간의 언어를 이해, 해석 및 조작하는 것을 다루는 연구 분야이다.</p>

<blockquote>
  <p>Natural Languae : 인간이 의사소통하는 모든 언어를 지칭한다!</p>
</blockquote>

<p>NLP은 인공지능의 <strong>하위 도메인</strong>이고, 중요한 정보의 대부분은 <strong>자연어</strong>로 작성되어 편리하게 태그가 지정되지 않기 때문에 텍스트 분석을 위한 컨텐츠를 식별하고 추출한 후 다양한 NLP기술을 사용하여 의미 있는 정보를 추출하고자 한다.</p>

<h4 id="nltk">NLTK</h4>

<p>NLTK이란 NLP를 위해 가장 널리 사용되는 패키지 중에 하나로, 컴퓨터가 자연어와 텍스트를 전처리, 분석 및 이해하는데 도움이 되는 여러 알고리즘이 포함된 강력한 파이썬 패키지이다.</p>

<h4 id="nltk에서-사용-가능한-일반적인-알고리즘">NLTK에서 사용 가능한 일반적인 알고리즘</h4>
<ul>
  <li><strong>Tokenization</strong> : 토큰화</li>
  <li><strong>Part of Speech Tagging</strong> : 품사 태깅</li>
  <li><strong>Named Entity Recognition</strong> : NER (명명된 엔티티 인식)</li>
  <li><strong>Sentiment analysis</strong> : 감정 분석</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"names"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">names</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">names</span><span class="p">.</span><span class="n">words</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['Abagael',
 'Abagail',
 'Abbe',
 'Abbey',
 'Abbi',
 'Abbie',
 'Abby',
 'Abigael',
 'Abigail',
 'Abigale',
 'Abra',
 ...]
</code></pre></div></div>

<blockquote>
  <p><em>corpus(말뭉치)</em></p>
  <blockquote>
    <p>논리적으로 <strong>최소한</strong>의 의미를 전달할 수 있는 단일 텍스트들의 모음이다.</p>
  </blockquote>
</blockquote>

<h1 id="part-2-tokenization">PART 2: Tokenization</h1>
<h2 id="2-1-tokenization">2-1) Tokenization</h2>
<ul>
  <li><strong>word tokenization</strong> : 대량의 텍스트를 단어로 분할하는 과정 각 단어를 인식하고 특정 감정에 대한 분류 및 계산과 같은 추가 분석을 거쳐야 하는 자연어 처리 작업</li>
  <li><strong>sentence tokenization</strong> : 문장을 기준으로 토큰화</li>
  <li><strong>Regex tokenization</strong> : Regex를 기준으로 해서 토큰화</li>
  <li><strong>Blank line tokenization</strong> : 빈 줄을 기준으로 토큰화</li>
</ul>

<h3 id="sentence-tokenization">Sentence Tokenization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">sent_tokenize</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"gutenberg"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample</span> <span class="o">=</span> <span class="n">gutenberg</span><span class="p">.</span><span class="n">raw</span><span class="p">(</span><span class="s">"carroll-alice.txt"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sent_tokens</span> <span class="o">=</span> <span class="n">sent_tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">sent_tokens</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1625
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sent_tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>["[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n\nCHAPTER I.",
 "Down the Rabbit-Hole\n\nAlice was beginning to get very tired of sitting by her sister on the\nbank, and of having nothing to do: once or twice she had peeped into the\nbook her sister was reading, but it had no pictures or conversations in\nit, 'and what is the use of a book,' thought Alice 'without pictures or\nconversation?'",
 'So she was considering in her own mind (as well as she could, for the\nhot day made her feel very sleepy and stupid), whether the pleasure\nof making a daisy-chain would be worth the trouble of getting up and\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\nclose by her.',
 "There was nothing so VERY remarkable in that; nor did Alice think it so\nVERY much out of the way to hear the Rabbit say to itself, 'Oh dear!",
 'Oh dear!',
 "I shall be late!'",
 '(when she thought it over afterwards, it\noccurred to her that she ought to have wondered at this, but at the time\nit all seemed quite natural); but when the Rabbit actually TOOK A WATCH\nOUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on,\nAlice started to her feet, for it flashed across her mind that she had\nnever before seen a rabbit with either a waistcoat-pocket, or a watch\nto take out of it, and burning with curiosity, she ran across the field\nafter it, and fortunately was just in time to see it pop down a large\nrabbit-hole under the hedge.',
 'In another moment down went Alice after it, never once considering how\nin the world she was to get out again.',
 'The rabbit-hole went straight on like a tunnel for some way, and then\ndipped suddenly down, so suddenly that Alice had not a moment to think\nabout stopping herself before she found herself falling down a very deep\nwell.',
 'Either the well was very deep, or she fell very slowly, for she had\nplenty of time as she went down to look about her and to wonder what was\ngoing to happen next.']
</code></pre></div></div>

<h3 id="word-tokenization">Word Tokenization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tok</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">tok</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>33494
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tok</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">20</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['[',
 'Alice',
 "'s",
 'Adventures',
 'in',
 'Wonderland',
 'by',
 'Lewis',
 'Carroll',
 '1865',
 ']',
 'CHAPTER',
 'I',
 '.',
 'Down',
 'the',
 'Rabbit-Hole',
 'Alice',
 'was',
 'beginning']
</code></pre></div></div>

<h3 id="regex-tokenization">Regex Tokenization</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample</span> <span class="o">=</span> <span class="s">"""
Volodymyr Oleksandrovych Zelenskyy (Ukrainian: Володимир Олександрович Зеленський; Russian: Владимир Александрович Зеленский, romanized: Vladimir Aleksandrovich Zelenskyy,[a] born 25 January 1978), also transliterated as Zelensky or Zelenskiy,[b] is a Ukrainian politician and former comedic actor[5] who has served as the 6th and current president of Ukraine since 2019.

Born to a Jewish family, Zelenskyy grew up as a native Russian speaker in Kryvyi Rih, a major city of Dnipropetrovsk Oblast in central Ukraine. Prior to his acting career, he obtained a degree in law from the Kyiv National Economic University. He then pursued a career in comedy and created the production company Kvartal 95, which produced films, cartoons, and TV shows including the TV series Servant of the People, in which Zelenskyy played the role of the Ukrainian president. The series aired from 2015 to 2019 and was immensely popular. A political party bearing the same name as the television show was created in March 2018 by employees of Kvartal 95.

Zelenskyy announced his candidacy in the 2019 Ukrainian presidential election on the evening of 31 December 2018, alongside the New Year's Eve address of then-president Petro Poroshenko on the TV channel 1+1. A political outsider, he had already become one of the frontrunners in opinion polls for the election. He won the election with 73.23 percent of the vote in the second round, defeating Poroshenko. He has positioned himself as an anti-establishment and anti-corruption figure.

As president, Zelenskyy has been a proponent of e-government and of unity between the Ukrainian- and Russian-speaking parts of the country's population.[6]: 11–13  His communication style heavily uses social media, particularly Instagram.[6]: 7–10  His party won a landslide victory in the snap legislative election held shortly after his inauguration as president. During his administration, Zelenskyy oversaw the lifting of legal immunity for members of parliament (the Verkhovna Rada),[7] the country's response to the COVID-19 pandemic and subsequent economic recession, and some progress in tackling corruption in Ukraine.[8][9]

During his presidential campaign, Zelenskyy promised to end Ukraine's protracted conflict with Russia, and he has attempted to engage in dialogue with Russian president Vladimir Putin.[10] His administration faced an escalation of tensions with Russia in 2021, culminating in the launch of the ongoing full-scale Russian invasion in February 2022. Zelenskyy's strategy during the Russian military buildup was to calm the Ukrainian populace and assure the international community that Ukraine was not seeking to retaliate.[11] He initially distanced himself from warnings of an imminent war, while also calling for security guarantees and military support from NATO to "withstand" the threat.[12] After the start of the invasion, Zelenskyy declared martial law across Ukraine and a general mobilisation of the armed forces. His leadership during the crisis has won him widespread international praise, and he has been described as a symbol of the Ukrainian resistance.[13][14]


"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">capword_tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="s">"[A-Z]\w+"</span><span class="p">)</span>
<span class="n">capword_tokenizer</span><span class="p">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['Volodymyr',
 'Oleksandrovych',
 'Zelenskyy',
 'Ukrainian',
 'Russian',
 'Vladimir',
 'Aleksandrovich',
 'Zelenskyy',
 'January',
 'Zelensky',
 'Zelenskiy',
 'Ukrainian',
 'Ukraine',
 'Born',
 'Jewish',
 'Zelenskyy',
 'Russian',
 'Kryvyi',
 'Rih',
 'Dnipropetrovsk',
 'Oblast',
 'Ukraine',
 'Prior',
 'Kyiv',
 ...]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">capword_tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="s">"[0-9]\w+"</span><span class="p">)</span>
<span class="n">capword_tokenizer</span><span class="p">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['25',
 '1978',
 '6th',
 '2019',
 '95',
 '2015',
 '2019',
 '2018',
 '95',
 '2019',
 '31',
 '2018',
 '73',
 '23',
 '11',
 '13',
 '10',
 '19',
 '10',
 '2021',
 '2022',
 '11',
 '12',
 '13',
 '14']
</code></pre></div></div>

<h3 id="blankline-tokenizer">Blankline Tokenizer</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">BlanklineTokenizer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample</span> <span class="o">=</span> <span class="s">"""
Good muffins cost £1.50 in London.</span><span class="se">\n\n</span><span class="s"> Please can you buy me two of them. </span><span class="se">\n\n</span><span class="s"> Thanks.
"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BlanklineTokenizer</span><span class="p">().</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['\nGood muffins cost £1.50 in London.',
 'Please can you buy me two of them.',
 'Thanks.\n']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample</span> <span class="o">=</span> <span class="sa">r</span><span class="s">"""
Good muffins cost £1.50 in London.\n\n Please can you buy me two of them. \n\n Thanks.
"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">BlanklineTokenizer</span><span class="p">().</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['\nGood muffins cost £1.50 in London.\\n\\n Please can you buy me two of them. \\n\\n Thanks.\n']
</code></pre></div></div>

<blockquote>
  <p><strong>f”“</strong> : f-string (format을 중시)</p>

  <p><strong>r”“</strong> : r-string (문자열의 문자 자체를 유지하려한다)</p>

  <p><strong>b”“</strong> : b-string (사람이 보기에는 일반 문자열처럼 보이지만, 내부적으로 byte형 문자열을 처리)</p>
</blockquote>

<h2 id="2-2-frequency-distribution-빈도-분포">2-2) Frequency Distribution (빈도 분포)</h2>
<p>텍스트에서 단어 빈도를 알아본다. Key가 단어이고, Value가 단어와 관련된 개수이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">gutenberg</span>
<span class="kn">from</span> <span class="nn">nltk.probability</span> <span class="kn">import</span> <span class="n">FreqDist</span> <span class="c1"># 문서에서 각 단어가 발생하는 횟수를 계산
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample</span> <span class="o">=</span> <span class="s">"""
The Bible (from Koine Greek τὰ βιβλία, tà biblía, 'the books') is a collection of religious texts or scriptures sacred in Christianity, Judaism, Samaritanism, and many other religions. The Bible is an anthology—a compilation of texts of a variety of forms—originally written in Hebrew, Aramaic, and Koine Greek. These texts include instructions, stories, poetry, and prophesies, among other genres. The collection of materials that are accepted as part of the Bible by a particular religious tradition or community is called a biblical canon. Believers in the Bible generally consider it to be a product of divine inspiration, while understanding what that means in different ways.

The origins of the oldest writings of the Israelites are lost to antiquity. The religious texts were compiled by different religious communities into various official collections. The earliest contained the first five books of the Bible, called the Torah, which was accepted as Jewish canon by the 5th century BCE. A second collection of narrative histories and prophesies was canonized in the 3rd century BCE. A third collection containing psalms, proverbs, and narrative histories, was canonized sometime between the 2nd century BCE and the 2nd century CE.[1] The transmission history of these combined collections spans approximately 3000 years, and there is no scholarly consensus as to when the Jewish Hebrew Bible canon was settled in its present form.[2] Some scholars argue that it was fixed by the Hasmonean dynasty (140–40 BCE),[a] while others argue it was not fixed until the second century CE or even later.[3] The Dead Sea scrolls are approximately dated to 250 BCE–100 CE and are the oldest existing copies of the books of the Hebrew Bible. Tanakh is an alternate term for the Hebrew Bible composed of the first letters of the three parts of the Hebrew scriptures: the Torah ("Teaching"), the Nevi'im ("Prophets"), and the Ketuvim ("Writings"). The Torah is also known as the Pentateuch. The Masoretic Text, in Hebrew and Aramaic, is considered the authoritative text by Rabbinic Judaism; the Septuagint, a Koine Greek translation from the third and second centuries BCE, largely overlaps with the Hebrew Bible.

Christianity began as an outgrowth of Judaism, using the Septuagint as the basis of the Old Testament. The early Church continued the Jewish tradition of writing and incorporating what it saw as inspired, authoritative religious books. The gospels, Pauline epistles and other texts coalesced into the "New Testament" very early. In the first three centuries CE, the concept of a closed canon emerged in response to heretical writings in the second century. The list of books included in the Catholic Bible was established as canon by the Council of Rome in 382, followed by those of Hippo in 393 and Carthage in 397. Christian biblical canons range from the 73 books of the Catholic Church canon, and the 66-book canon of most Protestant denominations, to the 81 books of the Ethiopian Orthodox Tewahedo Church canon, among others.

With estimated total sales of over five billion copies, the Bible is widely considered to be the best-selling publication of all time.[4][5] It has had a profound influence both on Western culture and history and on cultures around the globe.[6] "Simply put, the Bible is the most influential book of all-time."[7] The study of the Bible through biblical criticism has indirectly impacted culture and history as well. The Bible is currently translated or being translated into about half of the world's languages.
"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">token_words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">token_words</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['The',
 'Bible',
 '(',
 'from',
 'Koine',
 'Greek',
 'τὰ',
 'βιβλία',
 ',',
 'tà',
 'biblía',
 ',',
 "'the",
 'books',
 "'",
 ')',
 'is',
 'a',
 'collection',
 'of']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">token_words</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FreqDist({'the': 51, ',': 35, 'of': 32, '.': 27, 'and': 18, 'The': 15, 'Bible': 14, 'in': 13, 'is': 10, 'a': 9, ...})
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">capword_tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="s">"[A-Za-z0-9]\w+"</span><span class="p">)</span>
<span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">capword_tokenizer</span><span class="p">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>FreqDist({'the': 52, 'of': 32, 'and': 18, 'The': 15, 'Bible': 14, 'in': 13, 'is': 10, 'as': 9, 'canon': 8, 'books': 7, ...})
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">matplotlib</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"Top 10 Most Common Words"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180378796-f8a9a87f-2f43-4f6a-9d3b-64b415132eba.png" alt="output_66_0" /></p>

<h2 id="2-3-stop-words-불용어">2-3) Stop Words (불용어)</h2>
<p>일반적으로 자연어를 처리하기 전에 걸러내는 단어이다.</p>

<p>실제로 모든 언어에서 가장 흔한 단어 (관사, 전치사, 대명사, 접속사 등)이며 텍스트에 많은 정보를 추가하지 않는다는 것이 특징이다.</p>

<p>주어진 말뭉치의 텍스트에서 불용어를 제거하여 데이터를 정리하고, 더 희귀하고 우리가 관심 있는 것과 잠재적으로 더 관련이 있는 단어를 식별하고자 하는 것이 목적이다!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"stopwords"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">))</span>
<span class="nb">type</span><span class="p">(</span><span class="n">stop_words</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">stop_words</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(set, 179)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span><span class="p">,</span> <span class="n">sent_tokenize</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filtered_word</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample</span> <span class="o">=</span> <span class="s">"""
The Bible (from Koine Greek τὰ βιβλία, tà biblía, 'the books') is a collection of religious texts or scriptures sacred in Christianity, Judaism, Samaritanism, and many other religions. The Bible is an anthology—a compilation of texts of a variety of forms—originally written in Hebrew, Aramaic, and Koine Greek. These texts include instructions, stories, poetry, and prophesies, among other genres. The collection of materials that are accepted as part of the Bible by a particular religious tradition or community is called a biblical canon. Believers in the Bible generally consider it to be a product of divine inspiration, while understanding what that means in different ways.

The origins of the oldest writings of the Israelites are lost to antiquity. The religious texts were compiled by different religious communities into various official collections. The earliest contained the first five books of the Bible, called the Torah, which was accepted as Jewish canon by the 5th century BCE. A second collection of narrative histories and prophesies was canonized in the 3rd century BCE. A third collection containing psalms, proverbs, and narrative histories, was canonized sometime between the 2nd century BCE and the 2nd century CE.[1] The transmission history of these combined collections spans approximately 3000 years, and there is no scholarly consensus as to when the Jewish Hebrew Bible canon was settled in its present form.[2] Some scholars argue that it was fixed by the Hasmonean dynasty (140–40 BCE),[a] while others argue it was not fixed until the second century CE or even later.[3] The Dead Sea scrolls are approximately dated to 250 BCE–100 CE and are the oldest existing copies of the books of the Hebrew Bible. Tanakh is an alternate term for the Hebrew Bible composed of the first letters of the three parts of the Hebrew scriptures: the Torah ("Teaching"), the Nevi'im ("Prophets"), and the Ketuvim ("Writings"). The Torah is also known as the Pentateuch. The Masoretic Text, in Hebrew and Aramaic, is considered the authoritative text by Rabbinic Judaism; the Septuagint, a Koine Greek translation from the third and second centuries BCE, largely overlaps with the Hebrew Bible.

Christianity began as an outgrowth of Judaism, using the Septuagint as the basis of the Old Testament. The early Church continued the Jewish tradition of writing and incorporating what it saw as inspired, authoritative religious books. The gospels, Pauline epistles and other texts coalesced into the "New Testament" very early. In the first three centuries CE, the concept of a closed canon emerged in response to heretical writings in the second century. The list of books included in the Catholic Bible was established as canon by the Council of Rome in 382, followed by those of Hippo in 393 and Carthage in 397. Christian biblical canons range from the 73 books of the Catholic Church canon, and the 66-book canon of most Protestant denominations, to the 81 books of the Ethiopian Orthodox Tewahedo Church canon, among others.

With estimated total sales of over five billion copies, the Bible is widely considered to be the best-selling publication of all time.[4][5] It has had a profound influence both on Western culture and history and on cultures around the globe.[6] "Simply put, the Bible is the most influential book of all-time."[7] The study of the Bible through biblical criticism has indirectly impacted culture and history as well. The Bible is currently translated or being translated into about half of the world's languages.
"""</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenized_word</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">tokenized_word</span><span class="p">)</span>
<span class="n">fdist_top10</span> <span class="o">=</span> <span class="n">fdist</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fdist_top10</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[('the', 51),
 (',', 35),
 ('of', 32),
 ('.', 27),
 ('and', 18),
 ('The', 15),
 ('Bible', 14),
 ('in', 13),
 ('is', 10),
 ('a', 9)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"Top 10 Most Common Words in Sample"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180379028-cfc18f85-faa9-4d0c-b693-a2544f8457bf.png" alt="output_88_0" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokenized_word</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">filtered_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">filtered_word</span><span class="p">)</span>
<span class="n">fdist_top10</span> <span class="o">=</span> <span class="n">fdist</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">fdist_top10</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[('Bible', 28),
 ('canon', 16),
 ('books', 14),
 ('Hebrew', 14),
 ('century', 12),
 ('religious', 10),
 ('texts', 10),
 ('collection', 8),
 ('second', 8),
 ('Koine', 6)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s">"Top 10 Most Common Words in Sample"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180378703-5c921d67-37ce-45b8-a7ed-edde873e76b1.png" alt="output_90_0" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"stopwords"</span><span class="p">,</span> <span class="n">download_dir</span><span class="o">=</span><span class="s">"./data"</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="2-4-unigrams-bigrams-trigrams-ngrams">2-4) Unigrams, Bigrams, Trigrams, ngrams</h2>
<p>기계는 한 번에 한 단어를 통과해야 할 때 문장의 의미를 완전히 이해할 수 없다.</p>
<ul>
  <li>한 번에 하나씩 주어진 단어를 유니그램이라고 합니다.</li>
  <li>한 번에 두 개의 단어 -&gt; 바이그램</li>
  <li>한 번에 세 개의 단어 -&gt; 트라이그램</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">nltk</span><span class="p">.</span><span class="n">download</span><span class="p">(</span><span class="s">"webtext"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">webtext</span><span class="p">,</span> <span class="n">stopwords</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">bigrams</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_words</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">webtext</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"firefox.txt"</span><span class="p">):</span>
    <span class="n">text_words</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="nb">type</span><span class="p">(</span><span class="n">text_words</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_words</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(list, 102457)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">text_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">webtext</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"firefox.txt"</span><span class="p">)]</span> 

<span class="nb">type</span><span class="p">(</span><span class="n">text_words</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_words</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(list, 102457)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filtered_word</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text_words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">filtered_word</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">filtered_word</span><span class="p">)</span>
<span class="n">fdist</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[('page', 882),
 ('firefox', 879),
 ('window', 647),
 ('bookmarks', 598),
 ('firebird', 583),
 ('open', 576),
 ('menu', 527),
 ('toolbar', 518),
 ('browser', 484),
 ('bookmark', 482),
 ('download', 441),
 ('work', 421),
 ('manager', 408),
 ('crash', 389),
 ('file', 382),
 ('button', 378),
 ('dialog', 369),
 ('text', 327),
 ('crashes', 316),
 ('mozilla', 314)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180378509-0b7f8535-5123-43c3-838d-27f45a609411.png" alt="output_101_0" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">filtered_word</span><span class="p">[:</span><span class="mi">20</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['cookie',
 'manager',
 'allow',
 'sites',
 'removed',
 'cookies',
 'future',
 'cookies',
 'stay',
 'checked',
 'full',
 'screen',
 'mode',
 'pressing',
 'ctrl',
 'open',
 'browser',
 'download',
 'dialog',
 'left']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bigrams_list</span> <span class="o">=</span> <span class="n">bigrams</span><span class="p">(</span><span class="n">filtered_word</span><span class="p">)</span>
<span class="n">freq</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">bigrams_list</span><span class="p">)</span>
<span class="n">freq</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[(('download', 'manager'), 150),
 (('context', 'menu'), 105),
 (('bookmarks', 'toolbar'), 103),
 (('mozilla', 'firebird'), 96),
 (('right', 'click'), 89),
 (('firefox', 'crashes'), 72),
 (('print', 'preview'), 71),
 (('password', 'manager'), 63),
 (('open', 'tabs'), 61),
 (('browser', 'window'), 56),
 (('default', 'browser'), 52),
 (('tools', 'options'), 50),
 (('middle', 'click'), 47),
 (('home', 'page'), 47),
 (('toolbar', 'folder'), 46),
 (('bookmarks', 'menu'), 46),
 (('bookmark', 'manager'), 44),
 (('bookmark', 'toolbar'), 43),
 (('page', 'info'), 43),
 (('bookmarks', 'manager'), 42)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">freq</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180378599-674ae2aa-ad6a-4f9c-89e0-84189f66228d.png" alt="output_104_0" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">trigrams</span>

<span class="n">trigrams_list</span> <span class="o">=</span> <span class="n">trigrams</span><span class="p">(</span><span class="n">filtered_word</span><span class="p">)</span>
<span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">trigrams_list</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[(('bookmarks', 'toolbar', 'folder'), 23),
 (('full', 'screen', 'mode'), 19),
 (('view', 'page', 'source'), 15),
 (('bookmark', 'toolbar', 'folder'), 14),
 (('right', 'click', 'context'), 14),
 (('middle', 'mouse', 'button'), 13),
 (('click', 'context', 'menu'), 13),
 (('right', 'click', 'menu'), 12),
 (('save', 'link', 'disk'), 12),
 (('download', 'manager', 'open'), 9)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180378674-2bfcf9aa-1aef-4394-8de3-1877773589a3.png" alt="output_108_0" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">ngrams</span>

<span class="n">ngrams_list</span> <span class="o">=</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">filtered_word</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">ngrams_list</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fdist</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[(('right', 'click', 'context', 'menu'), 13),
 (('error', 'launching', 'browser', 'window'), 7),
 (('launching', 'browser', 'window', 'binding'), 6),
 (('browser', 'window', 'binding', 'browser'), 6),
 (('tree', 'view', 'bookmark', 'dialog'), 4),
 (('bookmarks', 'toolbar', 'folder', 'bookmarks'), 3),
 (('click', 'middle', 'mouse', 'button'), 3),
 (('work', 'full', 'screen', 'mode'), 3),
 (('button', 'download', 'font', 'dialog'), 3),
 (('error', 'establishing', 'encrypted', 'connection'), 3)]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ngrams_list</span> <span class="o">=</span> <span class="n">ngrams</span><span class="p">(</span><span class="n">filtered_word</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">fdist</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">(</span><span class="n">ngrams_list</span><span class="p">)</span>
<span class="n">fdist</span><span class="p">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[(('error', 'launching', 'browser', 'window', 'binding'), 6),
 (('launching', 'browser', 'window', 'binding', 'browser'), 6),
 (('save', 'link', 'disk', 'context', 'menu'), 3),
 (('allow', 'sites', 'removed', 'cookies', 'future'), 2),
 (('sites', 'removed', 'cookies', 'future', 'cookies'), 2),
 (('shortcut', 'increase', 'text', 'size', 'broken'), 2),
 (('focus', 'page', 'going', 'page', 'bookmark'), 2),
 (('..."', 'right', 'click', 'context', 'menu'), 2),
 (('webpage', 'loads', 'refreshing', 'page', 'continuous'), 2),
 (('loads', 'refreshing', 'page', 'continuous', 'loop'), 2)
</code></pre></div></div>]]></content><author><name>Hojun Eric Choi</name><email>hchoi256@wisc.edu</email></author><category term="NLP" /><category term="NLP" /><category term="python" /><summary type="html"><![CDATA[PART 1: Text Mining 1-1) 텍스트 마이닝(Text Mining)이란? 비정형(= 구조화 되지 않은) 텍스트 빅 데이터에 대하여 효과적인 탐색 및 분석을 통해 유용한 정보, 패턴 및 실행 가능한 통찰력을 도출하는 과정이다.]]></summary></entry><entry><title type="html">How to Write Markdown</title><link href="http://localhost:4000/star/template/" rel="alternate" type="text/html" title="How to Write Markdown" /><published>2022-07-19T00:00:00+09:00</published><updated>2022-07-19T00:00:00+09:00</updated><id>http://localhost:4000/star/template</id><content type="html" xml:base="http://localhost:4000/star/template/"><![CDATA[<h1 id="공지사항">공지사항</h1>
<h2 id="공지사항-등록">공지사항 등록</h2>
<p class="notice--danger"><strong>[Notice]</strong> <a href="https://hchoi256.github.io/star/template/">Get your post template!</a></p>

<h2 id="공지사항-세부내용">공지사항 세부내용</h2>

<div class="notice--success">
<h4>공지사항입니다.</h4>
<ul>
    <li>공지사항 순서1</li>
    <li>공지사항 순서2</li>
</ul>
</div>

<h1 id="버튼-생성하기">버튼 생성하기</h1>
<p><a href="https://hchoi256.github.io/" class="btn btn--danger">Home</a></p>

<h1 id="미디어-불러오기">미디어 불러오기</h1>

<!-- Courtesy of embedresponsively.com -->

<div class="responsive-video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/XsxDH4HcOWA" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </div>]]></content><author><name>Hojun Eric Choi</name><email>hchoi256@wisc.edu</email></author><category term="star" /><category term="markdown" /><summary type="html"><![CDATA[공지사항 공지사항 등록 [Notice] Get your post template!]]></summary></entry></feed>