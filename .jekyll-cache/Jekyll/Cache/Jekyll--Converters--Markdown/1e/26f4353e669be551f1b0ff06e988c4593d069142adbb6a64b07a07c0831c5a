I"ĞC<h1 id="what-is-topic-modeling">What is Topic Modeling?</h1>
<p>ì£¼ì œ ëª¨ë¸ë§(Topic Modeling)ì´ë€ ì£¼ì œì— í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ íŒ¨í„´ì„ ì‹ë³„í•˜ëŠ” ê³¼ì •ì´ë‹¤. <span style="color: blue"> Topic Modeling is the process of identifying a pattern of text data corresponding to a topic. </span></p>

<p>í…ìŠ¤íŠ¸ì— ì—¬ëŸ¬ ì£¼ì œê°€ í¬í•¨ëœ ê²½ìš° ì´ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ í…ìŠ¤íŠ¸ ë‚´ì—ì„œ í•´ë‹¹ ì£¼ì œë¥¼ ì‹ë³„í•˜ê³  ë¶„ë¦¬í•  ìˆ˜ ìˆë‹¤. <span style="color: blue"> If the text contains multiple subjects, this technique can be used to identify and isolate those subjects within the input text. </span></p>

<p>ì´ ê¸°ìˆ ì€ ì£¼ì–´ì§„ ë¬¸ì„œ ì…‹ì—ì„œ ìˆ¨ê²¨ì§„ ì£¼ì œë¥¼ ì°¾ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤. <span style="color: blue"> This technique can also be used to find hidden topics in a given set of documents. </span></p>

<h2 id="chracteristics-of-topic-modeling">Chracteristics of Topic Modeling</h2>
<p>ë ˆì´ë¸”ì´ ì§€ì •ëœ ë°ì´í„°ê°€ í•„ìš”í•˜ì§€ ì•Šë‹¤ (ë¹„ì§€ë„í•™ìŠµ) <span style="color: blue"> No labeling (Unsupervised Learning) </span></p>

<p>ì¸í„°ë„·ì—ì„œ ìƒì„±ë˜ëŠ” ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê°ì•ˆí•  ë•Œ í† í”½ ëª¨ë¸ë§ì€ ë°©ëŒ€í•œ ì–‘ì„ ë°ì´í„°ë¥¼ ìš”ì•½í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•˜ë‹¤. <span style="color: blue"> Topic Modeling can summarize tons of text data springing up online.  </span></p>

<h1 id="loading-the-libraries">Loading the libraries</h1>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">RegexpTokenizer</span> <span class="c1"># Vectorization
</span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span> <span class="c1"># ë¶ˆìš©ì–´ stopwords
</span><span class="kn">from</span> <span class="nn">nltk.stem.snowball</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span> <span class="c1"># ì–´ê°„ ì¶”ì¶œ Stemmer
</span><span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">corpora</span>
</code></pre></div></div>

<h1 id="loading-the-dataset">Loading the dataset</h1>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">input_file</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">input_file</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">():</span>
            <span class="n">data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">data</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">load_data</span><span class="p">(</span><span class="s">"7.1 data.txt"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            ['The Roman empire expanded very rapidly and it was the biggest empire in the world for a long time.',
            'An algebraic structure is a set with one or more finitary operations defined on it that satisfies a list of axioms.',
            'Renaissance started as a cultural movement in Italy in the Late Medieval period and later spread to the rest of Europe.',
            'The line of demarcation between prehistoric and historical times is crossed when people cease to live only in the present.',
            'Mathematicians seek out patterns and use them to formulate new conjectures.  ',
            'A notational symbol that represents a number is called a numeral in mathematics. ',
            'The process of extracting the underlying essence of a mathematical concept is called abstraction.',
            'Historically, people have frequently waged wars against each other in order to expand their empires.',
            'Ancient history indicates that various outside influences have helped formulate the culture and traditions of Eastern Europe.',
            'Mappings between sets which preserve structures are of special interest in many fields of mathematics.']
</code></pre></div></div>

<h1 id="tokenization">Tokenization</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="n">input_text</span><span class="p">):</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RegexpTokenizer</span><span class="p">(</span><span class="sa">r</span><span class="s">"\w+"</span><span class="p">)</span>
    <span class="n">stemmer</span> <span class="o">=</span> <span class="n">SnowballStemmer</span><span class="p">(</span><span class="s">"english"</span><span class="p">)</span>
    <span class="n">stop_words</span> <span class="o">=</span> <span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">"english"</span><span class="p">)</span>

    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">input_text</span><span class="p">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span> <span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">stop_words</span> <span class="p">]</span>
    <span class="n">tokens_stemmed</span> <span class="o">=</span> <span class="p">[</span> <span class="n">stemmer</span><span class="p">.</span><span class="n">stem</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="p">]</span>

    <span class="k">return</span> <span class="n">tokens_stemmed</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span> <span class="n">process</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span> <span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            [['roman', 'empir', 'expand', 'rapid', 'biggest', 'empir', 'world', 'long', 'time'], ['algebra', 'structur', 'set', 'one', 'finitari', 'oper', 'defin', 'satisfi', 'list', 'axiom'], ['renaiss', 'start', 'cultur', 'movement', 'itali', 'late', 'mediev', 'period', 'later', 'spread', 'rest', 'europ'], ['line', 'demarc', 'prehistor', 'histor', 'time', 'cross', 'peopl', 'ceas', 'live', 'present'], ['mathematician', 'seek', 'pattern', 'use', 'formul', 'new', 'conjectur'], ['notat', 'symbol', 'repres', 'number', 'call', 'numer', 'mathemat'], ['process', 'extract', 'under', 'essenc', 'mathemat', 'concept', 'call', 'abstract'], ['histor', 'peopl', 'frequent', 'wage', 'war', 'order', 'expand', 'empir'], ['ancient', 'histori', 'indic', 'various', 'outsid', 'influenc', 'help', 'formul', 'cultur', 'tradit', 'eastern', 'europ'], ['map', 'set', 'preserv', 'structur', 'special', 'interest', 'mani', 'field', 'mathemat']]
</code></pre></div></div>

<p>ìƒê¸° ë°ì´í„°ê°€ 2ì°¨ì› ë°°ì—´ë¡œì¨ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì—, ë”•ì…”ë„ˆë¦¬ë¥¼ í™œìš©í•˜ì—¬ ì´ìš©í•˜ê¸° ìš©ì´í•˜ê²Œ ë³€í™˜í•´ì¤€ë‹¤. <span style="color: blue"> Since the data exists as a two-dimensional array, we are using a dictionary to convert the data for easy use. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dict_tokens</span> <span class="o">=</span> <span class="n">corpora</span><span class="p">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>

<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            ['roman', 'empir', 'expand', 'rapid', 'biggest', 'empir', 'world', 'long', 'time']
            ['algebra', 'structur', 'set', 'one', 'finitari', 'oper', 'defin', 'satisfi', 'list', 'axiom']
            ['renaiss', 'start', 'cultur', 'movement', 'itali', 'late', 'mediev', 'period', 'later', 'spread', 'rest', 'europ']
            ['line', 'demarc', 'prehistor', 'histor', 'time', 'cross', 'peopl', 'ceas', 'live', 'present']
            ['mathematician', 'seek', 'pattern', 'use', 'formul', 'new', 'conjectur']
            ['notat', 'symbol', 'repres', 'number', 'call', 'numer', 'mathemat']
            ['process', 'extract', 'under', 'essenc', 'mathemat', 'concept', 'call', 'abstract']
            ['histor', 'peopl', 'frequent', 'wage', 'war', 'order', 'expand', 'empir']
            ['ancient', 'histori', 'indic', 'various', 'outsid', 'influenc', 'help', 'formul', 'cultur', 'tradit', 'eastern', 'europ']
            ['map', 'set', 'preserv', 'structur', 'special', 'interest', 'mani', 'field', 'mathemat']
</code></pre></div></div>

<h1 id="vectorization-bag-of-words">Vectorization: Bag of Words</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">doc_term_mat</span> <span class="o">=</span> <span class="p">[</span> <span class="n">dict_tokens</span><span class="p">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">doc_term_mat</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            [[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1)], [(18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1)], [(6, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1)], [(39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1)], [(46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1)], [(46, 1), (47, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1)], [(1, 1), (2, 1), (33, 1), (36, 1), (59, 1), (60, 1), (61, 1), (62, 1)], [(18, 1), (19, 1), (40, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1)], [(16, 1), (17, 1), (47, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1)]]
</code></pre></div></div>

<h1 id="latent-dirichlet-allocation">Latent Dirichlet Allocation</h1>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_topics</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Latent Dirichlet Allocation
</span><span class="n">ldamodel</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="n">ldamodel</span><span class="p">.</span><span class="n">LdaModel</span><span class="p">(</span><span class="n">doc_term_mat</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="n">num_topics</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dict_tokens</span><span class="p">,</span> <span class="n">passes</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</code></pre></div></div>

<blockquote>
  <p><strong>ì ì¬ ë””ë¦¬í´ë ˆ í• ë‹¹(Latent Dirichlet allocation, LDA)</strong>: ì£¼ì–´ì§„ ë¬¸ì„œì— ëŒ€í•˜ì—¬ ê° ë¬¸ì„œì— ì–´ë–¤ ì£¼ì œë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ë¥¼ ì„œìˆ í•˜ëŠ” ëŒ€í•œ í™•ë¥ ì  í† í”½ ëª¨ë¸ ê¸°ë²• ì¤‘ í•˜ë‚˜ì´ë‹¤. <span style="color: blue"> It is one of the probabilistic topic model techniques for describing which topics exist in each document for a given document. </span></p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_words</span> <span class="o">=</span> <span class="mi">5</span> <span class="c1"># ê° ì£¼ì œì— ëŒ€í•œ ê¸°ì—¬í•˜ëŠ” ìƒìœ„ 5ê°œ ë‹¨ì–´ ì¶œë ¥ the top 5 contributing words to each topic
</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Top "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_words</span><span class="p">)</span> <span class="o">+</span> <span class="s">" contributing words to each topic."</span><span class="p">)</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">ldamodel</span><span class="p">.</span><span class="n">print_topics</span><span class="p">(</span><span class="n">num_topics</span><span class="o">=</span><span class="n">num_topics</span><span class="p">,</span> <span class="n">num_words</span><span class="o">=</span><span class="n">num_words</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Topic : "</span><span class="p">,</span> <span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="n">list_of_strings</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">split</span><span class="p">(</span><span class="s">" + "</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">list_of_strings</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">"*"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">"*"</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="s">"==&gt;"</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="s">'%'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Top 5 contributing words to each topic.
            Topic :  0
            "empir" ==&gt; 3.4%
            "cultur" ==&gt; 2.4%
            "europ" ==&gt; 2.4%
            "time" ==&gt; 2.4%
            "histor" ==&gt; 2.4%

            Topic :  1
            "mathemat" ==&gt; 4.9%
            "structur" ==&gt; 3.7%
            "set" ==&gt; 3.7%
            "call" ==&gt; 3.1%
            "one" ==&gt; 2.2%
</code></pre></div></div>

<blockquote>
  <p><a href="https://wikidocs.net/30708">LDA</a></p>
</blockquote>
:ET