I"<h1 id="code">Code</h1>
<p class="notice--danger"><strong>[Notice]</strong> <a href="https://github.com/hchoi256/machine-learning-development">download here</a></p>

<h1 id="observing-the-dataset">Observing the dataset</h1>
<p>Classes are as listed below:</p>
<ul>
  <li>( 0, bâ€™Speed limit (20km/h)â€™) ( 1, bâ€™Speed limit (30km/h)â€™)</li>
  <li>( 2, bâ€™Speed limit (50km/h)â€™) ( 3, bâ€™Speed limit (60km/h)â€™)</li>
  <li>( 4, bâ€™Speed limit (70km/h)â€™) ( 5, bâ€™Speed limit (80km/h)â€™)</li>
  <li>( 6, bâ€™End of speed limit (80km/h)â€™) ( 7, bâ€™Speed limit (100km/h)â€™)</li>
  <li>( 8, bâ€™Speed limit (120km/h)â€™) ( 9, bâ€™No passingâ€™)</li>
  <li>(10, bâ€™No passing for vehicles over 3.5 metric tonsâ€™)</li>
  <li>(11, bâ€™Right-of-way at the next intersectionâ€™) (12, bâ€™Priority roadâ€™)</li>
  <li>(13, bâ€™Yieldâ€™) (14, bâ€™Stopâ€™) (15, bâ€™No vehiclesâ€™)</li>
  <li>(16, bâ€™Vehicles over 3.5 metric tons prohibitedâ€™) (17, bâ€™No entryâ€™)</li>
  <li>(18, bâ€™General cautionâ€™) (19, bâ€™Dangerous curve to the leftâ€™)</li>
  <li>(20, bâ€™Dangerous curve to the rightâ€™) (21, bâ€™Double curveâ€™)</li>
  <li>(22, bâ€™Bumpy roadâ€™) (23, bâ€™Slippery roadâ€™)</li>
  <li>(24, bâ€™Road narrows on the rightâ€™) (25, bâ€™Road workâ€™)</li>
  <li>(26, bâ€™Traffic signalsâ€™) (27, bâ€™Pedestriansâ€™) (28, bâ€™Children crossingâ€™)</li>
  <li>(29, bâ€™Bicycles crossingâ€™) (30, bâ€™Beware of ice/snowâ€™)</li>
  <li>(31, bâ€™Wild animals crossingâ€™)</li>
  <li>(32, bâ€™End of all speed and passing limitsâ€™) (33, bâ€™Turn right aheadâ€™)</li>
  <li>(34, bâ€™Turn left aheadâ€™) (35, bâ€™Ahead onlyâ€™) (36, bâ€™Go straight or rightâ€™)</li>
  <li>(37, bâ€™Go straight or leftâ€™) (38, bâ€™Keep rightâ€™) (39, bâ€™Keep leftâ€™)</li>
  <li>(40, bâ€™Roundabout mandatoryâ€™) (41, bâ€™End of no passingâ€™)</li>
  <li>(42, bâ€™End of no passing by vehicles over 3.5 metric tonsâ€™)</li>
</ul>

<p><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">The network used is called <strong>Le-Net</strong> that was presented by Yann LeCun</a></p>

<h1 id="learning-goals">Learning Goals</h1>
<ol>
  <li>Le-Netì´ë¼ëŠ” ì‹¬ì¸µ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ êµí†µ í‘œì§€íŒ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. <span style="color: blue">Traffic signs classification using Le-Net, a deep neural network</span>
    <ul>
      <li>ììœ¨ ì£¼í–‰ ìë™ì°¨ ë¶„ì•¼ì—ì„œ íŠ¹íˆ ê°ê´‘ë°›ëŠ” ë¶„ì•¼ë¡œ ì¹´ë©”ë¼ë¥¼ í†µí•´ ë¬¼ì²´ ê°ì§€ ë° êµí†µ í‘œì§€íŒ ì¸ì‹í•˜ì—¬ ì ì ˆí•œ ìë™ì°¨ ìˆ˜í–‰ì²˜ë¦¬ë¥¼ ì´í–‰í•´ì•¼ í•œë‹¤. <span style="color: blue">A rising field of study in self-driving, expecting the camera to identify objects and traffic signs.</span></li>
    </ul>
  </li>
  <li>
    <p>ì‹œê·¸ëª¨ì´ë“œ ReLUì™€ ê°™ì€ í™œì„±í™” í•¨ìˆ˜ì— ëŒ€í•´ ì´í•´í•œë‹¤ <span style="color: blue">Understanding activation functions like ReLU, Sigmoid, etc.</span></p>
  </li>
  <li>
    <p>ì¼€ë¼ìŠ¤ APIë¡œ ì‹¬ì¸µ í•©ì„±ê³± ì‹ ê²¬ë§ì„ ì„¤ê³„í•˜ê³  ë¶„ë¥˜ ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ìµœì í™”í•œë‹¤. <span style="color: blue">Building deep CNN using Keras API and optimizing the network for better classification</span></p>
  </li>
  <li>
    <p>êµì°¨ ê²€ì¦(Cross Validation)ì„ ì´í•´í•˜ê³  ì‹ ê²½ë§ ê³¼ì í•© ë°©ì§€ ì ìš© ë°©ë²•ì— ëŒ€í•´ ì´í•´í•œë‹¤. <span style="color: blue">Understanding cross-validation and how to avoid overfitting</span></p>
  </li>
  <li>í˜¼ë™, í–‰ë ¬ ë° ë¶„ë¥˜ ë³´ê³ ì„œë¡œ ëª¨ë¸ í‰ê°€ ë° ê²°ê³¼ ì œì‹œí•˜ëŠ” ë²•ì„ ë°°ìš´ë‹¤ <span style="color: blue">Model evaluation using confusion matrix and classification report</span>
    <ul>
      <li>precision &amp; recall</li>
    </ul>
  </li>
</ol>

<details>
<summary>Le-Net(Hide/Show)</summary>
<div>

    <p><img src="https://user-images.githubusercontent.com/39285147/180630434-4192f16c-b0e4-473d-bc36-3d1fc2b652d1.png" alt="image" /></p>

    <ul>
      <li>STEP 1: THE FIRST CONVOLUTIONAL LAYER #1
        <ul>
          <li>Input = 32x32x1</li>
          <li>Output = 28x28x6</li>
          <li>Output = (Input-filter+1)/Stride* =&gt; (32-5+1)/1=28</li>
          <li>Used a 5x5 Filter with input depth of 3 and output depth of 6</li>
          <li>Apply a RELU Activation function to the output</li>
          <li>
            <p>pooling for input, Input = 28x28x6 and Output = 14x14x6</p>
          </li>
          <li>Stride is the amount by which the kernel is shifted when the kernel is passed over the image.</li>
        </ul>
      </li>
      <li>STEP 2: THE SECOND CONVOLUTIONAL LAYER #2
        <ul>
          <li>Input = 14x14x6</li>
          <li>Output = 10x10x16</li>
          <li>Layer 2: Convolutional layer with Output = 10x10x16</li>
          <li>Output = (Input-filter+1)/strides =&gt; 10 = 14-5+1/1</li>
          <li>Apply a RELU Activation function to the output</li>
          <li>Pooling with Input = 10x10x16 and Output = 5x5x16</li>
        </ul>
      </li>
      <li>STEP 3: FLATTENING THE NETWORK
        <ul>
          <li>Flatten the network with Input = 5x5x16 and Output = 400</li>
        </ul>
      </li>
      <li>STEP 4: FULLY CONNECTED LAYER
        <ul>
          <li>Layer 3: Fully Connected layer with Input = 400 and Output = 120</li>
          <li>Apply a RELU Activation function to the output</li>
        </ul>
      </li>
      <li>STEP 5: ANOTHER FULLY CONNECTED LAYER
        <ul>
          <li>Layer 4: Fully Connected Layer with Input = 120 and Output = 84</li>
          <li>Apply a RELU Activation function to the output</li>
        </ul>
      </li>
      <li>STEP 6: FULLY CONNECTED LAYER
        <ul>
          <li>Layer 5: Fully Connected layer with Input = 84 and Output = 43</li>
        </ul>
      </li>
    </ul>

  </div>
</details>

<h1 id="loading-the-dataset">Loading the dataset</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pickle</span> <span class="c1"># Serialize the data
</span><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1"># Import Pandas for data manipulation using dataframes
</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># Import Numpy for data statistical analysis 
</span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> <span class="c1"># Import matplotlib for data visualisation
</span><span class="kn">import</span> <span class="nn">random</span>
</code></pre></div></div>

<blockquote>
  <p><em>ë°ì´í„° ì§ë ¬í™”(Serialization)</em>: ê°ì²´ì— ì €ì¥ëœ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¼ì— ì“°ê¸°ìœ„í•´ ì—°ì†ì ì¸ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ëŠ”ê²ƒ  <span style="color: blue">the process of converting an object into a stream of bytes</span></p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading the dataset
</span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"./traffic-signs-data/train.p"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">training_data</span><span class="p">:</span>
    <span class="n">train</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"./traffic-signs-data/valid.p"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">validation_data</span><span class="p">:</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">validation_data</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">"./traffic-signs-data/test.p"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">testing_data</span><span class="p">:</span>
    <span class="n">test</span> <span class="o">=</span> <span class="n">pickle</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">testing_data</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s">'features'</span><span class="p">],</span> <span class="n">train</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span>
<span class="n">X_validation</span><span class="p">,</span> <span class="n">y_validation</span> <span class="o">=</span> <span class="n">valid</span><span class="p">[</span><span class="s">'features'</span><span class="p">],</span> <span class="n">valid</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s">'features'</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="s">'labels'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (34799, 32, 32, 3)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (34799,)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">i</span> <span class="o">=</span> <span class="mi">1001</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="c1"># show the image
</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180631134-45a40a80-e0a0-4953-a1bb-753178210aae.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    36
</code></pre></div></div>

<p>ìƒê¸° ê²°ê³¼ì—ì„œ í•´ë‹¹ ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ëŠ” 36ìœ¼ë¡œ, ì´ëŠ” â€˜Go straight or rightâ€™ì— í•´ë‹¹ëœë‹¤. <span style="color: blue">The result shows the image has its index , which corresponds to â€˜Go straight or rightâ€™</span></p>

<h1 id="image-preprocessing">Image Preprocessing</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## Shuffle the dataset
</span><span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

</code></pre></div></div>

<p>ìƒê¸° ì½”ë“œì—ì„œ ì´ë¯¸ì§€ ìˆœì„œì— ê¸°ë°˜í•œ ê³¼ì í•©ì„ ë°©ì§€í•˜ê³ ì ì´ë¯¸ì§€ ì…”í”Œì„ ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ í•´ì¤˜ì•¼ í•œë‹¤. <span style="color: blue">Shuffling the image dataset to avoid overfitting by order of images</span></p>

<p>ê·¸ë ‡ì§€ ì•Šìœ¼ë©´, ëª¨ë¸ì´ ë§¤ë²ˆ ê°™ì€ ìˆœì„œì˜ ì´ë¯¸ì§€ë“¤ì„ í•™ìŠµí•˜ì—¬ ê·¸ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ ê³¼ëŒ€ í•™ìŠµì´ ì´ë£¨ì–´ì§ˆ ê²ƒì´ë‹¤. <span style="color: blue">Otherwise, the model will inevitably face overfitting</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Color image--&gt; dark image (integrating into one RGB channel)
</span><span class="n">X_train_gray</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">X_train</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># ì‹¤ì œ ì´ë¯¸ì§€ ì°¨ì›ì„ ê·¸ëŒ€ë¡œ ìœ ì§€ Keep the image's dimension
</span><span class="n">X_test_gray</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">X_test</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_validation_gray</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">X_validation</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> 
</code></pre></div></div>

<p>ìƒ‰ìƒë•Œë¬¸ì— ë¶„ë¥˜ê°€ í—·ê°ˆë¦¬ì§€ ì•Šê²Œ í•˜ê¸°ìœ„í•´ì„œ RGBë¥¼ í‘ë°±ìœ¼ë¡œ í†µì¼í•œë‹¤. <span style="color: blue">Integrating into one RGB channel (dark)</span></p>

<p>np.sum()</p>
<ul>
  <li><em>[axis]</em>(https://stackoverflow.com/questions/51628437/compute-the-sum-of-the-red-green-and-blue-channels-using-python): íŠ¹ì • ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œë§Œ í•©ê³„ë¥¼ êµ¬í•˜ê¸° <span style="color: blue">summation based on certain axis</span>
    <ul>
      <li>i.e, (34799, 32, 32, 3) â€“&gt; axis=2 &lt;=&gt; 32, axis=3 &lt;=&gt; 3. Thus, â€˜axis=3â€™ performs summation based on RGB</li>
    </ul>
  </li>
  <li>keepdims: ì°¨ì› ìœ ì§€í•˜ì—¬ í•©ê³„ êµ¬í•˜ê¸° <span style="color: blue">Find the sum, keeping the dimension</span>
    <ul>
      <li>ê¸°ì¡´ ì°¨ì›ì´ nì¼ ë•Œ, axisëŠ” n-1ì˜ ì°¨ì›ì„ ë°°ì¶œí•œë‹¤. ë”°ë¼ì„œ, keepdims=Trueë¥¼ í†µí•˜ì—¬ n ì°¨ì›ì„ ë°°ì¶œí•˜ê²Œ í•œë‹¤. <span style="color: blue">If original dimension is n, axis will produce n-1 dimensions. â€˜keepdims=Trueâ€™ makes it possible to produce n dimensions</span></li>
    </ul>
  </li>
</ul>

<blockquote>
  <p>RGBëŠ” 3ê°œì˜ ì±„ë„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë¯€ë¡œ; ì´ë¯¸ì§€ ë°ì´í„°ì˜ RGB ê°’ë“¤ì„ ì´ í•©í•œ ë‹¤ìŒ 3ìœ¼ë¡œ ë‚˜ëˆ„ë©´ ìƒ‰ê¹”ì´ ì œê±°ëœë‹¤. <span style="color: blue">RGB consists of three channels; summing all RGB values then dividing the sum by 3</span></p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># normalization
</span><span class="n">X_train_gray_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train_gray</span> <span class="o">-</span> <span class="mi">128</span><span class="p">)</span><span class="o">/</span><span class="mi">128</span> 
<span class="n">X_test_gray_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test_gray</span> <span class="o">-</span> <span class="mi">128</span><span class="p">)</span><span class="o">/</span><span class="mi">128</span>
<span class="n">X_validation_gray_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_validation_gray</span> <span class="o">-</span> <span class="mi">128</span><span class="p">)</span><span class="o">/</span><span class="mi">128</span>
</code></pre></div></div>

<blockquote>
  <p>ì™œ â€˜128â€™ì´ë¼ëŠ” ìˆ«ìë¡œ ì •ê·œí™”í•˜ëŠ”ê±¸ê¹Œ? <span style="color: blue">Why normalizing the dataset with 128? </span></p>

  <blockquote>
    <p>ì¼ë°˜ì ìœ¼ë¡œ ì •ê·œí™”ì— 128 í˜¹ì€ 256 ì‚¬ìš© å¤š <span style="color: blue"> Generally using 128 or 256 as a normalizing parameter</span></p>
  </blockquote>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># data visualization
</span><span class="n">i</span> <span class="o">=</span> <span class="mi">610</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train_gray</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

</code></pre></div></div>

<p>[<em>dark</em>]</p>

<p><img src="https://user-images.githubusercontent.com/39285147/180631744-3e9ec0da-7271-408a-983a-4f329a148234.png" alt="image" /></p>

<p>[<em>original</em>]</p>

<p><img src="https://user-images.githubusercontent.com/39285147/180631746-cc3638e8-b277-4351-993b-1f96434d8825.png" alt="image" /></p>

<blockquote>
  <p><em>squeeze</em>:  [[1, 2, 3, 4]] â€“&gt; [1, 2, 3, 4]</p>
</blockquote>

<h1 id="training-the-dataset">Training the dataset</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading the dataset
</span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> <span class="n">AveragePooling2D</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">TensorBoard</span>

<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Building the model
</span><span class="n">cnn_model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">AveragePooling2D</span><span class="p">())</span>

<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">AveragePooling2D</span><span class="p">())</span>

<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">())</span>

<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>

<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">84</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>

<span class="n">cnn_model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">43</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">'softmax'</span><span class="p">))</span>

</code></pre></div></div>

<blockquote>
  <p><a href="#learning-goals">How to Build Le-Net?</a></p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Training the model
</span><span class="n">cnn_model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span> <span class="o">=</span><span class="s">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span><span class="n">metrics</span> <span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<p>compile()</p>
<ul>
  <li><em>sparse_categorical_crossentropy</em>: ì†ì‹¤ ë²”ì£¼í˜• êµì°¨ì—”íŠ¸ë¡œí”¼ë¡œ ë¶„ë¥˜ì— ì‚¬ìš©ëœë‹¤. <span style="color: blue">used for classification</span>
    <ul>
      <li>í´ë˜ìŠ¤ê°€ ë‘ ê°œë°–ì— ì—†ë‹¤ë©´ ì´ì§„ êµì°¨ì—”íŠ¸ë¡œí”¼(â€˜binary_categorical_crossentropyâ€™)ë¥¼ ì‚¬ìš©í•œë‹¤. <span style="color: blue">â€˜binary_categorical_crossentropyâ€™ is used for binary tasks </span></li>
    </ul>
  </li>
  <li><a href="https://github.com/hchoi256/lg-ai-auto-driving-radar-sensor/blob/main/supervised-learning/gradient-discent.md">Adam</a>
    <ul>
      <li>lr: í•™ìŠµë¥  (learning rate)</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_gray_norm</span><span class="p">,</span>
                        <span class="n">y_train</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                        <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_validation_gray_norm</span><span class="p">,</span><span class="n">y_validation</span><span class="p">))</span> <span class="c1"># Adding validation set, test set
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Epoch 50/50
    34799/34799 [==============================] - 13s 364us/step - loss: 0.0255 - acc: 0.9951 - val_loss: 0.7429 - val_acc: 0.8624
</code></pre></div></div>

<h1 id="evaluating-the-model-performance">Evaluating the model performance</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">score</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_gray_norm</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Test Accuracy : {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">score</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Test Accuracy : 0.8611
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="n">keys</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Accuracy distribution
</span><span class="n">accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'acc'</span><span class="p">]</span>
<span class="n">val_accuracy</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_acc'</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">]</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="s">'bo'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Accuracy'</span><span class="p">)</span> <span class="c1"># 'bo': íŒŒë€ X, Y ì  blue X, Y points
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_accuracy</span><span class="p">,</span> <span class="s">'b'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation Accuracy'</span><span class="p">)</span> <span class="c1"># 'b': íŒŒë€ì„  blue lines
</span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training and Validation accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180636372-f48db725-e8ca-4d6f-a031-22761b99b2a1.png" alt="image" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># loss distribution
</span><span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Training Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s">'r'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Validation Loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Training and validation loss'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180636376-57811f95-d13c-42cf-8c3c-b526790ea1dc.png" alt="image" /></p>

<h1 id="prediction">Prediction</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get the predictions for the test data
</span><span class="n">predicted_classes</span> <span class="o">=</span> <span class="n">cnn_model</span><span class="p">.</span><span class="n">predict_classes</span><span class="p">(</span><span class="n">X_test_gray_norm</span><span class="p">)</span>

<span class="c1"># predicted vs. actual
</span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predicted_classes</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">25</span><span class="p">,</span><span class="mi">25</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180636509-7a29b79a-1658-450c-af6f-71b5e2889b30.png" alt="image" /></p>

<p>í˜¼ë™í–‰ë ¹ì—ì„œ ëŒ€ê°ì„ ì´ ì•„ë‹Œ ìœ„ì¹˜ì— ì†í•œ ìˆ˜ì¹˜ê°’ë“¤ì€ ì˜¤ë¶„ë¥˜ ê°œìˆ˜ì´ë‹¤. <span style="color: blue">The elements not on the diagonal line represent the number of errors</span></p>

<p>ì˜ˆì¸¡ê°’ì„ ë§Œë“¤ì–´ëƒˆìœ¼ë‹ˆ, ì‹¤ì œê°’ë“¤ê³¼ ë¹„êµí•˜ê¸° ìœ„í•´ 7x7 ê·¸ë¦¬ë“œì— 49ê°œì˜ ëœë¤ ì´ë¯¸ì§€ë¥¼ ë‚˜ì—´í•´ì„œ í™•ì¸í•´ë³´ì. <span style="color: blue">Letâ€™s lay out the 7x7 grid of randomly generated images so that we can intuitively compare estimates with answers</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">L</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">W</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="p">.</span><span class="n">ravel</span><span class="p">()</span> <span class="c1"># flatten the array
</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span> <span class="o">*</span> <span class="n">W</span><span class="p">):</span>  
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Prediction={}</span><span class="se">\n</span><span class="s"> True={}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">predicted_classes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_true</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">axis</span><span class="p">(</span><span class="s">'off'</span><span class="p">)</span> <span class="c1"># remove axis
</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># space out images
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180636517-bca07edb-4d29-4bf4-a4ae-4bd927e5c7b2.png" alt="image" /></p>

<blockquote>
  <p><a href="https://m.blog.naver.com/wideeyed/221533365486">ravel() vs. reshape() vs. flatten()</a></p>
</blockquote>
:ET