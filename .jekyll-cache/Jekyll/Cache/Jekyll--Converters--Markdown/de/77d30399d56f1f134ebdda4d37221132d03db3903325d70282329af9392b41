I"?—<h1 id="learning-goals">Learning Goals</h1>

<p>ì „ì´í•™ìŠµì„ ì–´ë–»ê²Œ ìš°ë¦¬ì˜ taskì— ë§ê²Œ ì´ìš©í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³¸ë‹¤. <span style="color: blue">Letâ€™s see how transfer learning can be used for our tasks. </span></p>

<p>ê°€ë ¹, ìš°ë¦¬ëŠ” ìˆ˜ë§ì€ ì‚¬ëŒì˜ ì–¼êµ´ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ëª¨ë¸ì„ ì „ì´í•™ìŠµìœ¼ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤. <span style="color: blue"> For example, we can load a model that learned face data from a large number of people (transfer learning). </span></p>

<p>ì´í›„, ìš°ë¦¬ íšŒì‚¬ ë¶€ì„œ ì‚¬ëŒ ëª‡ëª…ì„ ê·¸ ëª¨ë¸ì˜ output layerì— í´ë˜ìŠ¤ë¡œì¨ í• ë‹¹í•˜ë©´, ì˜ˆì¸¡ ê²°ê³¼ë¡œ ì£¼ì–´ì§„ ë¶€ì„œ ì‚¬ëŒë“¤ ì–¼êµ´ ì¤‘ ê°€ì¥ ë¹„ìŠ·í•œ ì‚¬ëŒ ì–¼êµ´ì„ ê²°ê³¼ë¡œì¨ ë°°ì¶œí•  ê²ƒì´ë‹¤. <span style="color: blue"> After that, if we set a few people from our companyâ€™s department as classes to the output layer of the model, the most similar personâ€™s face will be the prediction result. </span></p>

<p>ê·¸ë ‡ë‹¤ë©´, ë‚´ê°€ ìˆ˜í–‰í•˜ë ¤ëŠ” taskì— ë§ëŠ” ì‚¬ì „í•™ìŠµ ëª¨ë¸ì€ ì–´ë–»ê²Œ ì°¾ì•„ì˜¬ê¹Œ (ê°€ë ¹, ì‚¬ëŒ ì–¼êµ´ í•™ìŠµí•œ ëª¨ë¸)? <span style="color: blue"> Then, how can we download the pre-trained model suitable for our task (i.e., a model that learned face data)?  </span></p>

<p>â€˜<strong><em>TensorFlow Hub</em></strong>â€˜ë¼ëŠ” ì‚¬ì´íŠ¸ëŠ” ë‹¤ì–‘í•œ ì‚¬ì „í•™ìŠµ ëª¨ë¸ì„ ì œê³µí•œë‹¤. <span style="color: blue"> â€˜TensorFlow Hubâ€™ provides diverse pre-trained models. </span></p>

<p>ê°€ë ¹, ëª¨ë°”ì¼ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê³ ì ì´ì™€ ê´€ë ¨ëœ ì‚¬ì „ ëª¨ë¸ì¸ â€˜<em>MobileNet</em>â€˜ì„ ì „ì´í•™ìŠµí•´ë³´ì. <span style="color: blue"> Letâ€™s load a pre-trained model â€˜<em>MobileNet</em>â€™ that trained miscellaneous mobile data. </span></p>

<h1 id="example-1-identifying-watch">Example 1: Identifying â€˜Watchâ€™</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading the pre-trained model
</span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">tensorflow_hub</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="n">hub</span>

<span class="n">Trained_MobileNet_url</span> <span class="o">=</span> <span class="s">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Building the model
</span><span class="n">Trained_MobileNet</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">Trained_MobileNet_url</span><span class="p">,</span> <span class="n">input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="p">])</span>

<span class="n">Trained_MobileNet</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Model: "sequential"
    _________________________________________________________________
    Layer (type)                Output Shape              Param #   
    =================================================================
    keras_layer (KerasLayer)    (None, 1001)              3540265   
                                                                    
    =================================================================
    Total params: 3,540,265
    Trainable params: 0
    Non-trainable params: 3,540,265
    _________________________________________________________________
</code></pre></div></div>

<p>MobileNet ëª¨ë¸ì„ ê°€ì ¸ì™€ ìš°ë¦¬ì˜ ëª©ì ì— ë§ê²Œ ë§ˆì§€ë§‰ ë ˆì´ì–´ë§Œ í•˜ë‚˜ ì¶”ê°€í–ˆë‹¤. <span style="color: blue"> We took the MobileNet model and added just one last layer for our purposes. </span></p>

<p>ì´ì œ ì´ ëª¨ë¸ì— ì´ë¯¸ì§€ë¥¼ ë„£ì–´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•´ë³´ì.  <span style="color: blue"> Now letâ€™s put an image into this model. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predicting the image
</span><span class="n">Sample_Image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="s">"watch.jpg"</span><span class="p">,</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182831989-d3678292-8342-4652-adf4-251ec039a67a.png" alt="image" /></p>

<p>TensorFlowì—ì„œ ì œê³µí•˜ëŠ” ì´ë¯¸ì§€ ë°ì´í„° í•˜ë‚˜ë¥¼ ëŒê³ ì™”ë‹¤. <span style="color: blue"> We are using one image data provided by TensorFlow. </span></p>

<p>ì‹ ê²½ë§ í•™ìŠµì„ ìœ„í•´ ì•Œë§ì€ í˜•íƒœë¡œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë³€í™˜ì‹œì¼œì£¼ì. <span style="color: blue"> Letâ€™s transform the image data into an appropriate form for neural network training. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Sample_Image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">Sample_Image</span><span class="p">)</span> <span class="c1"># to ndarray
</span><span class="n">Sample_Image</span> <span class="o">=</span> <span class="n">Sample_Image</span> <span class="o">/</span> <span class="mf">255.0</span> <span class="c1"># normalization
</span><span class="n">Sample_Image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">Sample_Image</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># (224, 224, 3) --&gt; (1, 224, 224, 3)
</span><span class="n">Sample_Image</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (1, 224, 224, 3)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_class</span> <span class="o">=</span> <span class="n">Trained_MobileNet</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Sample_Image</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">)</span>
<span class="n">predicted_class</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    array([[ 0.31899276,  0.69766045, -0.4810167 , ...,  0.22585514,
    -1.4412354 , -0.02521752]], dtype=float32)

    (1, 1001)
</code></pre></div></div>

<p>ImageNetì€ ì„œë¡œ ë‹¤ë¥¸ í´ë˜ìŠ¤ 1001ê°œì— ëŒ€í•œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ í•™ìŠµí•œ ëª¨ë¸ì´ë‹¤. <span style="color: blue"> ImageNet is a model trained on image data for 1001 different classes. </span></p>

<blockquote>
  <p>ImageNet dataset has â€˜1001â€™ classes</p>
</blockquote>

<p>ì´ì œ, ì´ 1001ê°œì˜ í´ë˜ìŠ¤ ì¤‘ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ì—°ê´€ì„±ì„ ê°€ì§€ëŠ” í´ë˜ìŠ¤ ì´ë¦„ì„ ê°€ì ¸ì™€ë³´ì. <span style="color: blue"> Now, letâ€™s get the class name with the highest probability of association among these 1001 classes predicted by the model. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_class</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    827
</code></pre></div></div>

<p>ìš°ë¦¬ ëª¨ë¸ì€ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 827ë²ˆì„ ì°¨ì§€í•˜ëŠ” ê²ƒì´ ì¸í’‹ ì‚¬ì§„ì˜ í´ë˜ìŠ¤ë¼ê³  ì˜ˆì¸¡í–ˆë‹¤. <span style="color: blue"> Our model predicted that the class occupying class index 827 is the class of the input picture.</span></p>

<p>ì—¬ê¸°ì„œ MobileNet ì‚¬ì´íŠ¸ì— ë“¤ì–´ê°€ë³´ë©´, ì´ ëª¨ë¸ì€ ImageNet ë°ì´í„°ì…‹ì— ê¸°ë°˜í•´ì„œ í•™ìŠµì„ ìˆ˜í–‰í–ˆë‹¤.  <span style="color: blue"> If you go to the MobileNet site, the model was trained based on the ImageNet dataset. </span></p>

<p>ë”°ë¼ì„œ, ìš°ë¦¬ëŠ” ImageNet ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 827ì„ í™•ì¸í•´ì•¼ í•œë‹¤. <span style="color: blue"> Therefore, we need to check the class index 827 of the ImageNet dataset. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">labels_path</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">get_file</span><span class="p">(</span><span class="s">"ImageNetLabels.txt"</span><span class="p">,</span> <span class="s">"https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt"</span><span class="p">)</span> <span class="c1"># loading the dataset from the website
</span>
<span class="n">imagenet_labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span> <span class="nb">open</span><span class="p">(</span><span class="n">labels_path</span><span class="p">).</span><span class="n">read</span><span class="p">().</span><span class="n">splitlines</span><span class="p">()</span> <span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">imagenet_labels</span><span class="p">)</span>
<span class="n">imagenet_labels</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    array(['background', 'tench', 'goldfish', ..., 'bolete', 'ear',
   'toilet tissue'], dtype='&lt;U30')

   (1001,)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_class_name</span> <span class="o">=</span> <span class="n">imagenet_labels</span><span class="p">[</span><span class="n">predicted_class</span><span class="p">]</span>
<span class="n">predicted_class_name</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    'watch'
</code></pre></div></div>

<p>ëª¨ë¸ì´ ë§ê²Œ ì˜ˆì¸¡í•œ ëª¨ìŠµì´ë‹¤. <span style="color: blue"> Our model got the correct answer. </span></p>

<p>í•˜ì§€ë§Œ, ì‹œê³„ëŠ” ì‚¬ì‹¤ ImageNet dataset ì•ˆì— í¬í•¨ëœ í•™ìŠµ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¡œ, ì „ì´í•™ìŠµìœ¼ë¡œ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì€ ì´ë¯¸ ì‹œê³„ì— ëŒ€í•œ ë¶„ë¥˜ë¥¼ ì˜í•œë‹¤.  <span style="color: blue"> However, â€˜clockâ€™ is actually one of the classes included in the ImageNet dataset, and the model imported by transfer learning is already good at classifying clocks. </span></p>

<p>ë§Œì•½, ê·¸ ëª¨ë¸ì´ í•œ ë²ˆë„ ë¶„ë¥˜í•´ë³´ì§€ ëª»í•œ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•´ì•¼ í•˜ëŠ” ìƒˆë¡œìš´ ì´ë¯¸ì§€ê°€ ì£¼ì–´ì§„ë‹¤ë©´ ì£¼ì–´ì§„ í´ë˜ìŠ¤ í’€ ì•ˆì—ì„œ ê·¸ë‚˜ë§ˆ ë¹„ìŠ·í•œ ì´ìƒí•œ ë‹µì„ ë„ì¶œí•  ê²ƒì´ë‹¤.  <span style="color: blue"> If given a new image that the model should classify into a class that it has never classified before, it will derive a similar but strange answer within the given class pool. </span></p>

<h1 id="example-2-classifying-flower">Example 2: Classifying â€˜Flowerâ€™</h1>

<p>ì´ë²ˆì—ëŠ” ì´ ëª¨ë¸ì—ê²Œ TensorFlow ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì™„ì „íˆ ìƒˆë¡œìš´ ê½ƒ ì‚¬ì§„ í•˜ë‚˜ë¥¼ ê°€ì ¸ì™€ì„œ ê¸°ì¡´ ëª¨ë¸ì— ì˜ˆì¸¡ì‹œì¼œë³´ì. <span style="color: blue"> This time, letâ€™s get this model an entirely new picture of a flower from the TensorFlow library and make predictions on the old model. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading the dataset of flowers
</span><span class="n">flowers_data_url</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">get_file</span><span class="p">(</span><span class="s">"flower_photos"</span><span class="p">,</span> <span class="s">"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz"</span><span class="p">,</span> <span class="n">untar</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span> <span class="c1"># auto-untar when loading
</span>
<span class="c1"># adjusting the image
</span><span class="n">image_generator</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">ImageDataGenerator</span><span class="p">(</span><span class="n">rescale</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span> <span class="c1"># scale to fit 255 pixels
</span>
<span class="n">flowers_data</span> <span class="o">=</span> <span class="n">image_generator</span><span class="p">.</span><span class="n">flow_from_directory</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">flowers_data_url</span><span class="p">),</span> <span class="n">target_size</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>â€˜image_generator.flow_from_directoryâ€™ë¥¼ í™œìš©í•˜ì—¬ í•œ batch(ë¬¶ìŒ)ì— 64ê°œì˜ 224x224 ì‚¬ì´ì¦ˆ ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ì§‘í•©ì„ ë§Œë“¤ì—ˆë‹¤. <span style="color: blue"> Making a batch with 64 images of 224x224 using â€˜image_generator.flow_from_directoryâ€™. </span></p>

<p>ì—¬ê¸°ì„œ <em>shuffle</em>ì€ ë§¤ë²ˆ ì´ë¯¸ì§€ë¥¼ ì„ì–´ì„œ ëª¨ë¸ì´ ê°™ì€ ìˆœì„œë¡œ ê°™ì€ ì´ë¯¸ì§€ë¥¼ ë§¤ë²ˆ í•™ìŠµí•˜ëŠ” ë¶ˆìƒì‚¬ë¥¼ í”¼í•˜ê¸° ìœ„í•¨ì´ë‹¤. <span style="color: blue"> We set <em>shuffle</em> to True so that our model wonâ€™t train the images in the same order. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">flowers_data_input_batch</span><span class="p">,</span> <span class="n">flower_data_label_batch</span> <span class="ow">in</span> <span class="n">flowers_data</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Image batch shape"</span><span class="p">,</span> <span class="n">flowers_data_input_batch</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Label batch shape"</span><span class="p">,</span> <span class="n">flower_data_label_batch</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">break</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Image batch shape (64, 224, 224, 3)
    Label batch shape (64, 5)
</code></pre></div></div>

<p>64ê°œì˜ ê½ƒ ì´ë¯¸ì§€ ì‚¬ì§„ì´ ì£¼ì–´ì¡Œê³ , ê·¸ë“¤ì€ 5ê°œì˜ í´ë˜ìŠ¤ë¡œ ê°ê° ë¶„ë¥˜ë˜ì–´ì•¼ í•œë‹¤. <span style="color: blue"> 64 flower image pictures were given, and they should each be classified into 5 classes. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predicing the image
</span><span class="n">predictions_batch</span> <span class="o">=</span> <span class="n">Trained_MobileNet</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">flowers_data_input_batch</span><span class="p">)</span>
<span class="n">predictions_batch</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    2/2 [==============================] - 2s 2s/step

    (64, 1001)
</code></pre></div></div>

<p>ì•ì„œ ì „ì´í•™ìŠµì„ í†µí•´ ë¶ˆëŸ¬ì˜¨ MobileNet ëª¨ë¸ì„ í™œìš©í•´ì„œ ê½ƒ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•´ë³´ì. <span style="color: blue"> Letâ€™s classify flower images using the MobileNet model loaded through transfer learning. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_class_name</span> <span class="o">=</span> <span class="n">imagenet_labels</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions_batch</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)]</span>
</code></pre></div></div>

<p>ì—¬ê¸°ì„œ â€˜axis=-1â€™ ì€ 64ê°œì˜ í–‰(=ì´ë¯¸ì§€ ê°œìˆ˜) ê°ê°ì— ëŒ€í•œ ì—´(ë°ì´í„°)ë“¤ ì¤‘ì—ì„œ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ë¼ëŠ” ë§ì´ë‹¤. <span style="color: blue"> Here, â€˜axis=-1 â€˜means to get the index of the largest value among the columns (data) belonging to 64 rows (= number of images). </span></p>

<p>ë¬´ìŠ¨ ë§ì¸ì§€ í—·ê°ˆë¦°ë‹¤ë©´ ì•„ë˜ ì˜ˆì‹œë¥¼ ë³´ì. <span style="color: blue"> If you are still confused, donâ€™t worry and look at the following example. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="o">+</span> <span class="mi">10</span>
<span class="k">print</span><span class="p">(</span><span class="n">a</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Max elements"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Max elements"</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[10 11 12]
    [13 14 15]
    [16 17 18]
    [19 20 21]]
    Max elements [3 3 3]
    Max elements [2 2 2 2]
</code></pre></div></div>

<p>ì´ ì˜ˆì‹œëŠ” 4ê°œì˜ í–‰ì„ ê°€ì§€ê³  ìˆê³ , ê° í–‰ì—ì„œ ê°€ì¥ í° ë°ì´í„°ì˜ ì¸ë±ìŠ¤ë¥¼ ê°€ì ¸ì˜¨ë‹¤. <span style="color: blue"> This example has 4 rows, and in each row we get the index of the biggest data. </span></p>

<p>â€˜axis=0â€™ì´ë¼ë©´, <strong>ì„¸ë¡œ</strong>ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ë ¹ â€˜10 13 16 19â€™ ì¤‘ì—ì„œ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ì¸ 3ì„ ê°€ì ¸ì˜¨ë‹¤. <span style="color: blue"> If â€˜axis=0â€™, for example, 3, the index of the largest value among â€˜10 13 16 19â€™, is taken based on the vertical. </span></p>

<p>ë°˜ëŒ€ë¡œ â€˜axis=-1â€™ì´ë¼ë©´, <strong>ê°€ë¡œ</strong>ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê°€ë ¹ â€˜10 11 12â€™ ì¤‘ì—ì„œ ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ì¸ 2ì„ ê°€ì ¸ì˜¨ë‹¤. <span style="color: blue"> If â€˜axis=-1â€™, for example, 2, the index of the largest value among â€˜10 11 12â€™, is taken based on the horizontal. </span></p>

<blockquote>
  <p>â€˜axis=1â€™ is same as â€˜axis=-1â€™ in this example.</p>
</blockquote>

<p>ì, ì´ì œ ì›ë˜ ë¬¸ì œë¡œ ëŒì•„ì™€ì„œ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì´ë¦„ì„ í™•ì¸í•´ë³´ì. <span style="color: blue"> Now, back to the original problem, letâ€™s check the prediction class name. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_class_name</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    array(['daisy', 'rapeseed', 'feather boa', 'tray', 'daisy', 'bonnet',
        'daisy', 'daisy', 'barrow', 'picket fence', 'buckeye', 'orange',
        'daisy', 'jackfruit', 'bonnet', 'sea urchin', 'picket fence',
        'daisy', 'sea urchin', 'daisy', 'chainlink fence', 'daisy',
        'daisy', 'picket fence', 'picket fence', 'head cabbage', 'daisy',
        'daisy', 'bakery', 'red-backed sandpiper', 'vase', 'sea urchin',
        'daisy', 'teddy', 'cardoon', 'vase', 'daisy', 'daisy', 'daisy',
        'bee', 'daisy', 'strawberry', 'rapeseed', 'cauliflower', 'bakery',
        'quill', 'oxcart', 'vine snake', 'artichoke', 'pot', 'monarch',
        'daisy', 'spindle', 'chime', 'volcano', 'velvet', 'quill', 'daisy',
        'picket fence', 'cardoon', 'daisy', 'daisy', 'picket fence', 'hip'],
        dtype='&lt;U30')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">flowers_data_input_batch</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">predicted_class_name</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182841799-08d3230c-52b2-40ef-a6c3-4732921e8642.png" alt="image" /></p>

<p>64ê°œì˜ ê½ƒ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í–ˆë‹¤. <span style="color: blue"> The prediction results of the model for 64 flower images were visualized. </span></p>

<p>ê°€ì¥ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ë¶„ë¥˜ë§Œ ë´ë„ ê²°ê³¼ê°€ ì´ìƒí•˜ë‹¤. <span style="color: blue"> Just looking at the first image classification, the result is strange. </span></p>

<p>â€˜í•´ë°”ë¼ê¸°â€™ ì‚¬ì§„ì— ëŒ€í•˜ì—¬ â€˜ë°ì´ì§€â€™ë¼ëŠ” ì˜ëª»ëœ ë¶„ë¥˜ ê²°ê³¼ê°€ ë‚˜íƒ€ë‚¬ë‹¤. <span style="color: blue"> Misclassified â€˜Sunflowerâ€™ as â€˜Daisyâ€™ </span></p>

<p>ì•„ë§ˆ, ImageNet datasetì—ì„œ í•™ìŠµí•œ ëª‡ëª‡ì˜ ê½ƒ ê´€ë ¨ ì‚¬ì§„ë“¤ì€ â€˜í•´ë°”ë¼ê¸°â€™ í´ë˜ìŠ¤ê°€ ì—†ì–´ì„œ â€˜ë°ì´ì§€â€™ë¼ëŠ” ê½ƒìœ¼ë¡œ ë¶„ë¥˜ëœ ê²ƒ ê°™ë‹¤. <span style="color: blue"> Perhaps, some flower-related pictures learned from the ImageNet dataset are classified as a flower called â€˜daisyâ€™ because there was no class â€˜sunflowerâ€™. </span></p>

<p>ìš°ë¦¬ëŠ” â€˜ë°ì´ì§€â€™ê°€ ì•„ë‹Œ â€˜í•´ë°”ë¼ê¸°â€™ë¡œ í•´ë‹¹ ì´ë¯¸ì§€ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ê³ ì‹¶ë‹¤. <span style="color: blue"> We would like to see the predictions for that image as sunflowers, not daisies. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MobileNet_feature_extractor_url</span> <span class="o">=</span> <span class="s">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"</span> <span class="c1"># base model
</span>
<span class="n">MobileNet_feature_extractor_layer</span> <span class="o">=</span> <span class="n">hub</span><span class="p">.</span><span class="n">KerasLayer</span><span class="p">(</span><span class="n">MobileNet_feature_extractor_url</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="c1"># convert images to a form of 224x224x3
</span>
<span class="n">feature_batch</span> <span class="o">=</span> <span class="n">MobileNet_feature_extractor_layer</span><span class="p">(</span><span class="n">flowers_data_input_batch</span><span class="p">)</span> <span class="c1"># apply the flower images we want to predict
</span>
<span class="n">feature_batch</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    TensorShape([64, 1280])
</code></pre></div></div>

<p>ì•„ê¹Œì™€ ê°™ì€ 64ê°œì˜ ê½ƒ ì‚¬ì§„ë“¤ì„ 1280ê°œì˜ í´ë˜ìŠ¤ë¡œ êµ¬ë¶„í•˜ëŠ” base modelì´ë‹¤. <span style="color: blue"> This is a base model that identifies the previous 64 flower photos into 1280 classes. </span></p>

<p>â€˜MobileNet_feature_extractor_layerâ€™ì— base modelì˜ ì‹ ê²½ë§ì„ ì €ì¥í•˜ê³ , ì°¨í›„ì— output layerë§Œ ì¶”ê°€í•˜ì—¬ ìš°ë¦¬ê°€ ì›í•˜ëŠ” 5ê°œ í´ë˜ìŠ¤ ë‚´ë¡œ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆê²Œ ë§Œë“¤ì. <span style="color: blue"> Letâ€™s save the neural network of the base model in â€˜MobileNet_feature_extractor_layerâ€™ and add only an output layer later so that we can see the prediction results in the 5 classes we want. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MobileNet_feature_extractor_layer</span><span class="p">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="bp">False</span> <span class="c1"># not modifying base model's parameters
</span>
<span class="k">print</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">.</span><span class="n">num_classes</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">MobileNet_feature_extractor_layer</span><span class="p">,</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">.</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"softmax"</span><span class="p">)</span>
<span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    5


    Model: "sequential_1"
    _________________________________________________________________
    Layer (type)                Output Shape              Param #   
    =================================================================
    keras_layer_1 (KerasLayer)  (None, 1280)              2257984   
                                                                    
    dense (Dense)               (None, 5)                 6405      
                                                                    
    =================================================================
    Total params: 2,264,389
    Trainable params: 6,405
    Non-trainable params: 2,257,984
    _________________________________________________________________
</code></pre></div></div>

<p>base modelê°€ í•™ìŠµí•˜ì—¬ ì–»ì€ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì€ ê·¸ëŒ€ë¡œ ê°€ì ¸ê°€ê³ , ë§ˆì§€ë§‰ì— output layerë§Œ ìˆ˜ì •í•˜ì—¬ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ë„ë¡ í•œë‹¤. <span style="color: blue"> We donâ€™t want to change the weights and biases obtained from the base model and only the output layer to be modified. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"Adam"</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s">"categorical_crossentropy"</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="s">"accuracy"</span><span class="p">])</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">.</span><span class="n">class_indices</span><span class="p">.</span><span class="n">items</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Epoch 1/20
    58/58 [==============================] - 183s 3s/step - loss: 0.8617 - accuracy: 0.6768
    Epoch 2/20
    58/58 [==============================] - 136s 2s/step - loss: 0.4060 - accuracy: 0.8608
    Epoch 3/20
    58/58 [==============================] - 132s 2s/step - loss: 0.3253 - accuracy: 0.8894
    ...
    Epoch 19/20
    58/58 [==============================] - 145s 2s/step - loss: 0.0857 - accuracy: 0.9826
    Epoch 20/20
    58/58 [==============================] - 137s 2s/step - loss: 0.0812 - accuracy: 0.9845


    dict_items([('daisy', 0), ('dandelion', 1), ('roses', 2), ('sunflowers', 3), ('tulips', 4)])
</code></pre></div></div>

<p>ìƒê¸° ê²°ê³¼ì²˜ëŸ¼ ëª¨ë¸ì€ ì´ ë‹¤ì„¯ ê°œì˜ ê½ƒ í´ë˜ìŠ¤ë¡œ ì¸í’‹ ì´ë¯¸ì§€ë“¤ì„ ë¶„ë¥˜í•˜ëŠ” í•™ìŠµì„ ìˆ˜í–‰í•œë‹¤.  <span style="color: blue"> As shown above, the model classifies input images into a total of five flower classes. </span></p>

<p>ì´ì œ ì•„ê¹Œ â€˜í•´ë°”ë¼ê¸°â€™ë¥¼ â€˜ë°ì´ì§€â€™ë¼ ì˜ëª» ë¶„ë¥˜í–ˆë˜ ì˜ˆì¸¡ì´ ì–´ë–»ê²Œ ë°”ë€”ì§€ í™•ì¸í•´ë³´ì.  <span style="color: blue"> Now letâ€™s see how the prediction that our model had previously misclassified sunflowers as daisies would change. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_batch</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">flowers_data_input_batch</span><span class="p">)</span> <span class="c1"># predicing the images
</span><span class="n">predicted_id</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predicted_batch</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># find the index of the most proabable class
</span>
<span class="c1"># get the class names (must be 5 in total)
</span><span class="n">class_names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">.</span><span class="n">class_indices</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span> <span class="p">[</span> <span class="n">key</span><span class="p">.</span><span class="n">title</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">class_names</span> <span class="p">]</span> <span class="p">)</span>

<span class="n">predicted_label_batch</span> <span class="o">=</span> <span class="n">class_names</span><span class="p">[</span><span class="n">predicted_id</span><span class="p">]</span> <span class="c1"># get the name of the class
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">class_names</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">flowers_data</span><span class="p">.</span><span class="n">class_indices</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">pair</span><span class="p">:</span><span class="n">pair</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span> <span class="p">[</span> <span class="n">key</span><span class="p">.</span><span class="n">title</span><span class="p">()</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">class_names</span> <span class="p">]</span> <span class="p">)</span>
<span class="n">class_names</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    array(['Daisy', 'Dandelion', 'Roses', 'Sunflowers', 'Tulips'],
        dtype='&lt;U10')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">64</span><span class="p">):</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">flowers_data_input_batch</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">predicted_label_batch</span><span class="p">[</span><span class="n">n</span><span class="p">].</span><span class="n">title</span><span class="p">())</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s">"off"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182860851-4d9bcd69-e7a3-44b2-950d-783d282b1069.png" alt="image" /></p>

<p>ì´ì œì„œì•¼ â€˜í•´ë°”ë¼ê¸°â€™ë¥¼ ë§ê²Œ ì˜ˆì¸¡í•˜ëŠ” ëª¨ìŠµì´ë‹¤. <span style="color: blue"> Now, our model does the trick in prediction tasks! </span></p>

:ET