I"I<h1 id="learning-goals">Learning Goals</h1>
<p>Transfer Learning 활용 이미지 분류 <span style="color: blue"> Image classification using Transfer Learning </span></p>

<h1 id="transfer-learning">Transfer Learning</h1>
<p>Transfer learning is one of the most important techniques in deep learning.</p>

<p>1) 모델을 만들기 위한 데이터가 있어야 한다. <span style="color: blue"> You must have data to build the model. </span></p>

<p>2) 모델을 만들기 위한 computing 자원이 필요 -&gt; 비용과 시간도 필요하다. <span style="color: blue"> Computing resources are required to create the model -&gt; cost and time are also required. </span></p>

<p>3) 모델 설계 디자인도 직접 해야 한다 -&gt; 전문가와 시간도 필요하다 <span style="color: blue"> You have to do the model design yourself -&gt; Consultation time with Experts required </span></p>

<p><strong>기존의 모델에서 잘 하는 부분을 우리만의 새로운 모델로 만드는 것! -&gt; 우리의 데이터로 모델을 새로 학습시킨다!</strong> <span style="color: blue"> Using good parts of the original model for building our own new model -&gt; From pre-trained model to new model with my data. </span></p>

<p>전이학습은 딥러닝에서 굉장히 중요한 기법중에 하나이다. <span style="color: blue"> Transfer learning is one of the most important techniques in deep learning. </span></p>
<ul>
  <li><strong>Computing 시간을 줄어준다</strong> (기존 모델에 나의 데이터만 학습시키기 때문에) <span style="color: blue"> Saving computing time (Training the existing model with only my data) </span></li>
  <li><strong>적은 데이터로도 정확도를 얻을 수 있다.</strong> <span style="color: blue"> Accuracy can be obtained with little data. </span></li>
</ul>

<h1 id="loading-the-pre-trained-model---imagenet">Loading the pre-trained model - ImageNet</h1>

<!-- 
**[Notice]** [Download Dataset (Kaggle)](https://www.kaggle.com/datasets/zalando-research/fashionmnist)
{: .notice--danger} -->

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">applications</span><span class="p">.</span><span class="n">ResNet50</span><span class="p">(</span><span class="n">weights</span> <span class="o">=</span> <span class="s">"imagenet"</span><span class="p">)</span> <span class="c1"># Loading the other model
</span></code></pre></div></div>

<p>‘ImageNet’이라는 여러 장의 이미지를 학습한 모델의 hyperparameters를 가져온다. <span style="color: blue"> Loading the hyperparameters of the model trained on multiple images called ‘ImageNet’.</span></p>

<p>이후에 소수의 이미지에 대한 학습이 추가된 모델로 활용하고자 한다. <span style="color: blue"> After that, we will use the parameters to build our model. </span></p>

<p>텐서플로우 라이브러리에서 제공해주는 샘플 이미지 몇 장을 가져와서 가져온 모델에 예측시켜보자. <span style="color: blue"> Loading a few sample images from the tensorflow library, we want to predict their class with the model. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_Sample_Image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">load_img</span><span class="p">(</span><span class="s">"cat.282.jpg"</span><span class="p">,</span> <span class="n">target_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>

<span class="n">Sample_Image</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182647167-5a62b1a2-895f-4b06-b17c-8df85a80f855.png" alt="image" /></p>

<p>이제 이미지를 신경망 학습에 용이한 형태로 변환하자. <span style="color: blue"> Now, let’s transform the image into a form that is suitable for neural network training.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_Sample_Image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">preprocessing</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">img_to_array</span><span class="p">(</span><span class="n">new_Sample_Image</span><span class="p">)</span> <span class="c1"># converting to ndarray
</span>
<span class="n">new_Sample_Image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">new_Sample_Image</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># (224, 224, 3) --&gt; (1, 224, 224, 3)
</span>
<span class="n">new_Sample_Image</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">applications</span><span class="p">.</span><span class="n">resnet50</span><span class="p">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">new_Sample_Image</span><span class="p">)</span> <span class="c1"># converting to a form that is suitable for resnet
</span>
<span class="nb">type</span><span class="p">(</span><span class="n">new_Sample_Image</span><span class="p">),</span> <span class="n">new_Sample_Image</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            (numpy.ndarray, (1, 224, 224, 3))
</code></pre></div></div>

<p>이제 해당 이미지를 ResNet 모델의 예측 입력 데이터로 활용할 준비가 끝났다. <span style="color: blue"> Now we are ready to use that image as predictive input data for our ResNet model. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_Sample_Image</span><span class="p">)</span>
<span class="n">predictions</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            (1, 1000)
</code></pre></div></div>

<p>1000개의 이미지 예측 분류 결과가 도출되었다. <span style="color: blue"> 1000 image prediction classification results were derived. </span></p>

<p>이 중에서 가장 연관성이 높은 10개의 결과를 불러와보자. <span style="color: blue"> Let’s recall the 10 most relevant results. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">applications</span><span class="p">.</span><span class="n">resnet50</span><span class="p">.</span><span class="n">decode_predictions</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">top</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            [('n02123045', 'tabby', 0.6685119),
            ('n02123159', 'tiger_cat', 0.20534384),
            ('n04589890', 'window_screen', 0.04501871),
            ('n02124075', 'Egyptian_cat', 0.028584264),
            ('n02127052', 'lynx', 0.0222634),
            ('n02123394', 'Persian_cat', 0.0032146596),
            ('n02125311', 'cougar', 0.0023683226),
            ('n02123597', 'Siamese_cat', 0.0023211897),
            ('n04040759', 'radiator', 0.0019854198),
            ('n03938244', 'pillow', 0.0010624481)]
</code></pre></div></div>

<p>여러 가지 예측 결과 중에서 가장 연관성이 높은 10개를 보여준다. <span style="color: blue"> Among the various prediction results, the 10 most relevant are shown. </span></p>

<p>주어진 인풋 이미지에 대하여 ‘tabby’가 압도적으로 높은 예측 결과률을 보여준다 <span style="color: blue"> For a given input image, ‘tabby’ shows an overwhelmingly high prediction result rate. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            Model: "resnet50"
            __________________________________________________________________________________________________
            Layer (type)                   Output Shape         Param #     Connected to                     
            ==================================================================================================
            input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               
                                            )]                                                                
                                                                                                            
            conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                
                                                                                                            
            conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              
                                            )                                                                 
                                                                                                            
            conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             
                                            )                                                                 
                                                                                                            
            conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               
                                            )                                                                 
                                                                                                            
            pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             
                                            )                                                                 
                                                                                                            
            pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              
                                                                                                            
            conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             
                                                                                                            
            ...
            Total params: 25,636,712
            Trainable params: 25,583,592
            Non-trainable params: 53,120
            __________________________________________________________________________________________________
</code></pre></div></div>

<p>‘include_top=False’를 하면 convolution layer들만 가져오고 그 다음으로 우리가 만들고자 하는 모델에 새로운 Fully Connected Layer를 추가한다. <span style="color: blue"> ‘include_top=False’: Building our model that borrows the convolution layer from the existing model and new fully connected layers. </span></p>

<h1 id="expanding-the-model">Expanding the model</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">.</span><span class="n">output</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">()(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"relu"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s">"softmax"</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">base_model</span><span class="p">.</span><span class="nb">input</span> <span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">preds</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>            181
</code></pre></div></div>

<p>hidden layer 등을 포함하는 모든 레이어 개수가 181개라는 것을 볼 수 있다. <span style="color: blue"> It can be seen that the number of all layers including hidden layers is 181. </span></p>

<p>실제 ImageNet 학습에 소요되는 시간은 어마어마하다. 우리는 그저 그 정보를 이용해 소량의 새로운 이미지와 모델 설계만 추가하여 목적에 맞는 task를 간편하게 완료한다. <span style="color: blue"> The time required for actual ImageNet training is enormous. We simply use that information to add a small number of new images and model designs to easily complete the task for the purpose. </span></p>

<p>이제 이 모델을 가지고 여러 task를 수행하면 된다. <span style="color: blue"> Now we can perform several tasks with this model. </span></p>

<p>지금까지는 전이 학습의 가장 기본적인 학습 구조를 알아보았다. <span style="color: blue"> So far, we have looked at the most basic learning structure of transfer learning. </span></p>

<p>다음 글에서 전이학습을 ‘실질적으로’ 이용하는 법을 알아보자. <span style="color: blue"> In the next article, we will see how to use transfer learning ‘practically’. </span></p>

<h1 id="next-post"><a href="https://hchoi256.github.io/dl/dl-cnn-transfer-learning2/">Next Post</a></h1>
:ET