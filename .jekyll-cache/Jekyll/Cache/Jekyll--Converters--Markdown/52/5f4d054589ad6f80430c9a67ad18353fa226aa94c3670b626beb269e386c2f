I"ª<h1 id="code">Code</h1>
<p class="notice--danger"><strong>[Notice]</strong> <a href="https://github.com/hchoi256/machine-learning-development">download here</a></p>

<h1 id="learning-goals">Learning Goals</h1>
<ol>
  <li><strong>Naive Beyas Theorem</strong>
    <ul>
      <li><em>ë² ì´ì¦ˆ ì •ë¦¬</em>ì— ê¸°ë°˜í•œ ë¶„ë¥˜ ê¸°ìˆ  <span style="color: blue">Classification techniques with beyas theorem</span></li>
    </ul>
  </li>
  <li>ìì—°ì–´ ì²˜ë¦¬ì˜ ê¸°ì´ˆ <span style="color: blue">Understanding NLP</span>
    <ul>
      <li>tokenization with <em>NLTK</em></li>
      <li>Extracting features with <em>Count Vectorizer</em></li>
    </ul>
  </li>
  <li>
    <p>ìš°ë„, ì‚¬ì „ í™•ë¥ , ì£¼ë³€ ìš°ë„ì˜ ì°¨ì´ì  <span style="color: blue">Likelihood, prior, marginal likelihood</span></p>
  </li>
  <li>ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ ë°©ë²• <span style="color: blue">How to handle unbalanced data</span></li>
</ol>

<h1 id="part-1-email-spam-filtering">PART 1: Email Spam Filtering</h1>
<p>ì´ í”„ë¡œì íŠ¸ëŠ” <a href="https://github.com/hchoi256/ai-terms/blob/main/README.md">Naive Beyas Classifier</a>ë¥¼ í™œìš©í•˜ì—¬ SMS ìŠ¤íŒ¸ ë¶„ë¥˜ ë°©ë²•ì„ ì œì‹œí•œë‹¤. <span style="color: blue">Presenting the method of SMS Spam Classification using Naive Beyas Classifier</span></p>

<h2 id="loading-the-dataset">Loading the dataset</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spam_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"emails.csv"</span><span class="p">)</span>
<span class="n">spam_df</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180648071-f7e5cc4d-ef12-457b-8777-bc7419665b16.png" alt="image" /></p>

<h2 id="data-visualization">Data visualization</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># spam 0 or 1
</span><span class="n">ham</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">[</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">]</span><span class="o">==</span><span class="mi">0</span><span class="p">]</span>
<span class="n">spam</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">[</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Visualizing the distribution 
</span><span class="n">spam</span><span class="p">[</span><span class="s">'length'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span> <span class="s">'Spam percentage ='</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">spam</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">spam_df</span><span class="p">)</span> <span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">"%"</span><span class="p">)</span>

<span class="n">ham</span><span class="p">[</span><span class="s">'length'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span> <span class="s">'Ham percentage ='</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ham</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">spam_df</span><span class="p">)</span> <span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">"%"</span><span class="p">)</span>
</code></pre></div></div>

<p>[<em>spam</em>]</p>

<p><img src="https://user-images.githubusercontent.com/39285147/180648230-596590f7-e756-42a4-83a0-92f6bc7cce72.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Spam percentage = 23.88268156424581 %
</code></pre></div></div>

<p>[<em>ham</em>]</p>

<p><img src="https://user-images.githubusercontent.com/39285147/180648232-5b6010a1-797f-4da6-b2c0-d0487d4c1f9c.png" alt="image" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Ham percentage = 76.11731843575419 %
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Count"</span><span class="p">)</span> <span class="c1"># ê° ì¹´í…Œê³ ë¦¬ ê°’ë³„ë¡œ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ìˆëŠ”ì§€ í‘œì‹œ Data distribution by category
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180648340-8fab09eb-0467-4352-9a2e-45bc857caf33.png" alt="image" /></p>

<h2 id="nlp">NLP</h2>

<h3 id="data-preprocessing">Data Preprocessing</h3>
<h4 id="ë¶ˆìš©ì–´-ì œê±°--ì†Œë¬¸ì-í†µì¼í•˜ê¸°-stopwords-and-lowercase">ë¶ˆìš©ì–´ ì œê±° &amp; ì†Œë¬¸ì í†µì¼í•˜ê¸° (Stopwords and lowercase)</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)</span> <span class="c1"># ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° Loading the list of stopwords
</span>
<span class="n">sample_data</span> <span class="o">=</span> <span class="p">[</span><span class="s">'This is the first document.'</span><span class="p">,</span><span class="s">'This document is the second document.'</span><span class="p">,</span><span class="s">'And this is the third one.'</span><span class="p">,</span><span class="s">'Is this the first document?'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ['i',
    'me',
    'my',
    'myself',
    'we',
    'our',
    'ours',
    'ourselves',
    'you',
    "you're",
    "you've",
    "you'll",
    "you'd",
    ...
    "weren't",
    'won',
    "won't",
    'wouldn',
    "wouldn't"]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sample_data</span><span class="p">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)]</span>
</code></pre></div></div>

<h4 id="removing-punctuation">Removing punctuation</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">string</span>
<span class="n">string</span><span class="p">.</span><span class="n">punctuation</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    '!"#$%&amp;\'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~'
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sample_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">sample_data</span> <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">]</span>
</code></pre></div></div>

<h3 id="count-vectorizer">Count Vectorizer</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span> <span class="c1"># Text to number
</span><span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">vectorizer</span><span class="p">.</span><span class="n">get_feature_names</span><span class="p">())</span>

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>  
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[0 1 1 1 0 0 1 0 1]
    [0 2 0 1 0 1 1 0 1]
    [1 0 0 1 1 0 1 1 1]
    [0 1 1 1 0 0 1 0 1]]
</code></pre></div></div>

<p>ìƒ˜í”Œì— ì¡´ì¬í•˜ëŠ” ê° ë‹¨ì–´ë“¤ì´ ì¸ë±ìŠ¤ë¡œì¨ í• ë‹¹ë˜ëŠ” <em>ì¸ì½”ë”©</em> ê³¼ì •ì´ ìˆ˜í–‰ë˜ì—ˆë‹¤. <span style="color: blue">Encoding process is complete.</span></p>

<p>ë¬´ìŠ¨ ë§ì´ëƒë©´, â€˜[0 1 1 1 0 0 1 0 1]â€™ì´ë¼ëŠ” ìˆ«ìí™”ëœ ê°’ì€ í•˜ê¸°ì²˜ëŸ¼ ë§¤ì¹­ë©ë‹ˆë‹¤:</p>
<ul>
  <li><em>this: 0, is: 1, the: 1, first: 1, second: 0, third: 0, document: 1, and: 0, one: 0</em></li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">message_cleaning</span><span class="p">)</span>
<span class="n">spamham_countvectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">spam_df</span><span class="p">[</span><span class="s">'text'</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="n">spamham_countvectorizer</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span> 
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    ...
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spamham_countvectorizer</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (5728, 37229)
</code></pre></div></div>

<h2 id="creating-the-trainingtest-dataset">Creating the Training/Test dataset</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">[</span><span class="s">'spam'</span><span class="p">].</span><span class="n">values</span> <span class="c1"># Loading the spam index (0 or 1)
</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">spamham_countvectorizer</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span> 

<span class="n">NB_classifier</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">NB_classifier</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_countvectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># vectorizing the sample
</span><span class="n">test_predict</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_countvectorizer</span><span class="p">)</span> <span class="c1"># applying the classifier to the sample
</span></code></pre></div></div>

<p>ë§Œì•½, ë©”ì‹œì§€ ë‚´ìš©ì˜ spam ì¸ìê°’ì´ 1ì´ë¼ë©´, NBClassifierì— ì˜í•´ ìŠ¤íŒ¸ ë©”ì‹œì§€ë¡œ ë¶„ë¥˜ëœ ê²ƒì´ë‹¤. <span style="color: blue">If the spam parameter value of the message content is 1, it is classified as a spam message by the NBClassifier.</span></p>

<h2 id="evaluating-the-model-confusion-matrixclassification-report">Evaluating the model: Confusion Matrix/Classification Report</h2>

<h3 id="í˜¼ë™-í–‰ë ¬-confusion-matrix">í˜¼ë™ í–‰ë ¬ (Confusion Matrix)</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Confusion Matrix
</span><span class="n">y_predict_train</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_predict_train</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_predict_train</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180649439-46c5a9af-0ef0-4e10-80ca-41d6e978da11.png" alt="image" /></p>

<p>14(FN + FP)ê°œì˜ ì˜¤ë¶„ë¥˜ë§Œ ì¡´ì¬í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” ì „ë¶€ ì˜³ê²Œ ë¶„ë¥˜í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. <span style="color: blue">Training dataset â€“&gt; # errors = 14(FN + FP)</span></p>

<p>í•˜ì§€ë§Œ, ì´ ê²°ê³¼ê°’ì€ ì–´ë””ê¹Œì§€ë‚˜ í•™ìŠµ ë°ì´í„° í›ˆë ¨ ì„±ëŠ¥ì´ë¯€ë¡œ í…ŒìŠ¤íŠ¸ì…‹ì—ì„œëŠ” ì—­ì „ë  ìˆ˜ ìˆìœ¼ë‹ˆ ì ˆëŒ€ì  ì‹ ë¢°ëŠ” ê¸ˆë¬¼ì´ë‹¤. <span style="color: blue">Cannot trust this result 100% because it is just based on the training dataset.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predicting the Test set results
</span><span class="n">y_predict_test</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180649505-8fd871fa-cd4b-4ae2-be89-b85f67a7a0b7.png" alt="image" /></p>

<p>ë‹¤í–‰íˆ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œë„ ë¹„ìŠ·í•œ ì„±ëŠ¥ í‰ê°€ë¥¼ ë³´ì—¬ì¤€ë‹¤. 12ê°œì˜ ì˜¤ë¶„ë¥˜ë§Œ ì¡´ì¬í•˜ëŠ” ê²ƒì„ í™•ì¸í•´ë³¼ ìˆ˜ ìˆë‹¤. <span style="color: blue">Test dataset â€“&gt; # errors = 12(FN + FP)</span></p>

<p>í•˜ì§€ë§Œ, í…ŒìŠ¤íŠ¸ì…‹ê³¼ training ë°ì´í„°ì˜ ë¹„ìœ¨ ë¶„í¬ì— ì£¼ëª©í•˜ê³ , ì ˆëŒ€ì ì¸ ìˆ˜ì¹˜ì— ì˜ì¡´í•˜ì—¬ ì„±ëŠ¥ í‰ê°€ë¥¼ í•˜ë©´ ì•ˆëœë‹¤. <span style="color: blue">Paying attention to the distribution of the training and test dataset </span></p>

<h3 id="ì„±ëŠ¥-ì§€í‘œ-classification-report">ì„±ëŠ¥ ì§€í‘œ (Classification Report)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                precision    recall  f1-score   support

            0       1.00      0.99      0.99       881
            1       0.96      0.99      0.98       265

    avg / total       0.99      0.99      0.99      1146
</code></pre></div></div>

<h1 id="part-2-yelp-reviews">PART 2: YELP Reviews</h1>
<p>â€˜ì—˜í”„â€™ëŠ” ê¸°ì—…ì²´ì™€ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ëŒ€ì¤‘ì˜ ë¦¬ë·° í¬ëŸ¼ì„ ì œê³µí•˜ëŠ” ì•±ìœ¼ë¡œ ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ ì‚¬ìš©í•´ ì—˜í”„ ë¦¬ë·°ë¥¼ ë¶„ì„í•´ë³¸ë‹¤. <span style="color: blue">A public review forum for businesses and services, using natural language processing technology to analyze YELP reviews.</span></p>

<p>ìì—°ì–´ ì²˜ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ë¦¬ë·°ì— ìˆëŠ” ìˆœìˆ˜ í…ìŠ¤íŠ¸ì— ê¸°ë°˜í•´ ê³ ê° ê¸°ë¶„ì´ ì¢‹ì€ì§€ ë‚˜ìœì§€ ê°ì„± ë¶„ì„ì„ ì‹œí–‰í•œ í›„, ëª¨ë¸ì´ ìë™ì ìœ¼ë¡œ í•´ë‹¹ ê³ ê°ì´ ìƒí’ˆì— ë³„ì ì„ ì–¼ë§ˆë‚˜ ë¶€ê³¼í• ì§€ ì˜ˆì¸¡í•œë‹¤. <span style="color: blue">After sentiment analysis to raw test data using NLP, the model predicts appropriate star rate</span></p>

<h2 id="loading-the-dataset-1">Loading the dataset</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"yelp.csv"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180663433-611d058b-ec9e-4276-a517-9b7020c66700.png" alt="image" /></p>

<h2 id="data-visualization-1">Data Visualization</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df</span><span class="p">[</span><span class="s">'length'</span><span class="p">]</span> <span class="o">=</span> <span class="n">yelp_df</span><span class="p">[</span><span class="s">'text'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
<span class="n">yelp_df</span><span class="p">[</span><span class="s">'length'</span><span class="p">].</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">'hist'</span><span class="p">)</span> 
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180663579-4a692ad7-7df5-4913-8a64-d4edd41607ec.png" alt="image" /></p>

<p>ëŒ€ëµ 400ë‹¨ì–´ê°€ ë¶„í¬ì—ì„œ ê°€ì¥ ë§ì€ ê²ƒìœ¼ë¡œ ê´€ì°°ëœë‹¤. <span style="color: blue">Approximately, 400 words appear the most in the distribution</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df</span><span class="p">.</span><span class="n">length</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    count    10000.000000
    mean       710.738700
    std        617.399827
    min          1.000000
    25%        294.000000
    50%        541.500000
    75%        930.000000
    max       4997.000000
    Name: length, dtype: float64
</code></pre></div></div>

<p>ìœ„ ê²°ê³¼ì—ì„œ ê°€ì¥ ë§ì€ ë‹¨ì–´ ìˆ˜ëŠ” 4997ê°œì´ê³ , í‰ê·  ë‹¨ì–´ ìˆ˜ëŠ” 710ì¸ ê²ƒìœ¼ë¡œ ë°œê²¬ëë‹¤. <span style="color: blue">The max number of words = 4997, avg. = 710</span></p>

<p>ê·¸ë ‡ë‹¤ë©´, ê° ë³„ì  ë³„ ë¦¬ë·° ê°œìˆ˜ ë¶„í¬ëŠ” ì–´ë– í• ê¹Œ? <span style="color: blue">What about the star distribution?</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="s">'stars'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">yelp_df</span><span class="p">)</span> <span class="c1"># count by column 'stars'
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180664615-c1904d4b-a7f2-49b5-b6c1-4c5001687b63.png" alt="image" /></p>

<p>ë¶„í¬ë„ì—ì„œ ë‚˜ì˜¨ ë°”ì™€ ê°™ì´ ë³„ì  4ì ì´ ê°€ì¥ ë§ì€ ë¹ˆë„ìˆ˜ë¥¼ ì°¨ì§€í•œë‹¤. <span style="color: blue">4 stars appear the most</span></p>

<p>ì—¬ê¸°ì„œ, ìš°ë¦¬ëŠ” ê° ë³„ì  ë³„ë¡œ ë‹¨ì–´ ê¸¸ì´ ê°œìˆ˜ ë¶„í¬ë¥¼ í™•ì¸í•´ë³´ê³ ì í•œë‹¤. <span style="color: blue">What about the length of words by star rate</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">FacetGrid</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">yelp_df</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">'stars'</span><span class="p">,</span> <span class="n">col_wrap</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># í•œ ì¤„ì— ì´ 5ê°œ gridë¥¼ ë³„ì  ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
</span><span class="n">g</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">plt</span><span class="p">.</span><span class="n">hist</span><span class="p">,</span> <span class="s">'length'</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'r'</span><span class="p">)</span> <span class="c1"># íˆìŠ¤í† ê·¸ë¨ w/ x-axis = length
</span></code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180664713-5cda0980-4cb4-4f77-b58d-b11f059294d7.png" alt="image" /></p>

<p>ë¶„í¬ë„ì—ì„œ í™•ì¸í•´ë³¼ ìˆ˜ ìˆë“¯ì´, xì¶•ì€ ë‹¨ì–´ì˜ ê¸¸ì´ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. <span style="color: blue">x-axis = length of words</span></p>

<p>ë”°ë¼ì„œ, ê¸¸ì´ê°€ ì§§ì€ ë¦¬ë·°ì˜ ë¹ˆë„ìˆ˜ê°€ ê° ë³„ì ë§ˆë‹¤ ë†’ê²Œ ë‚˜íƒ€ë‚œ ê²ƒì„ í™•ì¸í•´ë³¼ ìˆ˜ ìˆë‹¤. <span style="color: blue">The short length of reviews appear the most by each star rate</span></p>

<p>ì´ì œ, ë³„ì  1ê³¼ 5ë¥¼ ë¹„êµí•´ë³´ì. <span style="color: blue">What about star rate 1 vs. 5?</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df_1</span> <span class="o">=</span> <span class="n">yelp_df</span><span class="p">[</span><span class="n">yelp_df</span><span class="p">[</span><span class="s">'stars'</span><span class="p">]</span><span class="o">==</span><span class="mi">1</span><span class="p">]</span>
<span class="n">yelp_df_5</span> <span class="o">=</span> <span class="n">yelp_df</span><span class="p">[</span><span class="n">yelp_df</span><span class="p">[</span><span class="s">'stars'</span><span class="p">]</span><span class="o">==</span><span class="mi">5</span><span class="p">]</span>
<span class="n">yelp_df_1_5</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">yelp_df_1</span> <span class="p">,</span> <span class="n">yelp_df_5</span><span class="p">])</span> <span class="c1"># í•œ í–‰ë ¬ë¡œ í•©ì¹˜ê¸°
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span> <span class="s">'1-Stars percentage ='</span><span class="p">,</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">yelp_df_1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">)</span> <span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="s">"%"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    1-Stars percentage = 18.330885952031327 %
</code></pre></div></div>

<p>ë³„ì  1ì ì€ ë³„ì  5ì ì— ëŒ€ë¹„í•˜ì—¬ 18.3%ì˜ ë¹ˆë„ìˆ˜ë¥¼ ì°¨ì§€í•œë‹¤. <span style="color: blue">star rate 1 appear 18.3% more than 5</span></p>

<p>ë”°ë¼ì„œ, ë³„ì  5ì ì€ 81.67%ë¥¼ ì°¨ì§€í•  ê²ƒì´ë‹¤. <span style="color: blue">hence, star rate 5 takes 81.67%</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'stars'</span><span class="p">],</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Count"</span><span class="p">)</span> 
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180664906-878df245-f501-4236-bde6-903fd5cb8cee.png" alt="image" /></p>

<h2 id="nlp-1">NLP</h2>

<h3 id="ë¶ˆìš©ì–´êµ¬ë‘ì -ì œê±°-stopwordspunctuation">ë¶ˆìš©ì–´/êµ¬ë‘ì  ì œê±° (Stopwords/Punctuation)</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">message_cleaning</span><span class="p">(</span><span class="n">message</span><span class="p">):</span>
    <span class="n">Test_punc_removed</span> <span class="o">=</span> <span class="p">[</span><span class="n">char</span> <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">message</span> <span class="k">if</span> <span class="n">char</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">]</span>
    <span class="n">Test_punc_removed_join</span> <span class="o">=</span> <span class="s">''</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">Test_punc_removed</span><span class="p">)</span>
    <span class="n">Test_punc_removed_join_clean</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">Test_punc_removed_join</span><span class="p">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">word</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="p">.</span><span class="n">words</span><span class="p">(</span><span class="s">'english'</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">Test_punc_removed_join_clean</span>
</code></pre></div></div>

<details>
<summary>Result(hide/show)</summary>
<div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">yelp_df_clean</span> <span class="o">=</span> <span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'text'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="n">message_cleaning</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">yelp_df_clean</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># show the cleaned up version
</span></code></pre></div>    </div>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    ['wife', 'took', 'birthday', 'breakfast', 'excellent', 'weather', 'perfect', 'made', 'sitting', 'outside', 'overlooking', 'grounds', 'absolute', 'pleasure', 'waitress', 'excellent', 'food', 'arrived', 'quickly', 'semibusy', 'Saturday', 'morning', 'looked', 'like', 'place', 'fills', 'pretty', 'quickly', 'earlier', 'get', 'better', 'favor', 'get', 'Bloody', 'Mary', 'phenomenal', 'simply', 'best', 'Ive', 'ever', 'Im', 'pretty', 'sure', 'use', 'ingredients', 'garden', 'blend', 'fresh', 'order', 'amazing', 'EVERYTHING', 'menu', 'looks', 'excellent', 'white', 'truffle', 'scrambled', 'eggs', 'vegetable', 'skillet', 'tasty', 'delicious', 'came', '2', 'pieces', 'griddled', 'bread', 'amazing', 'absolutely', 'made', 'meal', 'complete', 'best', 'toast', 'Ive', 'ever', 'Anyway', 'cant', 'wait', 'go', 'back']
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'text'</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># show the original version
</span></code></pre></div>    </div>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.

    Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.

    While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best "toast" I've ever had.

    Anyway, I can't wait to go back!
</code></pre></div>    </div>

  </div>
</details>

<h3 id="count-vectorizer-1"><a href="#count-vectorizer">Count Vectorizer</a></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">message_cleaning</span><span class="p">)</span>
<span class="n">yelp_countvectorizer</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'text'</span><span class="p">])</span>

<span class="n">yelp_countvectorizer</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    (4086, 26435)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">yelp_countvectorizer</span><span class="p">.</span><span class="n">toarray</span><span class="p">())</span>  
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    ...
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]
    [0 0 0 ... 0 0 0]]
</code></pre></div></div>

<h2 id="creating-the-trainingtest-dataset-1">Creating the Training/Test dataset</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">yelp_countvectorizer</span><span class="p">,</span> <span class="n">yelp_df_1_5</span><span class="p">[</span><span class="s">'stars'</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="training-the-model-naive-beyas">Training the model (Naive Beyas)</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>

<span class="n">NB_classifier</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="n">NB_classifier</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="evaluating-the-model">Evaluating the model</h2>
<h3 id="confusion-matrix">Confusion Matrix</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="n">y_predict_train</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">y_predict_train</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_predict_train</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180665314-052c9c4f-9ee8-4e45-83e8-40498b220715.png" alt="image" /></p>

<p>ëª¨ë¸ì´ í•™ìŠµ ë°ì´í„°ë¥¼ í›ˆë ¨í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ìƒê¸° í˜¼ë™ í–‰ë ¬ì—ì„œ ì˜¤ë¶„ë¥˜ê°€ 64ê°œì¸ ê²ƒìœ¼ë¡œ í™•ì¸ëœë‹¤. <span style="color: blue">Training dataset â€“&gt; # errors = 64 in confusion matrix</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Predicting the Test set results
</span><span class="n">y_predict_test</span> <span class="o">=</span> <span class="n">NB_classifier</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/180665355-5991613d-7965-4802-982c-6913ef276720.png" alt="image" /></p>

<p>ë°˜ëŒ€ë¡œ ëª¨ë¸ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ìƒê¸° í˜¼ë™ í–‰ë ¬ì—ì„œ ì˜¤ë¶„ë¥˜ê°€ 67ê°œì¸ ê²ƒìœ¼ë¡œ í™•ì¸ëœë‹¤. <span style="color: blue">Test dataset â€“&gt; # errors = 67 in confusion matrix</span></p>

<h3 id="ì„±ëŠ¥-ì§€í‘œ-classification-report-1">ì„±ëŠ¥ ì§€í‘œ (Classification Report)</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predict_test</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                precision    recall  f1-score   support

            1       0.86      0.68      0.76       156
            5       0.93      0.97      0.95       662

    avg / total       0.92      0.92      0.91       818
</code></pre></div></div>

<h2 id="tf-idf-term-frequency-inverse-document-frequency">TF-IDF (term frequency-inverse document frequency)</h2>
<p>ì •ë³´ ê²€ìƒ‰ê³¼ í…ìŠ¤íŠ¸ ë§ˆì´ë‹ì—ì„œ ì´ìš©í•˜ëŠ” ê°€ì¤‘ì¹˜ë¡œ, ì—¬ëŸ¬ ë¬¸ì„œë¡œ ì´ë£¨ì–´ì§„ ë¬¸ì„œêµ°ì´ ìˆì„ ë•Œ ì–´ë–¤ ë‹¨ì–´ê°€ íŠ¹ì • ë¬¸ì„œ ë‚´ì—ì„œ ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œ ê²ƒì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í†µê³„ì  ìˆ˜ì¹˜ì´ë‹¤. <span style="color: blue">A statistical measure that evaluates how relevant a word is to a document in a collection of documents.</span></p>

<p>ê°€ë ¹, ë¶€ë™ì‚° ê´€ë ¨í•˜ì—¬ â€˜ê³„ì•½â€™ì´ë¼ëŠ” ë‹¨ì–´ê°€ ì§€ê·¹íˆ ì¤‘ìš”í•  ê²ƒì´ë‹¤. <span style="color: blue">For example, â€˜contractâ€™ is important in terms of â€˜real estatesâ€™</span></p>

<p>For more information, click <a href="https://hchoi256.github.io/nlp/nlp-basic-word-embedding/">here</a> or <a href="#code">code</a>.</p>
:ET