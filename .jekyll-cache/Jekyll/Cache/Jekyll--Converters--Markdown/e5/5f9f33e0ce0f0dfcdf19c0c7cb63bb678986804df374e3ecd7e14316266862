I" g<p class="notice--danger"><strong>[Notice]</strong> <a href="https://github.com/Dataweekends/zero_to_deep_learning_udemy">Reference</a></p>

<h1 id="rnn">RNN</h1>
<p>ë‹¤ë¥¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ì²˜ëŸ¼ ì€ë‹‰ì¸µ (Hidden Layer)ì„ ì œê³µí•  ë¿ë§Œ ì•„ë‹ˆë¼, ìì²´ì ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ì„ì‹œì ì¸ ë£¨í”„ê°€ ì¡´ì¬í•œë‹¤; ì‹œê°„ì´ë¼ëŠ” ì°¨ì›ì´ ì¶”ê°€ëœë‹¤. <span style="color: blue"> Not only does it provide a hidden layer like other deep learning models, but it also has its own ad hoc loops; <strong>A dimension of time</strong> is added. </span></p>

<p>ë”°ë¼ì„œ, RNNì€ ì´ì „ì—ì„œ ë°œìƒí•œ ì¼ì„ ê¸°ì–µí•  ìˆ˜ ìˆë‹¤! <span style="color: blue"> Thus, RNNs can remember what happened in the past! </span></p>

<p>í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ì™€ ì˜ ì˜ë™í•œë‹¤.<span style="color: blue"> Works well with text sequences. </span></p>

<h1 id="loading-the-dataset">Loading the dataset</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'../assets/data/cansim-0800020-eng-6674700030567901031.csv'</span><span class="p">,</span>
                 <span class="n">skiprows</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">skipfooter</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                 <span class="n">engine</span><span class="o">=</span><span class="s">'python'</span><span class="p">)</span>
<span class="n">df</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182352758-1db7300d-249f-4ec2-b7f4-2b1f4e942a6f.png" alt="image" /></p>

<p>ìƒê¸° ë””ë ‰í† ë¦¬ì— <em>ì°¸ì¡°</em> ì‚¬ì´íŠ¸ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë°›ì. <span style="color: blue"> Download the file from the <em>reference</em> site, then save it into the above directory. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182352030-57851bf4-8910-4dcc-89f0-fd90475b217a.png" alt="image" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182361418-701dae63-639d-46dc-8532-0d1c8a6ca33b.png" alt="image" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182352282-eaafad09-1ce0-4114-b6e7-fa80f923a533.png" alt="image" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182361578-93cd0623-48b6-4191-8ddf-cf72e3c11e16.png" alt="image" /></p>

<p>ì”¨ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ í•œ ëˆˆì— ë³€ìˆ˜ë“¤ ê°„ ìƒê´€ê´€ê³„ë¥¼ ì‹œê°í™”í–ˆë‹¤. <span style="color: blue"> The correlation between variables was visualized at a glance using the Seabone library. </span></p>

<p>â€˜Unadjustedâ€™ì™€ â€˜Seasonally adjustedâ€™ëŠ” ì„œë¡œ <strong>ì„ í˜•ì ì¸</strong> ìƒê´€ê´€ê³„ê°€ ìˆìŒì„ ë°œê²¬í•  ìˆ˜ ìˆë‹¤. <span style="color: blue"> It can be found that â€˜Unadjustedâ€™ and â€˜Seasonally adjustedâ€™ have a <strong>linear</strong> correlation with each other. </span></p>

<p>ê·¸ë ‡ë‹¤ë©´, ì´ì œ ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ ë‘ ë³€ìˆ˜ì˜ ë³€í™”ë¥¼ í™•ì¸í•´ë³´ì. <span style="color: blue"> Now, letâ€™s check the change of the two variables with the passage of time. </span></p>

<h1 id="preprocessing">Preprocessing</h1>

<p>ì‹œê³„ì—´ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ì„œëŠ” ì‹œê°„ê³¼ ê´€ë ¨ëœ ë³€ìˆ˜ë¥¼ ì¸ë±ìŠ¤ë¡œ ì‚¼ëŠ” ì „ì²˜ë¦¬ ì‘ì—…ì´ í•„ìˆ˜ë‹¤. <span style="color: blue"> In order to address time series data, we should go through the process to have time-related variables as indexes. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pandas.tseries.offsets</span> <span class="kn">import</span> <span class="n">MonthEnd</span>

<span class="n">df</span><span class="p">[</span><span class="s">'Adjustments'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'Adjustments'</span><span class="p">])</span> <span class="o">+</span> <span class="n">MonthEnd</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># date formatting
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'Adjustments'</span><span class="p">)</span> <span class="c1"># preprocessing for time series
</span><span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">df</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                Unadjusted  Seasonally adjusted
    Adjustments                                 
    1991-01-31     12588862             15026890
    1991-02-28     12154321             15304585
    1991-03-31     14337072             15413591
    1991-04-30     15108570             15293409
    1991-05-31     17225734             15676083
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182353479-97b1ba63-fa6f-4301-b5c7-722d18cd6c42.png" alt="image" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">time_pivot</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Timestamp</span><span class="p">(</span><span class="s">'01-01-2012'</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:</span><span class="n">time_pivot</span><span class="p">,</span> <span class="p">[</span><span class="s">'Unadjusted'</span><span class="p">]]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">time_pivot</span><span class="p">:,</span> <span class="p">[</span><span class="s">'Unadjusted'</span><span class="p">]]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># visualizing the datasets
</span><span class="n">ax</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">test</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'test'</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182354623-4dd81c45-f931-4d14-96b0-0b3d2a96d1b6.png" alt="image" /></p>

<p><strong>Training set</strong>: 2012ë…„ ê¹Œì§€ì˜ ë°ì´í„° <span style="color: blue"> Data before 2012 </span></p>

<p><strong>Test set</strong>: 2012ë…„ ì´í›„ ë°ì´í„° <span style="color: blue"> Data after 2012 </span></p>

<p>íŒŒë€ ì„ ì€ â€˜trainâ€™, ì£¼í™©ìƒ‰ì€ â€˜testâ€™ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. <span style="color: blue"> blue: train, orange: test</span></p>

<h1 id="feature-scaling">Feature Scaling</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

<span class="n">train_sc</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">test_sc</span> <span class="o">=</span> <span class="n">sc</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    array([[0.01402033],
        [0.        ],
        [0.0704258 ],
        [0.09531795],
        [0.16362761],
        [0.13514108],
    ...
        [0.81439355],
        [0.79916654],
        [0.80210057],
        [0.81482896],
        [1.        ]])
</code></pre></div></div>

<blockquote>
  <p><a href="https://github.com/hchoi256/ai-terms">MinMaxScaler</a></p>
</blockquote>

<p>ì‹ ê²½ë§ í•™ìŠµì— ì´ìš©í•˜ê¸° ì „ í…Œì´ë¸” í˜•íƒœë¡œì¨ ë°ì´í„°ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ dataframe í˜•íƒœë¡œ ë³€í˜•í•˜ì. <span style="color: blue"> Before using it for neural network training, letâ€™s transform it into a dataframe format to check the data in a table format.</span></p>

<p>ì§ê´€ì ìœ¼ë¡œ í™•ì¸í•´ë³´ê¸° ìœ„í•´ 12ë‹¬ì˜ ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•œ í…Œì´ë¸”ì„ í˜•ì„±í•´ë³´ì. <span style="color: blue"> For intuition, letâ€™s form a table for time series analysis of 13 months.</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_sc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_sc</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Scaled'</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">train</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">test_sc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_sc</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'Scaled'</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">)</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">):</span>
    <span class="n">train_sc_df</span><span class="p">[</span><span class="s">'shift_{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">s</span><span class="p">)]</span> <span class="o">=</span> <span class="n">train_sc_df</span><span class="p">[</span><span class="s">'Scaled'</span><span class="p">].</span><span class="n">shift</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">test_sc_df</span><span class="p">[</span><span class="s">'shift_{}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">s</span><span class="p">)]</span> <span class="o">=</span> <span class="n">test_sc_df</span><span class="p">[</span><span class="s">'Scaled'</span><span class="p">].</span><span class="n">shift</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/39285147/182356292-733ab690-76e4-47a3-94f2-e43a66de6855.png" alt="image" /></p>

<p>í…Œì´ë¸”ì—ì„œ ì‹œê°„ì˜ íë¦„ì— ë”°ë¼ ì‹œê³„ì—´ ê°’ë“¤ ë˜í•œ ëˆ„ì ë¨ì„ í™•ì¸í•´ë³¼ ìˆ˜ ìˆë‹¤. <span style="color: blue"> In the table, it can be seen that the time series values â€‹â€‹are accumulated over time.</span></p>

<h1 id="splitting-the-dataset-into-the-training-set-and-test-set">Splitting the dataset into the Training set and Test set</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_sc_df</span><span class="p">.</span><span class="n">dropna</span><span class="p">().</span><span class="n">drop</span><span class="p">(</span><span class="s">'Scaled'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_sc_df</span><span class="p">.</span><span class="n">dropna</span><span class="p">()[[</span><span class="s">'Scaled'</span><span class="p">]]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_sc_df</span><span class="p">.</span><span class="n">dropna</span><span class="p">().</span><span class="n">drop</span><span class="p">(</span><span class="s">'Scaled'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_sc_df</span><span class="p">.</span><span class="n">dropna</span><span class="p">()[[</span><span class="s">'Scaled'</span><span class="p">]]</span>
</code></pre></div></div>

<p>ê²°ì¸¡ì¹˜ê°€ ì¡´ì¬í•˜ëŠ” í–‰ì„ ì œì™¸í•œ í›„, ì‹ ê²½ë§ í•™ìŠµì— ë¶ˆí•„ìš”í•œ â€˜Scaledâ€™ë¥¼ ì œê±°í•œë‹¤. <span style="color: blue"> After excluding rows with missing values, â€˜Scaledâ€™ unnecessary for neural network training is removed. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Converting to ndarray
</span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">values</span>
<span class="n">X_test</span><span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">.</span><span class="n">values</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">.</span><span class="n">values</span>
</code></pre></div></div>

<p>ì‹œê°í™” ëª©ì ì„ ë‹¬ì„±í•œ dataframe í˜•íƒœë¥¼ ë‹¤ì‹œ ndarrayë¡œ ë°”ê¿”ì¤€ë‹¤. <span style="color: blue"> Changing the dataframe type that has achieved the purpose of visualization back to ndarray. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># reshape(size, timestep, feature)
</span><span class="n">X_train_t</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test_t</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>ê¸°ì¡´ ì‹ ê²½ë§ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” XëŠ” 2ì°¨ì› ë°°ì—´ í˜•íƒœì—¬ì•¼ í•˜ì§€ë§Œ, RNNì€ â€˜ì‹œê°„â€™ì´ë¼ëŠ”   ìƒˆë¡œìš´ ì°¨ì›ì´ ì¡´ì¬í•œë‹¤.<span style="color: blue"> Neural network training usually requires 2-dimensional input data, but RNNs have a new dimension called â€˜timeâ€™. </span></p>

<p>ë”°ë¼ì„œ, 2ì°¨ì›ì´ ì•„ë‹Œ 3ì°¨ì› ë°°ì—´ í˜•íƒœë¡œ ë°”ê¿”ì¤˜ì•¼ í•œë‹¤. <span style="color: blue"> Therefore, the input must be converted to a 3D array rather than a 2D. </span></p>

<h1 id="building-the-model-lstm">Building the model: LSTM</h1>
<p>LSTMì€ RNNì´ ê°€ì§„ ì„ì‹œì ì¸ ë£¨í”„ë¥¼ ì¢€ë” ì¥ê¸°ì ìœ¼ë¡œ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. <span style="color: blue"> LSTM is designed to maintain the temporary loop of RNN for a longer period of time. </span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># LSTM
</span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">backend</span><span class="p">.</span><span class="n">clear_session</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span> <span class="c1"># (timestep, feature)
</span><span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mean_squared_error'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Model: "sequential"
    _________________________________________________________________
    Layer (type)                Output Shape              Param #   
    =================================================================
    lstm (LSTM)                 (None, 20)                1760      
                                                                    
    dense (Dense)               (None, 1)                 21        
                                                                    
    =================================================================
    Total params: 1,781
    Trainable params: 1,781
    Non-trainable params: 0
    _________________________________________________________________
</code></pre></div></div>

<p>LSTM ëª¨ë¸ì˜ ì…ë ¥ì¸µ ì°¨ì›ìœ¼ë¡œ (12, 1)ì„ ë„£ì–´ì¤¬ë‹¤. <span style="color: blue"> We put (12, 1) as the dimension of the input layer of the LSTM model. </span></p>

<p>ì—¬ê¸°ì„œ, 12ëŠ” ì‹œê°„ ì°¨ì›ìœ¼ë¡œ 12ë‹¬ì„ ì˜ë¯¸í•œë‹¤. <span style="color: blue"> Here, 12 means 12 months in the time dimension.</span></p>

<h1 id="training-the-model">Training the model</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">early_stop</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s">'loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_t</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stop</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    Epoch 1/100
    8/8 [==============================] - 2s 6ms/step - loss: 0.2733
    Epoch 2/100
    8/8 [==============================] - 0s 6ms/step - loss: 0.1831
    Epoch 3/100
    8/8 [==============================] - 0s 6ms/step - loss: 0.1105
    Epoch 4/100
    8/8 [==============================] - 0s 5ms/step - loss: 0.0547
    Epoch 5/100
    8/8 [==============================] - 0s 5ms/step - loss: 0.0227
    Epoch 6/100
    8/8 [==============================] - 0s 5ms/step - loss: 0.0172
    Epoch 7/100
    8/8 [==============================] - 0s 5ms/step - loss: 0.0176
    Epoch 7: early stopping
</code></pre></div></div>

<p>EarlyStoppingì„ í™œìš©í•´ì„œ ì†ì‹¤í•¨ìˆ˜ ë³€í™”ê°€ 1ë²ˆ ì´ìƒ ì—†ë‹¤ë©´ í•™ìŠµì„ ì¤‘ì§€í•˜ê²Œ ì„¤ê³„í–ˆë‹¤.<span style="color: blue"> By using EarlyStopping, it is designed to stop learning if there is no change in the loss function more than once.</span></p>

<p>ë‰´ëŸ° ê°œìˆ˜ì™€ ê°™ì€ ìš”ì†Œë“¤ì€ <strong>ììœ¨ì ìœ¼ë¡œ</strong> ì„¤ì •í•œë‹¤.<span style="color: blue"> Factors such as the number of neurons are set <strong>autonomously</strong>.</span></p>

<h1 id="predicting-the-test-set">Predicting the Test set</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">X_test_t</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[[1.06265011]
    [0.87180554]
    [0.84048091]
    [0.86220767]
    [0.88363094]
    [0.89302107]
    [0.92552046]
    [0.89993326]
    [0.83505683]
    [0.77259579]
    [0.56926634]
    [0.61423187]]
    ...
    [1.05593537]
    [0.9437244 ]
    [0.75806325]
    [0.78276721]]]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_t</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    [[0.7675418 ]
    [0.7773328 ]
    [0.79216003]
    [0.79674876]
    [0.7971103 ]
    [0.7974134 ]
    [0.7950487 ]
    [0.7938808 ]
    [0.79453826]
    [0.7947075 ]
    [0.797763  ]
    [0.802348  ]
    [0.7896755 ]
    [0.7992326 ]
    [0.80933905]
    [0.8092701 ]
    [0.81345344]
    [0.81029963]
    [0.8067038 ]
    [0.80851555]
    [0.8075502 ]
    [0.81002915]
    [0.8135476 ]
    [0.81820446]
    ...
    [0.88950527]
    [0.8895281 ]
    [0.89572793]
    [0.8883731 ]]
</code></pre></div></div>

:ET